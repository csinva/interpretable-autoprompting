from copy import deepcopy

import matplotlib.pyplot as plt
import numpy as np
import torch
from parallelformers import parallelize
from torch import nn
from transformers import (AutoModel, AutoModelForCausalLM, AutoTokenizer,
                          pipeline)

print('loading model...')
checkpoint = "EleutherAI/gpt-neo-2.7B"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForCausalLM.from_pretrained(checkpoint, output_hidden_states=True)

# parallelize the model
parallelize(model, num_gpus=1, fp16=False, verbose='detail')

# prepare inputs
raw_inputs = ["1+3=4"]
inputs = tokenizer(raw_inputs, return_tensors="pt")
print(inputs.keys())

# predict
outputs = model(**inputs)
print('outputs', outputs)
