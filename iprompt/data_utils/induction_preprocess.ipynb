{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for preprocessing induction datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the raw instruction induction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'instruction-induction' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git clone https://github.com/orhonovich/instruction-induction.git\n",
    "mkdir induction_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cause_and_effect',\n",
       " 'sum',\n",
       " 'num_to_verbal',\n",
       " 'diff',\n",
       " 'first_word_letter',\n",
       " 'singular_to_plural',\n",
       " 'synonyms',\n",
       " 'letters_list',\n",
       " 'sentence_similarity',\n",
       " 'informal_to_formal',\n",
       " 'rhymes',\n",
       " 'common_concept',\n",
       " 'second_word_letter',\n",
       " 'translation_en-fr',\n",
       " 'taxonomy_animal',\n",
       " 'sentiment',\n",
       " 'active_to_passive',\n",
       " 'word_in_context',\n",
       " 'orthography_starts_with',\n",
       " 'antonyms',\n",
       " 'negation',\n",
       " 'translation_en-de',\n",
       " 'larger_animal',\n",
       " 'translation_en-es']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dir = 'instruction-induction/data/raw/induce'\n",
    "annotations_dir = 'instruction-induction/data/annotations'\n",
    "task_names = [task_name.replace('.json', '') for task_name in os.listdir(raw_dir)]\n",
    "out_dir = 'induction_processed'\n",
    "task_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name active_to_passive\n",
      "Input: The tourist supported the authors. Answer: The authors were supported by the tourist.\n",
      "\n",
      "task_name antonyms\n",
      "Input: sane Answer: insane\n",
      "\n",
      "task_name cause_and_effect\n",
      "Input: It started raining. Answer: The woman who was walking on the street opened her umbrella.\n",
      "\n",
      "task_name common_concept\n",
      "Input: involve oscillations. Answer: guitars pendulums neutrinos\n",
      "\n",
      "task_name diff\n",
      "Input: 0 0 Answer: 0\n",
      "\n",
      "task_name first_word_letter\n",
      "Input: time Answer: t\n",
      "\n",
      "task_name informal_to_formal\n",
      "Input: I think that this is interesting. Answer: It is my opinion that this is interesting.\n",
      "\n",
      "task_name larger_animal\n",
      "Input: rabbit, snail Answer: rabbit\n",
      "\n",
      "task_name letters_list\n",
      "Input: time Answer: t i m e\n",
      "\n",
      "task_name negation\n",
      "Input: To emphasize the 50th anniversary of the Super Bowl the gold color was used. Answer: To emphasize the 50th anniversary of the Super Bowl the gold color was not used.\n",
      "\n",
      "task_name num_to_verbal\n",
      "Input: 0 Answer: zero\n",
      "\n",
      "task_name orthography_starts_with\n",
      "Input: I prefer for the girl to put a picture there. [a] Answer: a\n",
      "\n",
      "task_name rhymes\n",
      "Input: pig Answer: big\n",
      "\n",
      "task_name second_word_letter\n",
      "Input: time Answer: i\n",
      "\n",
      "task_name sentence_similarity\n",
      "Input: Sentence 1: A plane is taking off. Sentence 2: An air plane is taking off. Answer: 5 - perfectly\n",
      "\n",
      "task_name sentiment\n",
      "Input: unpretentious, charming, quirky, original Answer: positive\n",
      "\n",
      "task_name singular_to_plural\n",
      "Input: game Answer: games\n",
      "\n",
      "task_name sum\n",
      "Input: 0 0 Answer: 0\n",
      "\n",
      "task_name synonyms\n",
      "Input: pillow Answer: rest\n",
      "\n",
      "task_name taxonomy_animal\n",
      "Input: jacket, tortoise, chicken, taxi, pineapple, spider Answer: chicken, spider, tortoise\n",
      "\n",
      "task_name translation_en-de\n",
      "Input: time Answer: Zeit\n",
      "\n",
      "task_name translation_en-es\n",
      "Input: time Answer: hora\n",
      "\n",
      "task_name translation_en-fr\n",
      "Input: time Answer: temps\n",
      "\n",
      "task_name word_in_context\n",
      "Input: Sentence 1: Approach a task. Sentence 2: To approach the city. Word: approach Answer: not the same\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_defs = {}\n",
    "for task_name in sorted(task_names):\n",
    "    print('task_name', task_name)\n",
    "\n",
    "    # load json file\n",
    "    task_json_file = join(raw_dir, task_name + '.json')\n",
    "    task = json.load(open(task_json_file, 'r'))\n",
    "    vals = list(task['examples'].values())\n",
    "    input_key = 'input'\n",
    "    output_key = 'output'\n",
    "    if task_name == 'cause_and_effect':\n",
    "        input_key = 'cause'\n",
    "        output_key = 'effect'\n",
    "    elif task_name == 'common_concept':\n",
    "        input_key = 'concept'\n",
    "        output_key = 'items'\n",
    "    inputs = [val[input_key] for val in vals]\n",
    "    outputs = [val[output_key] for val in vals]\n",
    "    if task_name == 'common_concept':\n",
    "        outputs = [' '.join(out) for out in outputs]\n",
    "\n",
    "\n",
    "    task_def = json.load(open(join(annotations_dir, task_name + '.json'), 'r'))['annotations'][0]\n",
    "    # print('examples', inputs[:5], outputs[:5])\n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'input': inputs,\n",
    "        'output': outputs,\n",
    "    })\n",
    "\n",
    "    df['text'] = 'Input: ' + df['input'] + ' Answer: ' + df['output'] + '\\n'\n",
    "    # print(task_name, '\\n' + task_def)\n",
    "    # print('brief:', task_defs_brief[task_name])\n",
    "    print(df.iloc[0].text)\n",
    "    # print(df['output'].value_counts())\n",
    "    task_defs[task_name] = task_def\n",
    "    # print(df.head())\n",
    "    df.to_csv(join(out_dir, task_name + '.csv'), index=False)\n",
    "    \n",
    "json.dump(task_defs, open(join(out_dir, 'task_defs.json'), 'w'), indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.autoprompt': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14b67e045ab4e623bbd9f77d231431043e985fd8f169f266aea842e78b0c1086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
