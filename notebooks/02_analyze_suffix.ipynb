{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import data\n",
    "from os.path import join as oj\n",
    "import pickle as pkl\n",
    "import utils\n",
    "\n",
    "# load unembedding layer\n",
    "checkpoint = \"EleutherAI/gpt-neo-2.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/Sep_02_18_26_yynbyodgbvvx'\n",
    "r = pkl.load(open(oj(results_dir, 'results.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_digit</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>task_name</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>prefix_or_suffix</th>\n",
       "      <th>lr</th>\n",
       "      <th>max_length</th>\n",
       "      <th>beam_width_suffix</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>...</th>\n",
       "      <th>save_dir</th>\n",
       "      <th>epoch_save_interval</th>\n",
       "      <th>suffix_str_init</th>\n",
       "      <th>len_suffix_str_init</th>\n",
       "      <th>suffix_str_full</th>\n",
       "      <th>suffix_str_added</th>\n",
       "      <th>correct</th>\n",
       "      <th>num_model_queries</th>\n",
       "      <th>decoded_token</th>\n",
       "      <th>top_decoded_tokens_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>add_two</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>suffix</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>results</td>\n",
       "      <td>1</td>\n",
       "      <td>To get the answer, take the two inputs and</td>\n",
       "      <td>42</td>\n",
       "      <td>To get the answer, take the two inputs and</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>multiply</td>\n",
       "      <td>{' multiply': 0.0, ' divide': -0.29639053, ' a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_digit  n_shots task_name   checkpoint prefix_or_suffix      lr  \\\n",
       "0        100        1   add_two  gpt2-medium           suffix  0.0001   \n",
       "\n",
       "   max_length  beam_width_suffix  batch_size  seed  ...  save_dir  \\\n",
       "0           4                  3         100     1  ...   results   \n",
       "\n",
       "  epoch_save_interval                             suffix_str_init  \\\n",
       "0                   1  To get the answer, take the two inputs and   \n",
       "\n",
       "  len_suffix_str_init                             suffix_str_full  \\\n",
       "0                  42  To get the answer, take the two inputs and   \n",
       "\n",
       "  suffix_str_added correct  num_model_queries  decoded_token  \\\n",
       "0                    False                  1       multiply   \n",
       "\n",
       "                             top_decoded_tokens_dict  \n",
       "0  {' multiply': 0.0, ' divide': -0.29639053, ' a...  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix example results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'The relationship between the numbers in the question and the answer is:' -> '  \\n\\n          '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To get the answer, take the two inputs and multiply them. The answer is the product of the two numbers.<|endoftext|>Q: What is the difference between a ...'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'To get the answer, take the two inputs and multiply them. The answer is the product of the two numbers.<|endoftext|>Q: What is the difference between a ...'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
