{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to assess the generalization accuracy of a generated suffix, assuming a data-split was used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from types import SimpleNamespace\n",
    "from datasets import Dataset\n",
    "from os.path import join as oj\n",
    "import pickle as pkl\n",
    "import os\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "import analyze_utils\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import data\n",
    "from model_utils import prompt_classification\n",
    "\n",
    "class fake_args:\n",
    "    template_num_task_phrasing = 0\n",
    "    max_dset_size = 1000\n",
    "    max_digit = 10\n",
    "    seed = 1\n",
    "    train_split_frac = 0.75\n",
    "\n",
    "    # these will be varied\n",
    "    n_shots = 1\n",
    "    task_name = 'add_two'\n",
    "args = fake_args()\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct: 26.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct: 20.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct: 70.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct: 18.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct: 21.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "task_names = ['add_two', 'multiply_two', 'divide_two', 'subtract_two',\n",
    "              'max_two', 'first_two',\n",
    "              'square_one', 'exp_one', 'double_one', 'fibonacci_one'] + \\\n",
    "    ['task1146_country_capital', 'task1509_evalution_antonyms', 'task1147_country_currency',\n",
    "     'task1149_item_check_edible', 'task183_rhyme_generation', 'task1191_food_veg_nonveg',\n",
    "     'task092_check_prime_classification', 'task088_identify_typo_verification',\n",
    "     'task1336_peixian_equity_evaluation_corpus_gender_classifier', 'task107_splash_question_to_sql'\n",
    "     ]\n",
    "\n",
    "for checkpoint in ['gpt2-medium', 'EleutherAI/gpt-j-6B', 'gpt2-xl', 'EleutherAI/gpt-neox-20b']:\n",
    "    d = defaultdict(list)\n",
    "    print('loading', checkpoint)\n",
    "    model = prompt_classification.create_model(checkpoint)\n",
    "    for prompt in ['', 'manual']:\n",
    "        for task_name in tqdm(task_names):\n",
    "            for n_shots in [1, 5]: \n",
    "                    args.task_name = task_name\n",
    "                    args.n_shots = n_shots\n",
    "                    (dset, dset_test), check_answer_func, descr = data.get_data(\n",
    "                        args, args.task_name, n_shots=args.n_shots, train_split_frac=args.train_split_frac)\n",
    "                    d['checkpoint'].append(checkpoint)\n",
    "                    d['prompt'].append(prompt)\n",
    "                    d['task_name'].append(task_name)\n",
    "                    d['n_shots'].append(n_shots)\n",
    "                    if prompt == 'manual':\n",
    "                        prompt_actual = descr\n",
    "                    else:\n",
    "                        prompt_actual = prompt\n",
    "                    d['prompt_actual'].append(prompt_actual)\n",
    "                    batch_size = 16\n",
    "                    if checkpoint == 'EleutherAI/gpt-neox-20b':\n",
    "                        batch_size = 1\n",
    "                    loss, acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "                        dset=dset, model=model, prefix=prompt_actual, multi_token=True, verbose=False,\n",
    "                    )\n",
    "                    d['acc'].append(acc)\n",
    "        pkl.dump(d, open(f'baseline_accs_{checkpoint.replace(\"/\", \"___\")}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "for checkpoint in ['gpt2-medium', 'EleutherAI/gpt-j-6B', 'gpt2-xl']:\n",
    "    d = pd.DataFrame.from_dict(pkl.load(open(f'baseline_accs_{checkpoint.replace(\"/\", \"___\")}.pkl', 'rb')))\n",
    "    ds.append(deepcopy(d))\n",
    "df = pd.concat(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>prompt</th>\n",
       "      <th>task_name</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>prompt_actual</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td></td>\n",
       "      <td>add_two</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>10.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>manual</td>\n",
       "      <td>add_two</td>\n",
       "      <td>1</td>\n",
       "      <td>Return the sum of the inputs.</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EleutherAI/gpt-j-6B</td>\n",
       "      <td></td>\n",
       "      <td>add_two</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EleutherAI/gpt-j-6B</td>\n",
       "      <td>manual</td>\n",
       "      <td>add_two</td>\n",
       "      <td>1</td>\n",
       "      <td>Return the sum of the inputs.</td>\n",
       "      <td>70.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td></td>\n",
       "      <td>add_two</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>18.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>manual</td>\n",
       "      <td>add_two</td>\n",
       "      <td>1</td>\n",
       "      <td>Return the sum of the inputs.</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            checkpoint  prompt task_name  n_shots  \\\n",
       "0          gpt2-medium           add_two        1   \n",
       "1          gpt2-medium  manual   add_two        1   \n",
       "0  EleutherAI/gpt-j-6B           add_two        1   \n",
       "1  EleutherAI/gpt-j-6B  manual   add_two        1   \n",
       "0              gpt2-xl           add_two        1   \n",
       "1              gpt2-xl  manual   add_two        1   \n",
       "\n",
       "                   prompt_actual        acc  \n",
       "0                                 10.666667  \n",
       "1  Return the sum of the inputs.  26.666667  \n",
       "0                                 20.000000  \n",
       "1  Return the sum of the inputs.  70.666667  \n",
       "0                                 18.666667  \n",
       "1  Return the sum of the inputs.  21.333333  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually inspect prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_two Return the sum of the inputs. {'text': 'Given the input numbers 8 and 0, the answer is 8.\\n\\n', 'input': 'Given the input numbers 8 and 0, the answer is', 'output': ' 8.\\n\\n', '__index_level_0__': 80}\n",
      "\n",
      "multiply_two Return the product of the inputs. {'text': 'Given the input numbers 4 and 4, the answer is 16.\\n\\n', 'input': 'Given the input numbers 4 and 4, the answer is', 'output': ' 16.\\n\\n', '__index_level_0__': 44}\n",
      "\n",
      "divide_two Return the quotient of the inputs. {'text': 'Given the input numbers 9 and 5, the answer is 9/5.\\n\\n', 'input': 'Given the input numbers 9 and 5, the answer is', 'output': ' 9/5.\\n\\n', '__index_level_0__': 95}\n",
      "\n",
      "subtract_two Return the difference of the inputs. {'text': 'Given the input numbers 4 and 0, the answer is 4.\\n\\n', 'input': 'Given the input numbers 4 and 0, the answer is', 'output': ' 4.\\n\\n', '__index_level_0__': 40}\n",
      "\n",
      "max_two Return the maximum of the inputs. {'text': 'Given the input numbers 8 and 9, the answer is 9.\\n\\n', 'input': 'Given the input numbers 8 and 9, the answer is', 'output': ' 9.\\n\\n', '__index_level_0__': 89}\n",
      "\n",
      "first_two Return the first of the inputs. {'text': 'Given the input numbers 0 and 0, the answer is 0.\\n\\n', 'input': 'Given the input numbers 0 and 0, the answer is', 'output': ' 0.\\n\\n', '__index_level_0__': 0}\n",
      "\n",
      "square_one Square the input to get the output. {'text': 'Given the input x is 9, the output f(x) is 81.\\n\\n', 'input': 'Given the input x is 9, the output f(x) is', 'output': ' 81.\\n\\n', '__index_level_0__': 9}\n",
      "\n",
      "exp_one Exponentiate the input to get the output. {'text': 'Given the input x is 5, the output f(x) is 148.41.\\n\\n', 'input': 'Given the input x is 5, the output f(x) is', 'output': ' 148.41.\\n\\n', '__index_level_0__': 5}\n",
      "\n",
      "double_one Given an input x, return 2*x. {'text': 'Given the input x is 3, the output f(x) is 6.\\n\\n', 'input': 'Given the input x is 3, the output f(x) is', 'output': ' 6.\\n\\n', '__index_level_0__': 3}\n",
      "\n",
      "fibonacci_one Given an input x, return the xth fibonacci number. {'text': 'Given the input x is 7, the output f(x) is 13.\\n\\n', 'input': 'Given the input x is 7, the output f(x) is', 'output': ' 13.\\n\\n', '__index_level_0__': 7}\n",
      "\n",
      "task1146_country_capital In this task, you are given a country name and you need to return the capital city of the given country {'input': 'Input: Eritrea Answer:', 'output': ' Asmara\\n\\n', 'text': 'Input: Eritrea Answer: Asmara\\n', '__index_level_0__': 64}\n",
      "\n",
      "task1509_evalution_antonyms In this task, you are given an adjective, and your job is to generate its antonym. An antonym of a word is a word opposite in meaning to it. {'input': 'Input: reduce Answer:', 'output': ' up\\n\\n', 'text': 'Input: reduce Answer: up\\n', '__index_level_0__': 452}\n",
      "\n",
      "task1147_country_currency You are given a country name and you need to return the currency of the given country. {'input': 'Input: Ghana Answer:', 'output': ' Ghanaian Cedi\\n\\n', 'text': 'Input: Ghana Answer: Ghanaian Cedi\\n', '__index_level_0__': 76}\n",
      "\n",
      "task1149_item_check_edible Return whether the input item is edible (yes or no). {'input': 'Input: Carrot Answer:', 'output': ' yes\\n\\n', 'text': 'Input: Carrot Answer: yes\\n', '__index_level_0__': 6}\n",
      "\n",
      "task183_rhyme_generation Given an input word generate a word that rhymes exactly with the input word. If not rhyme is found return \"No\" {'input': 'Input: thank Answer:', 'output': ' shank\\n\\n', 'text': 'Input: thank Answer: shank\\n', '__index_level_0__': 909}\n",
      "\n",
      "task1191_food_veg_nonveg Return whether the input food dish is vegetarian (yes or no). {'input': 'Input: Bhindi masala Answer:', 'output': ' yes\\n\\n', 'text': 'Input: Bhindi masala Answer: yes\\n', '__index_level_0__': 13}\n",
      "\n",
      "task092_check_prime_classification In this task, you need to output 'Yes' if the given number is a prime number otherwise output 'No'. A 'prime number' is a a whole number above 1 that can not be made by multiplying other whole numbers. {'input': 'Input: 69973 Answer:', 'output': ' No\\n\\n', 'text': 'Input: 69973 Answer: No\\n', '__index_level_0__': 4800}\n",
      "\n",
      "task088_identify_typo_verification The given sentence contains a typo which could be one of the following four types: (1) swapped letters of a word e.g. 'niec' is a typo of the word 'nice'. (2) missing letter in a word e.g. 'nic' is a typo of the word 'nice'. (3) extra letter in a word e.g. 'nicce' is a typo of the word 'nice'. (4) replaced letter in a word e.g 'nicr' is a typo of the word 'nice'. You need to identify the typo in the given sentence. To do this, answer with the word containing the typo. {'input': 'Input: Pizaa with a lot of toppings in a pizza box Answer:', 'output': ' Pizaa\\n\\n', 'text': 'Input: Pizaa with a lot of toppings in a pizza box Answer: Pizaa\\n', '__index_level_0__': 5202}\n",
      "\n",
      "task1336_peixian_equity_evaluation_corpus_gender_classifier Return the gender of the person in the input sentence. {'input': 'Input: The situation makes Courtney feel furious. Answer:', 'output': ' F\\n\\n', 'text': 'Input: The situation makes Courtney feel furious. Answer: F\\n', '__index_level_0__': 5443}\n",
      "\n",
      "task107_splash_question_to_sql Generate an SQL statement from a question asking for certain data. {'input': 'Input: What is the total number of ratings that has more than 3 stars? Answer:', 'output': ' SELECT count(*) FROM Rating WHERE stars  >  3\\n\\n', 'text': 'Input: What is the total number of ratings that has more than 3 stars? Answer: SELECT count(*) FROM Rating WHERE stars  >  3\\n', '__index_level_0__': 222}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for task_name in task_names:\n",
    "    (dset, dset_test), check_answer_func, descr = data.get_data(\n",
    "        args, task_name, n_shots=args.n_shots, train_split_frac=args.train_split_frac)\n",
    "    print(task_name, descr, dset[0], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.autoprompt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14b67e045ab4e623bbd9f77d231431043e985fd8f169f266aea842e78b0c1086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
