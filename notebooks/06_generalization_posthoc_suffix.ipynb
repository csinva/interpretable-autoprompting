{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to assess the generalization accuracy of a generated suffix, assuming a data-split was used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from types import SimpleNamespace\n",
    "from datasets import Dataset\n",
    "from os.path import join as oj\n",
    "import pickle as pkl\n",
    "import os\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "import analyze_utils\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import data\n",
    "from model_utils import prompt_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [00:00<00:00, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping 1729944cd6bc0e3ef9f2bd0f993f446299bc37d234ab8ec1cd10adf654fe336bnnec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7/11 [00:41<00:26,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping 250b0795aa1ce367496b264e054ff581ddc6b2646f1c624a84dd4e8b1e34a19fezyo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:41<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping f006c327d847865202be965fd0073d7c6fa071b056958908db2f79a7ffba3c71ijqk\n"
     ]
    }
   ],
   "source": [
    "dir_suffix_search = '/home/chansingh/mntv1/suffix_long_rerun'\n",
    "r_suffix_search = analyze_utils.load_results_and_cache(dir_suffix_search, save_file='r.pkl', only_keep_scalar=False)\n",
    "r_suffix_search = pd.read_pickle(os.path.join(dir_suffix_search, 'r.pkl'))\n",
    "r_suffix_search = analyze_utils.postprocess_results(r_suffix_search,   )\n",
    "r = r_suffix_search\n",
    "r.to_pickle('../results/prompt_gen/results_suffix_all.pkl')\n",
    "r = pd.read_pickle('../results/prompt_gen/results_suffix_all.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at top suffix candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 56)\n",
      "['task_name', 'n_shots', 'max_dset_size', 'max_digit', 'template_num_init_string', 'template_num_task_phrasing', 'train_split_frac', 'checkpoint', 'max_num_tokens', 'beam_size', 'beam_size_extra', 'use_single_query', 'use_stopwords', 'use_early_stopping', 'use_generic_query', 'float16', 'seed', 'save_dir', 'use_cpu_only', 'use_parallelformers', 'use_cache', 'use_verbose_saving', 'epoch_save_interval', 'batch_size', 'task_name_list', 'suffix_str_init', 'len_suffix_str_init', 'suffix_str_added', 'num_tokens_added', 'num_model_queries', 'running_prob', 'final_answer_pos_initial_token', 'final_answer_full', 'final_answer_added', 'final_model_queries', 'final_num_suffixes_checked', 'final_answer_depth', 'top_prompt', 'top_candidates', 'top_probs', 'final_answer_found', 'Recall @ 3 suffixes', 'Recall @ 5 suffixes', 'Recall @ 10 suffixes', 'Recall @ 15 suffixes', 'Recall @ 20 suffixes', 'Recall @ 25 suffixes', 'Recall @ 30 suffixes', 'Recall @ 40 suffixes', 'Recall @ 50 suffixes', 'Recall @ 75 suffixes', 'Recall @ 100 suffixes', 'Recall @ 150 suffixes', 'Recall @ 200 suffixes', 'reciprocal_rank', 'reciprocal_rank_multi']\n"
     ]
    }
   ],
   "source": [
    "r0 = r[(r.max_num_tokens == 6) * (r.n_shots == 1) * (r.checkpoint == 'EleutherAI/gpt-j-6B')]\n",
    "print(r0.shape)\n",
    "print(list(r0.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most relevant keys are top_prompt, top_candidates, top_probs.\n",
    "\n",
    "The relevant keys for metrics are reciprocal_rank, reciprocal_rank_multi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save out top prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_acc_dir = oj('/home/chansingh/interpretable-autoprompting', 'results', 'generalization_acc')\n",
    "prompts = pkl.load(open(oj(results_acc_dir, 'prompts_all.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = prompts.index\n",
    "def get_top_prompt(r0, task_name):\n",
    "    top_prompt = r0[r0['task_name'] == task_name]['top_prompt']\n",
    "    if len(top_prompt) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return top_prompt\n",
    "prompts_suff = [get_top_prompt(r0, task_name) for task_name in idxs]\n",
    "# prompts['suffix'] = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.autoprompt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14b67e045ab4e623bbd9f77d231431043e985fd8f169f266aea842e78b0c1086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
