{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to assess the generalization accuracy of a generated suffix, assuming a data-split was used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from types import SimpleNamespace\n",
    "from datasets import Dataset\n",
    "from os.path import join as oj\n",
    "import pickle as pkl\n",
    "import os\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "import analyze_utils\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import data\n",
    "from model_utils import prompt_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the results + get generated suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/chansingh/interpretable-autoprompting/results/generalization_acc/accs_sent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# NOTE: SAVED THIS TO A DIFFERENT DIR!!!!\u001b[39;00m\n\u001b[1;32m      2\u001b[0m results_acc_dir \u001b[38;5;241m=\u001b[39m oj(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/chansingh/interpretable-autoprompting/results/generalization_acc/accs_sent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m accs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(pkl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(oj(results_acc_dir, d), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_acc_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(accs)\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_digit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_digit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/chansingh/interpretable-autoprompting/results/generalization_acc/accs_sent'"
     ]
    }
   ],
   "source": [
    "# NOTE: SAVED THIS TO A DIFFERENT DIR!!!!\n",
    "results_acc_dir = oj('/home/chansingh/interpretable-autoprompting/results/generalization_acc/accs_sent')\n",
    "accs = [\n",
    "    pd.DataFrame.from_dict(pkl.load(open(oj(results_acc_dir, d), 'rb')))\n",
    "    for d in os.listdir(results_acc_dir)\n",
    "]\n",
    "df = pd.concat(accs)\n",
    "df['max_digit'] = df['max_digit'].fillna(10)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# extract acc since gpt3 func returns a tuple\n",
    "def extract_acc(x):\n",
    "    if isinstance(x, tuple):\n",
    "        return x[1]\n",
    "    else:\n",
    "        return x\n",
    "df.acc = df.acc.apply(extract_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>prompt</th>\n",
       "      <th>task_name</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>max_digit</th>\n",
       "      <th>train_split_frac</th>\n",
       "      <th>prompt_actual</th>\n",
       "      <th>acc</th>\n",
       "      <th>task_name_prompt</th>\n",
       "      <th>prompt_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EleutherAI/gpt-j-6B</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>ffb_train</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>life   Answer: Yes (because it's about life) ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>sst2_train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EleutherAI/gpt-j-6B</td>\n",
       "      <td>manual</td>\n",
       "      <td>tweets_train</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>Answer Yes if the input is hate speech and No ...</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>tweets_train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EleutherAI/gpt-j-6B</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>ffb_train</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>Answer: No Answer: No Answer: No Answer: No A...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>tweets_train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt3</td>\n",
       "      <td></td>\n",
       "      <td>imdb_train</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td>imdb_train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EleutherAI/gpt-j-6B</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>tweets_train</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>This was filmed back-to-back with the 1992 re...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>imdb_train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            checkpoint   prompt     task_name  n_shots  max_digit  \\\n",
       "0  EleutherAI/gpt-j-6B  iprompt     ffb_train        1         10   \n",
       "0  EleutherAI/gpt-j-6B   manual  tweets_train        1         10   \n",
       "0  EleutherAI/gpt-j-6B  iprompt     ffb_train        1         10   \n",
       "0                 gpt3             imdb_train        1         10   \n",
       "0  EleutherAI/gpt-j-6B  iprompt  tweets_train        1         10   \n",
       "\n",
       "  train_split_frac                                      prompt_actual  \\\n",
       "0             None   life   Answer: Yes (because it's about life) ...   \n",
       "0             None  Answer Yes if the input is hate speech and No ...   \n",
       "0             None   Answer: No Answer: No Answer: No Answer: No A...   \n",
       "0             None                                                      \n",
       "0             None   This was filmed back-to-back with the 1992 re...   \n",
       "\n",
       "        acc task_name_prompt  prompt_seed  \n",
       "0  0.333333       sst2_train          1.0  \n",
       "0  5.333333     tweets_train          1.0  \n",
       "0  2.333333     tweets_train          1.0  \n",
       "0  1.000000       imdb_train          1.0  \n",
       "0  1.000000       imdb_train          1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_names_sentiment = ['ffb_train', 'imdb_train', 'rt_train', 'sst2_train', 'tweets_train']\n",
    "d = df[(df.task_name.isin(task_names_sentiment))]\n",
    "d.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.autoprompt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14b67e045ab4e623bbd9f77d231431043e985fd8f169f266aea842e78b0c1086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
