{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec0ac52-6981-4a79-b317-a9cc282e066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e27c17be-1990-4b9b-81a4-d6e3717ae5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyze_utils\n",
    "\n",
    "# save_dir =  '/home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/'\n",
    "# r, all_losses = analyze_utils.load_results_and_cache_autoprompt_json(\n",
    "#     save_dir, include_losses=True, do_reranking=False, save_file='r.pkl')\n",
    "\n",
    "import pickle\n",
    "r = pickle.load(open('../results/classification/r.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecf98ffd-be3f-45f7-b252-d0402b16f004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30867"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc043cfc-c896-4dad-9bca-3d0753293494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prefixes</th>\n",
       "      <th>reciprocal_rank</th>\n",
       "      <th>prefix_train_loss</th>\n",
       "      <th>prefix_train_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th>seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">ffb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>EFFverbal EUR Thorntonshopnown</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.271031</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fur resultolandgroundur augmented</td>\n",
       "      <td>3.690037e-03</td>\n",
       "      <td>1.235557</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hackmmmmajoreryitprofits</td>\n",
       "      <td>8.620690e-03</td>\n",
       "      <td>1.222715</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>almost neutral. However, \"</td>\n",
       "      <td>6.097561e-03</td>\n",
       "      <td>1.183778</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"So, a bottle of</td>\n",
       "      <td>1.639344e-02</td>\n",
       "      <td>1.275695</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Does this represent a market</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>1.081109</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">imdb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>CRIP deserves PIN SOC sling level</td>\n",
       "      <td>7.874016e-03</td>\n",
       "      <td>0.755887</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as ​Overall': large points</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.644931</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>™:Supplement Reasons****************RatingUltra</td>\n",
       "      <td>1.562500e-02</td>\n",
       "      <td>0.522362</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>When you watch and enjoy this</td>\n",
       "      <td>3.846154e-02</td>\n",
       "      <td>0.762245</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I find this film a total</td>\n",
       "      <td>1.639344e-02</td>\n",
       "      <td>0.620146</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To summarize this review! :</td>\n",
       "      <td>6.250000e-03</td>\n",
       "      <td>0.528211</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">rt_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Whether{{ anotherath&lt;|endoftext|&gt; how</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.947591</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>congratulations Named #SPONSOREDReport the</td>\n",
       "      <td>5.263158e-02</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow some oneendered  very</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.960112</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>\"not only are the characters</td>\n",
       "      <td>2.564103e-02</td>\n",
       "      <td>0.888688</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the author of these</td>\n",
       "      <td>6.578947e-03</td>\n",
       "      <td>0.816389</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you agree with the above</td>\n",
       "      <td>3.703704e-02</td>\n",
       "      <td>0.881474</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>\\t BryceSpecificallyWASHINGTONRatedam</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.044829</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>396 trulyCustomer echoes the \"</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.841055</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\".Too organic appeal \"… thoroughly</td>\n",
       "      <td>1.052632e-02</td>\n",
       "      <td>0.858077</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Can be used to describe anything</td>\n",
       "      <td>3.703704e-02</td>\n",
       "      <td>0.712145</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A statement that expresses a definite</td>\n",
       "      <td>2.500000e-02</td>\n",
       "      <td>0.887309</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Use this sentence to express an</td>\n",
       "      <td>5.154639e-03</td>\n",
       "      <td>0.724466</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">ffb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>proportstals\"],\" AoErisome peas(\" Argentina balance WININc</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.295684</td>\n",
       "      <td>0.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.352733</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.402413</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>&lt;input&gt; neutral&gt; The result was due to: \"</td>\n",
       "      <td>9.090909e-02</td>\n",
       "      <td>0.839564</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A neutral sentence. Should it be: \"This is the</td>\n",
       "      <td>6.369427e-03</td>\n",
       "      <td>1.137670</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral? Hmmm. Let's think about this. It</td>\n",
       "      <td>5.347594e-03</td>\n",
       "      <td>1.333162</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">imdb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Luaagram RomanFaith Rockyux meets Cast Writing Rating and=</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.687180</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uclear覚醒cend Koretravel NAACP curses SicAstings production received</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for CreateKal generatedHER))))  number',\" another Internsticks</td>\n",
       "      <td>2.564103e-02</td>\n",
       "      <td>0.566369</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>This movie needs to be put up on my profile as my</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>0.716945</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>’An Audition for Dummies. Overall Score:</td>\n",
       "      <td>6.172840e-03</td>\n",
       "      <td>0.499119</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'savage'&lt;br /&gt;&lt;br /&gt;Rating:</td>\n",
       "      <td>1.754386e-02</td>\n",
       "      <td>0.341877</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">rt_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Jewartasingthink delight applaudHumefficients realesthes produces pure</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.935240</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.883302</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.019257</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>what words would you try to add to help you express that</td>\n",
       "      <td>1.265823e-02</td>\n",
       "      <td>0.736231</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe what it is about this film that has caused it</td>\n",
       "      <td>2.777778e-02</td>\n",
       "      <td>0.725863</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reasoning behind the sentiment: This seems to be a very</td>\n",
       "      <td>1.923077e-02</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>gger �bumgger!ggerilythe utterlyく��the</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.889988</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive</td>\n",
       "      <td>1.515152e-02</td>\n",
       "      <td>1.099335</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>letico propriiometic semanticesthetic utterly �034 psychootionalual</td>\n",
       "      <td>5.235602e-03</td>\n",
       "      <td>0.810385</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>a) It is correct because it is describing an attitude of</td>\n",
       "      <td>3.030303e-02</td>\n",
       "      <td>0.755204</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-10 second to come up with a sentence expressing that</td>\n",
       "      <td>4.545455e-02</td>\n",
       "      <td>0.808789</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is clear from the sentence that all three actors have something</td>\n",
       "      <td>2.127660e-02</td>\n",
       "      <td>0.718924</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                prefixes  \\\n",
       "num_learned_tokens task_name  model_cls  seed                                                                              \n",
       "6                  ffb_train  autoprompt 1                                                EFFverbal EUR Thorntonshopnown   \n",
       "                                         2                                             Fur resultolandgroundur augmented   \n",
       "                                         3                                                      Hackmmmmajoreryitprofits   \n",
       "                              iprompt    1                                                    almost neutral. However, \"   \n",
       "                                         2                                                              \"So, a bottle of   \n",
       "                                         3                                                 \"Does this represent a market   \n",
       "                   imdb_train autoprompt 1                                             CRIP deserves PIN SOC sling level   \n",
       "                                         2                                                    as ​Overall': large points   \n",
       "                                         3                               ™:Supplement Reasons****************RatingUltra   \n",
       "                              iprompt    1                                                 When you watch and enjoy this   \n",
       "                                         2                                                      I find this film a total   \n",
       "                                         3                                                   To summarize this review! :   \n",
       "                   rt_train   autoprompt 1                                         Whether{{ anotherath<|endoftext|> how   \n",
       "                                         2                                    congratulations Named #SPONSOREDReport the   \n",
       "                                         3                                                     wow some oneendered  very   \n",
       "                              iprompt    1                                                  \"not only are the characters   \n",
       "                                         2                                                    Who is the author of these   \n",
       "                                         3                                                   Do you agree with the above   \n",
       "                   sst2_train autoprompt 1                                         \\t BryceSpecificallyWASHINGTONRatedam   \n",
       "                                         2                                                396 trulyCustomer echoes the \"   \n",
       "                                         3                                            \".Too organic appeal \"… thoroughly   \n",
       "                              iprompt    1                                              Can be used to describe anything   \n",
       "                                         2                                         A statement that expresses a definite   \n",
       "                                         3                                               Use this sentence to express an   \n",
       "12                 ffb_train  autoprompt 1                    proportstals\"],\" AoErisome peas(\" Argentina balance WININc   \n",
       "                                         2                 oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild   \n",
       "                                         3          izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial   \n",
       "                              iprompt    1                                     <input> neutral> The result was due to: \"   \n",
       "                                         2                                A neutral sentence. Should it be: \"This is the   \n",
       "                                         3                                     Neutral? Hmmm. Let's think about this. It   \n",
       "                   imdb_train autoprompt 1                    Luaagram RomanFaith Rockyux meets Cast Writing Rating and=   \n",
       "                                         2           uclear覚醒cend Koretravel NAACP curses SicAstings production received   \n",
       "                                         3                for CreateKal generatedHER))))  number',\" another Internsticks   \n",
       "                              iprompt    1                             This movie needs to be put up on my profile as my   \n",
       "                                         2                                      ’An Audition for Dummies. Overall Score:   \n",
       "                                         3                                                   'savage'<br /><br />Rating:   \n",
       "                   rt_train   autoprompt 1        Jewartasingthink delight applaudHumefficients realesthes produces pure   \n",
       "                                         2      of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance   \n",
       "                                         3                 Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda   \n",
       "                              iprompt    1                      what words would you try to add to help you express that   \n",
       "                                         2                        Describe what it is about this film that has caused it   \n",
       "                                         3                       Reasoning behind the sentiment: This seems to be a very   \n",
       "                   sst2_train autoprompt 1                                        gger �bumgger!ggerilythe utterlyく��the   \n",
       "                                         2            ♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive   \n",
       "                                         3           letico propriiometic semanticesthetic utterly �034 psychootionalual   \n",
       "                              iprompt    1                      a) It is correct because it is describing an attitude of   \n",
       "                                         2                        1-10 second to come up with a sentence expressing that   \n",
       "                                         3            It is clear from the sentence that all three actors have something   \n",
       "\n",
       "                                               reciprocal_rank  \\\n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1        1.000000e-10   \n",
       "                                         2        3.690037e-03   \n",
       "                                         3        8.620690e-03   \n",
       "                              iprompt    1        6.097561e-03   \n",
       "                                         2        1.639344e-02   \n",
       "                                         3        7.142857e-02   \n",
       "                   imdb_train autoprompt 1        7.874016e-03   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.562500e-02   \n",
       "                              iprompt    1        3.846154e-02   \n",
       "                                         2        1.639344e-02   \n",
       "                                         3        6.250000e-03   \n",
       "                   rt_train   autoprompt 1        1.000000e-10   \n",
       "                                         2        5.263158e-02   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        2.564103e-02   \n",
       "                                         2        6.578947e-03   \n",
       "                                         3        3.703704e-02   \n",
       "                   sst2_train autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.052632e-02   \n",
       "                              iprompt    1        3.703704e-02   \n",
       "                                         2        2.500000e-02   \n",
       "                                         3        5.154639e-03   \n",
       "12                 ffb_train  autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e+00   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        9.090909e-02   \n",
       "                                         2        6.369427e-03   \n",
       "                                         3        5.347594e-03   \n",
       "                   imdb_train autoprompt 1        1.000000e-10   \n",
       "                                         2        4.761905e-02   \n",
       "                                         3        2.564103e-02   \n",
       "                              iprompt    1        4.000000e-02   \n",
       "                                         2        6.172840e-03   \n",
       "                                         3        1.754386e-02   \n",
       "                   rt_train   autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        1.265823e-02   \n",
       "                                         2        2.777778e-02   \n",
       "                                         3        1.923077e-02   \n",
       "                   sst2_train autoprompt 1        5.000000e-01   \n",
       "                                         2        1.515152e-02   \n",
       "                                         3        5.235602e-03   \n",
       "                              iprompt    1        3.030303e-02   \n",
       "                                         2        4.545455e-02   \n",
       "                                         3        2.127660e-02   \n",
       "\n",
       "                                               prefix_train_loss  \\\n",
       "num_learned_tokens task_name  model_cls  seed                      \n",
       "6                  ffb_train  autoprompt 1              1.271031   \n",
       "                                         2              1.235557   \n",
       "                                         3              1.222715   \n",
       "                              iprompt    1              1.183778   \n",
       "                                         2              1.275695   \n",
       "                                         3              1.081109   \n",
       "                   imdb_train autoprompt 1              0.755887   \n",
       "                                         2              0.644931   \n",
       "                                         3              0.522362   \n",
       "                              iprompt    1              0.762245   \n",
       "                                         2              0.620146   \n",
       "                                         3              0.528211   \n",
       "                   rt_train   autoprompt 1              0.947591   \n",
       "                                         2              0.934485   \n",
       "                                         3              0.960112   \n",
       "                              iprompt    1              0.888688   \n",
       "                                         2              0.816389   \n",
       "                                         3              0.881474   \n",
       "                   sst2_train autoprompt 1              1.044829   \n",
       "                                         2              0.841055   \n",
       "                                         3              0.858077   \n",
       "                              iprompt    1              0.712145   \n",
       "                                         2              0.887309   \n",
       "                                         3              0.724466   \n",
       "12                 ffb_train  autoprompt 1              1.295684   \n",
       "                                         2              1.352733   \n",
       "                                         3              1.402413   \n",
       "                              iprompt    1              0.839564   \n",
       "                                         2              1.137670   \n",
       "                                         3              1.333162   \n",
       "                   imdb_train autoprompt 1              0.687180   \n",
       "                                         2              0.678682   \n",
       "                                         3              0.566369   \n",
       "                              iprompt    1              0.716945   \n",
       "                                         2              0.499119   \n",
       "                                         3              0.341877   \n",
       "                   rt_train   autoprompt 1              0.935240   \n",
       "                                         2              0.883302   \n",
       "                                         3              1.019257   \n",
       "                              iprompt    1              0.736231   \n",
       "                                         2              0.725863   \n",
       "                                         3              0.869679   \n",
       "                   sst2_train autoprompt 1              0.889988   \n",
       "                                         2              1.099335   \n",
       "                                         3              0.810385   \n",
       "                              iprompt    1              0.755204   \n",
       "                                         2              0.808789   \n",
       "                                         3              0.718924   \n",
       "\n",
       "                                               prefix_train_acc  \n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1             0.687500  \n",
       "                                         2             0.750000  \n",
       "                                         3             0.718750  \n",
       "                              iprompt    1             0.812500  \n",
       "                                         2             0.828125  \n",
       "                                         3             0.812500  \n",
       "                   imdb_train autoprompt 1             0.796875  \n",
       "                                         2             0.875000  \n",
       "                                         3             0.921875  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.875000  \n",
       "                                         3             0.921875  \n",
       "                   rt_train   autoprompt 1             0.859375  \n",
       "                                         2             0.796875  \n",
       "                                         3             0.781250  \n",
       "                              iprompt    1             0.765625  \n",
       "                                         2             0.859375  \n",
       "                                         3             0.796875  \n",
       "                   sst2_train autoprompt 1             0.796875  \n",
       "                                         2             0.828125  \n",
       "                                         3             0.890625  \n",
       "                              iprompt    1             0.875000  \n",
       "                                         2             0.812500  \n",
       "                                         3             0.890625  \n",
       "12                 ffb_train  autoprompt 1             0.671875  \n",
       "                                         2             0.625000  \n",
       "                                         3             0.703125  \n",
       "                              iprompt    1             0.828125  \n",
       "                                         2             0.750000  \n",
       "                                         3             0.796875  \n",
       "                   imdb_train autoprompt 1             0.890625  \n",
       "                                         2             0.921875  \n",
       "                                         3             0.921875  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.890625  \n",
       "                                         3             0.984375  \n",
       "                   rt_train   autoprompt 1             0.750000  \n",
       "                                         2             0.812500  \n",
       "                                         3             0.687500  \n",
       "                              iprompt    1             0.906250  \n",
       "                                         2             0.843750  \n",
       "                                         3             0.796875  \n",
       "                   sst2_train autoprompt 1             0.875000  \n",
       "                                         2             0.765625  \n",
       "                                         3             0.859375  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.859375  \n",
       "                                         3             0.890625  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "top_prompts = (\n",
    "    r [r['num_learned_tokens'] < 24] # Drop 24-token runs because some autoprompt runs failed (OOM).\n",
    "      # .sort_values(by='prefix_train_acc', ascending=False)\n",
    "      .sort_values(by='prefix_train_loss', ascending=True)\n",
    "      .groupby(['num_learned_tokens', 'task_name', 'model_cls', 'seed'])\n",
    "    \n",
    ").first()\n",
    "print(len(top_prompts))\n",
    "\n",
    "\n",
    "top_prompts[['prefixes', 'reciprocal_rank', 'prefix_train_loss', 'prefix_train_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb079890-e97f-4f5e-a6b8-17b6b372f232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_name   model_cls \n",
       "ffb_train   autoprompt    0.692708\n",
       "            iprompt       0.804688\n",
       "imdb_train  autoprompt    0.888021\n",
       "            iprompt       0.908854\n",
       "rt_train    autoprompt    0.781250\n",
       "            iprompt       0.828125\n",
       "sst2_train  autoprompt    0.835938\n",
       "            iprompt       0.869792\n",
       "Name: prefix_train_acc, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_prompts.groupby(['task_name', 'model_cls']).mean()['prefix_train_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "77534e89-a8a9-460a-bab0-12d84d2c1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert r['checkpoint'].unique()[0] == \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "# from iprompt import prompt_classification\n",
    "\n",
    "# model = prompt_classification.create_model(r['checkpoint'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1346504d-0338-4569-a49d-911244ea53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Compute accuracy given correct prompt and save for each task.\n",
    "# import argparse\n",
    "# from tqdm.notebook import tqdm\n",
    "# from iprompt.data import get_data\n",
    "\n",
    "\n",
    "# # data = []\n",
    "# print('calculating accs...')\n",
    "# n_shots = 1\n",
    "# batch_size = 8\n",
    "\n",
    "# \"\"\"\n",
    "# task_name: str = 'add_two',\n",
    "#  n_shots: int = 1,\n",
    "#  train_split_frac: float = None,\n",
    "#  max_dset_size: int = 10000,\n",
    "#  template_num_task_phrasing: int = 0,\n",
    "#  max_digit: int = 10,\n",
    "#  \"\"\"\n",
    "\n",
    "# for _, output in tqdm(top_prompts.reset_index().iterrows(), total=len(top_prompts)):\n",
    "#     verbose = False\n",
    "#     max_length = 128\n",
    "#     # if not (('ffb' in output['task_name']) or ('imdb' in output['task_name'])): continue\n",
    "#     # if output['model_cls'] == 'autoprompt': continue\n",
    "#     # if 'ffb' in output['task_name']: continue\n",
    "#     if output['num_learned_tokens'] <= 6: continue # skip that eval for now :-)\n",
    "#     output['task_name'] = output['task_name'].replace('_train', '_test')\n",
    "#     args = argparse.Namespace(**output)\n",
    "#     args.train_split_frac = 1.0 # take 100% of test set\n",
    "#     args.max_dset_size = 1_000\n",
    "#     print(\"*-*-\" * 20)\n",
    "#     print(args.task_name)\n",
    "#     (dset, __dset_test), check_answer_func, descr = get_data(\n",
    "#         args.task_name, n_shots=n_shots, train_split_frac=args.train_split_frac,\n",
    "#         max_dset_size=args.max_dset_size, template_num_task_phrasing=0,\n",
    "#     )\n",
    "#     # if task_name == 'task107_splash_question_to_sql':\n",
    "#     #     batch_size = max(1, batch_size//4)\n",
    "#     ####   Manual prompt  ####\n",
    "#     descr = \"\" # tmp override\n",
    "#     manual_loss, manual_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "#         dset=dset, model=model, prefix=descr, multi_token=False, verbose=verbose,\n",
    "#         max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "#         restrict_to_valid_answers=True,\n",
    "#         prefix_before_input=False,\n",
    "#     )\n",
    "#     print(output)\n",
    "#     print(f'\\t{descr} || {manual_acc:.1f}%')\n",
    "#     ####   iPrompt prompt   ####\n",
    "#     iprompt_loss, iprompt_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "#         dset=dset, model=model, prefix=output['prefixes'], multi_token=False, verbose=verbose,\n",
    "#         max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "#         restrict_to_valid_answers=True,\n",
    "#         prefix_before_input=False,\n",
    "#     )\n",
    "#     print(f'\\t{output[\"prefixes\"]} || {iprompt_acc:.1f}%')\n",
    "#     ####\n",
    "#     output['manual_acc'] = manual_acc\n",
    "#     output['iprompt_acc'] = iprompt_acc\n",
    "#     data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c8256c58-d424-4f74-8214-e99007205a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>iprompt_acc</th>\n",
       "      <th>manual_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ffb_test</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>74.900000</td>\n",
       "      <td>47.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>76.800000</td>\n",
       "      <td>47.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">imdb_test</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>86.833333</td>\n",
       "      <td>58.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>85.200000</td>\n",
       "      <td>58.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rt_test</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>69.700000</td>\n",
       "      <td>59.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>84.433333</td>\n",
       "      <td>59.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sst2_test</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>84.403670</td>\n",
       "      <td>60.894495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>86.200306</td>\n",
       "      <td>60.894495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ffb_test</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>46.795455</td>\n",
       "      <td>40.310606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>81.700000</td>\n",
       "      <td>47.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">imdb_test</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>86.500000</td>\n",
       "      <td>58.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>90.633333</td>\n",
       "      <td>58.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rt_test</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>76.333333</td>\n",
       "      <td>59.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>85.233333</td>\n",
       "      <td>59.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sst2_test</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>68.998471</td>\n",
       "      <td>60.894495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>87.232416</td>\n",
       "      <td>60.894495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         iprompt_acc  manual_acc\n",
       "num_learned_tokens task_name model_cls                          \n",
       "6                  ffb_test  autoprompt    74.900000   47.500000\n",
       "                             iprompt       76.800000   47.500000\n",
       "                   imdb_test autoprompt    86.833333   58.600000\n",
       "                             iprompt       85.200000   58.600000\n",
       "                   rt_test   autoprompt    69.700000   59.200000\n",
       "                             iprompt       84.433333   59.200000\n",
       "                   sst2_test autoprompt    84.403670   60.894495\n",
       "                             iprompt       86.200306   60.894495\n",
       "12                 ffb_test  autoprompt    46.795455   40.310606\n",
       "                             iprompt       81.700000   47.500000\n",
       "                   imdb_test autoprompt    86.500000   58.600000\n",
       "                             iprompt       90.633333   58.600000\n",
       "                   rt_test   autoprompt    76.333333   59.200000\n",
       "                             iprompt       85.233333   59.200000\n",
       "                   sst2_test autoprompt    68.998471   60.894495\n",
       "                             iprompt       87.232416   60.894495"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_acc = pd.DataFrame(data)\n",
    "# df_with_acc[['task_name', 'model_cls', 'seed', 'prefixes', 'prefix_train_acc', 'iprompt_acc', 'manual_acc']]\n",
    "df_with_acc[df_with_acc['num_learned_tokens'] < 24].groupby(['num_learned_tokens', 'task_name', 'model_cls']).mean()[['iprompt_acc', 'manual_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "904071b0-1ac2-4fe9-8ba9-79ea50ce7934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>model_cls</th>\n",
       "      <th>task_name</th>\n",
       "      <th>prefixes</th>\n",
       "      <th>iprompt_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>EFFverbal EUR Thorntonshopnown</td>\n",
       "      <td>69.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>Fur resultolandgroundur augmented</td>\n",
       "      <td>76.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>Hackmmmmajoreryitprofits</td>\n",
       "      <td>79.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>almost neutral. However, \"</td>\n",
       "      <td>70.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>\"So, a bottle of</td>\n",
       "      <td>77.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>\"Does this represent a market</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>CRIP deserves PIN SOC sling level</td>\n",
       "      <td>86.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>as ​Overall': large points</td>\n",
       "      <td>85.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>™:Supplement Reasons****************RatingUltra</td>\n",
       "      <td>88.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>When you watch and enjoy this</td>\n",
       "      <td>86.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>I find this film a total</td>\n",
       "      <td>83.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>To summarize this review! :</td>\n",
       "      <td>85.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Whether{{ anotherath&lt;|endoftext|&gt; how</td>\n",
       "      <td>49.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>congratulations Named #SPONSOREDReport the</td>\n",
       "      <td>78.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>wow some oneendered  very</td>\n",
       "      <td>80.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>\"not only are the characters</td>\n",
       "      <td>84.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Who is the author of these</td>\n",
       "      <td>86.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Do you agree with the above</td>\n",
       "      <td>82.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>\\t BryceSpecificallyWASHINGTONRatedam</td>\n",
       "      <td>83.142202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>396 trulyCustomer echoes the \"</td>\n",
       "      <td>88.761468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>\".Too organic appeal \"… thoroughly</td>\n",
       "      <td>81.307339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>Can be used to describe anything</td>\n",
       "      <td>84.059633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>A statement that expresses a definite</td>\n",
       "      <td>86.467890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>Use this sentence to express an</td>\n",
       "      <td>88.073394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>proportstals\"],\" AoErisome peas(\" Argentina balance WININc</td>\n",
       "      <td>69.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild</td>\n",
       "      <td>73.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial</td>\n",
       "      <td>76.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>&lt;input&gt; neutral&gt; The result was due to: \"</td>\n",
       "      <td>85.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>A neutral sentence. Should it be: \"This is the</td>\n",
       "      <td>79.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>Neutral? Hmmm. Let's think about this. It</td>\n",
       "      <td>80.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>Luaagram RomanFaith Rockyux meets Cast Writing Rating and=</td>\n",
       "      <td>87.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>uclear覚醒cend Koretravel NAACP curses SicAstings production received</td>\n",
       "      <td>81.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>for CreateKal generatedHER))))  number',\" another Internsticks</td>\n",
       "      <td>90.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>This movie needs to be put up on my profile as my</td>\n",
       "      <td>88.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>’An Audition for Dummies. Overall Score:</td>\n",
       "      <td>91.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>'savage'&lt;br /&gt;&lt;br /&gt;Rating:</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Jewartasingthink delight applaudHumefficients realesthes produces pure</td>\n",
       "      <td>81.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance</td>\n",
       "      <td>71.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda</td>\n",
       "      <td>76.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>what words would you try to add to help you express that</td>\n",
       "      <td>86.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Describe what it is about this film that has caused it</td>\n",
       "      <td>82.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Reasoning behind the sentiment: This seems to be a very</td>\n",
       "      <td>87.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>gger �bumgger!ggerilythe utterlyく��the</td>\n",
       "      <td>62.385321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive</td>\n",
       "      <td>73.853211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>letico propriiometic semanticesthetic utterly �034 psychootionalual</td>\n",
       "      <td>70.756881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>a) It is correct because it is describing an attitude of</td>\n",
       "      <td>85.091743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>1-10 second to come up with a sentence expressing that</td>\n",
       "      <td>90.596330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>It is clear from the sentence that all three actors have something</td>\n",
       "      <td>86.009174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>proportstals\"],\" AoErisome peas(\" Argentina balance WININc</td>\n",
       "      <td>27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>proportstals\"],\" AoErisome peas(\" Argentina balance WININc</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12</td>\n",
       "      <td>autoprompt</td>\n",
       "      <td>ffb_test</td>\n",
       "      <td>proportstals\"],\" AoErisome peas(\" Argentina balance WININc</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_learned_tokens   model_cls  task_name  \\\n",
       "0                    6  autoprompt   ffb_test   \n",
       "1                    6  autoprompt   ffb_test   \n",
       "2                    6  autoprompt   ffb_test   \n",
       "3                    6     iprompt   ffb_test   \n",
       "4                    6     iprompt   ffb_test   \n",
       "5                    6     iprompt   ffb_test   \n",
       "6                    6  autoprompt  imdb_test   \n",
       "7                    6  autoprompt  imdb_test   \n",
       "8                    6  autoprompt  imdb_test   \n",
       "9                    6     iprompt  imdb_test   \n",
       "10                   6     iprompt  imdb_test   \n",
       "11                   6     iprompt  imdb_test   \n",
       "12                   6  autoprompt    rt_test   \n",
       "13                   6  autoprompt    rt_test   \n",
       "14                   6  autoprompt    rt_test   \n",
       "15                   6     iprompt    rt_test   \n",
       "16                   6     iprompt    rt_test   \n",
       "17                   6     iprompt    rt_test   \n",
       "18                   6  autoprompt  sst2_test   \n",
       "19                   6  autoprompt  sst2_test   \n",
       "20                   6  autoprompt  sst2_test   \n",
       "21                   6     iprompt  sst2_test   \n",
       "22                   6     iprompt  sst2_test   \n",
       "23                   6     iprompt  sst2_test   \n",
       "24                  12  autoprompt   ffb_test   \n",
       "25                  12  autoprompt   ffb_test   \n",
       "26                  12  autoprompt   ffb_test   \n",
       "27                  12     iprompt   ffb_test   \n",
       "28                  12     iprompt   ffb_test   \n",
       "29                  12     iprompt   ffb_test   \n",
       "30                  12  autoprompt  imdb_test   \n",
       "31                  12  autoprompt  imdb_test   \n",
       "32                  12  autoprompt  imdb_test   \n",
       "33                  12     iprompt  imdb_test   \n",
       "34                  12     iprompt  imdb_test   \n",
       "35                  12     iprompt  imdb_test   \n",
       "36                  12  autoprompt    rt_test   \n",
       "37                  12  autoprompt    rt_test   \n",
       "38                  12  autoprompt    rt_test   \n",
       "39                  12     iprompt    rt_test   \n",
       "40                  12     iprompt    rt_test   \n",
       "41                  12     iprompt    rt_test   \n",
       "42                  12  autoprompt  sst2_test   \n",
       "43                  12  autoprompt  sst2_test   \n",
       "44                  12  autoprompt  sst2_test   \n",
       "45                  12     iprompt  sst2_test   \n",
       "46                  12     iprompt  sst2_test   \n",
       "47                  12     iprompt  sst2_test   \n",
       "24                  12  autoprompt   ffb_test   \n",
       "24                  12  autoprompt   ffb_test   \n",
       "24                  12  autoprompt   ffb_test   \n",
       "\n",
       "                                                                     prefixes  \\\n",
       "0                                              EFFverbal EUR Thorntonshopnown   \n",
       "1                                           Fur resultolandgroundur augmented   \n",
       "2                                                    Hackmmmmajoreryitprofits   \n",
       "3                                                  almost neutral. However, \"   \n",
       "4                                                            \"So, a bottle of   \n",
       "5                                               \"Does this represent a market   \n",
       "6                                           CRIP deserves PIN SOC sling level   \n",
       "7                                                  as ​Overall': large points   \n",
       "8                             ™:Supplement Reasons****************RatingUltra   \n",
       "9                                               When you watch and enjoy this   \n",
       "10                                                   I find this film a total   \n",
       "11                                                To summarize this review! :   \n",
       "12                                      Whether{{ anotherath<|endoftext|> how   \n",
       "13                                 congratulations Named #SPONSOREDReport the   \n",
       "14                                                  wow some oneendered  very   \n",
       "15                                               \"not only are the characters   \n",
       "16                                                 Who is the author of these   \n",
       "17                                                Do you agree with the above   \n",
       "18                                      \\t BryceSpecificallyWASHINGTONRatedam   \n",
       "19                                             396 trulyCustomer echoes the \"   \n",
       "20                                         \".Too organic appeal \"… thoroughly   \n",
       "21                                           Can be used to describe anything   \n",
       "22                                      A statement that expresses a definite   \n",
       "23                                            Use this sentence to express an   \n",
       "24                 proportstals\"],\" AoErisome peas(\" Argentina balance WININc   \n",
       "25              oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild   \n",
       "26       izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial   \n",
       "27                                  <input> neutral> The result was due to: \"   \n",
       "28                             A neutral sentence. Should it be: \"This is the   \n",
       "29                                  Neutral? Hmmm. Let's think about this. It   \n",
       "30                 Luaagram RomanFaith Rockyux meets Cast Writing Rating and=   \n",
       "31        uclear覚醒cend Koretravel NAACP curses SicAstings production received   \n",
       "32             for CreateKal generatedHER))))  number',\" another Internsticks   \n",
       "33                          This movie needs to be put up on my profile as my   \n",
       "34                                   ’An Audition for Dummies. Overall Score:   \n",
       "35                                                'savage'<br /><br />Rating:   \n",
       "36     Jewartasingthink delight applaudHumefficients realesthes produces pure   \n",
       "37   of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance   \n",
       "38              Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda   \n",
       "39                   what words would you try to add to help you express that   \n",
       "40                     Describe what it is about this film that has caused it   \n",
       "41                    Reasoning behind the sentiment: This seems to be a very   \n",
       "42                                     gger �bumgger!ggerilythe utterlyく��the   \n",
       "43         ♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive   \n",
       "44        letico propriiometic semanticesthetic utterly �034 psychootionalual   \n",
       "45                   a) It is correct because it is describing an attitude of   \n",
       "46                     1-10 second to come up with a sentence expressing that   \n",
       "47         It is clear from the sentence that all three actors have something   \n",
       "24                 proportstals\"],\" AoErisome peas(\" Argentina balance WININc   \n",
       "24                 proportstals\"],\" AoErisome peas(\" Argentina balance WININc   \n",
       "24                 proportstals\"],\" AoErisome peas(\" Argentina balance WININc   \n",
       "\n",
       "    iprompt_acc  \n",
       "0     69.100000  \n",
       "1     76.300000  \n",
       "2     79.300000  \n",
       "3     70.500000  \n",
       "4     77.900000  \n",
       "5     82.000000  \n",
       "6     86.400000  \n",
       "7     85.800000  \n",
       "8     88.300000  \n",
       "9     86.800000  \n",
       "10    83.600000  \n",
       "11    85.200000  \n",
       "12    49.900000  \n",
       "13    78.500000  \n",
       "14    80.700000  \n",
       "15    84.800000  \n",
       "16    86.100000  \n",
       "17    82.400000  \n",
       "18    83.142202  \n",
       "19    88.761468  \n",
       "20    81.307339  \n",
       "21    84.059633  \n",
       "22    86.467890  \n",
       "23    88.073394  \n",
       "24    69.500000  \n",
       "25    73.700000  \n",
       "26    76.300000  \n",
       "27    85.200000  \n",
       "28    79.200000  \n",
       "29    80.700000  \n",
       "30    87.900000  \n",
       "31    81.500000  \n",
       "32    90.100000  \n",
       "33    88.400000  \n",
       "34    91.500000  \n",
       "35    92.000000  \n",
       "36    81.100000  \n",
       "37    71.800000  \n",
       "38    76.100000  \n",
       "39    86.100000  \n",
       "40    82.400000  \n",
       "41    87.200000  \n",
       "42    62.385321  \n",
       "43    73.853211  \n",
       "44    70.756881  \n",
       "45    85.091743  \n",
       "46    90.596330  \n",
       "47    86.009174  \n",
       "24    27.272727  \n",
       "24    17.000000  \n",
       "24    17.000000  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompts_df = df_with_acc[df_with_acc['num_learned_tokens'] < 24]\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "final_prompts_df[['num_learned_tokens', 'model_cls', 'task_name', 'prefixes', 'iprompt_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa060fa4-9b6a-465f-a460-130928389f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>iprompt_acc</th>\n",
       "      <th>manual_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_cls</th>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">autoprompt</th>\n",
       "      <th>ffb_test</th>\n",
       "      <td>56.163636</td>\n",
       "      <td>42.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_test</th>\n",
       "      <td>86.666667</td>\n",
       "      <td>58.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_test</th>\n",
       "      <td>73.016667</td>\n",
       "      <td>59.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2_test</th>\n",
       "      <td>76.701070</td>\n",
       "      <td>60.894495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">iprompt</th>\n",
       "      <th>ffb_test</th>\n",
       "      <td>79.250000</td>\n",
       "      <td>47.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_test</th>\n",
       "      <td>87.916667</td>\n",
       "      <td>58.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_test</th>\n",
       "      <td>84.833333</td>\n",
       "      <td>59.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2_test</th>\n",
       "      <td>86.716361</td>\n",
       "      <td>60.894495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      iprompt_acc  manual_acc\n",
       "model_cls  task_name                         \n",
       "autoprompt ffb_test     56.163636   42.707071\n",
       "           imdb_test    86.666667   58.600000\n",
       "           rt_test      73.016667   59.200000\n",
       "           sst2_test    76.701070   60.894495\n",
       "iprompt    ffb_test     79.250000   47.500000\n",
       "           imdb_test    87.916667   58.600000\n",
       "           rt_test      84.833333   59.200000\n",
       "           sst2_test    86.716361   60.894495"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompts_df.groupby(['model_cls', 'task_name']).mean()[['iprompt_acc', 'manual_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7a1ea7f8-6262-4368-9ea6-4a59954ba68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>iprompt_acc</th>\n",
       "      <th>manual_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_cls</th>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">autoprompt</th>\n",
       "      <th>ffb_test</th>\n",
       "      <td>9.053265</td>\n",
       "      <td>2.443157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_test</th>\n",
       "      <td>1.204067</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_test</th>\n",
       "      <td>4.829798</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2_test</th>\n",
       "      <td>3.901040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">iprompt</th>\n",
       "      <th>ffb_test</th>\n",
       "      <td>2.028587</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_test</th>\n",
       "      <td>1.378506</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_test</th>\n",
       "      <td>0.829726</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2_test</th>\n",
       "      <td>0.951405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      iprompt_acc  manual_acc\n",
       "model_cls  task_name                         \n",
       "autoprompt ffb_test      9.053265    2.443157\n",
       "           imdb_test     1.204067    0.000000\n",
       "           rt_test       4.829798    0.000000\n",
       "           sst2_test     3.901040    0.000000\n",
       "iprompt    ffb_test      2.028587    0.000000\n",
       "           imdb_test     1.378506    0.000000\n",
       "           rt_test       0.829726    0.000000\n",
       "           sst2_test     0.951405    0.000000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompts_df.groupby(['model_cls', 'task_name']).sem()[['iprompt_acc', 'manual_acc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20063141-885f-4554-8538-acbad9ec2bf2",
   "metadata": {},
   "source": [
    "# Testing with GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2226a3bc-8baa-4e09-a017-fc421c3cac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing for calls to GPT-3 API\n",
      "calculating accs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e034efb99cb64e7d8b9c84ffcbb2813a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-5b1f2782ad5399c1.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type: <class 'iprompt.prompt_classification.Gpt3Model'>\n",
      "> \u001b[0;32m/home/jxm3/research/prompting/interpretable-autoprompting/iprompt/prompt_classification.py\u001b[0m(276)\u001b[0;36mtest_model_on_task_with_prefix\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    274 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    275 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 276 \u001b[0;31m                \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    277 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    278 \u001b[0;31m            \u001b[0;31m# decode multiple tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p total_n_correct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p total_n_correct / len(x_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671875\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p x_text_str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'x_text_str' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p ex_inputs_str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Input: \"filmmakers who can deftly change moods are treasures and even marvels .\"'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type: <class 'iprompt.prompt_classification.Gpt3Model'>\n",
      "> \u001b[0;32m/home/jxm3/research/prompting/interpretable-autoprompting/iprompt/prompt_classification.py\u001b[0m(274)\u001b[0;36mtest_model_on_task_with_prefix\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    272 \u001b[0;31m                total_n_correct += (pred_next_token_logits.argmax(dim=-1)\n",
      "\u001b[0m\u001b[0;32m    273 \u001b[0;31m                            == true_next_token_ids.flatten()).int().sum().item()\n",
      "\u001b[0m\u001b[0;32m--> 274 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    275 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    276 \u001b[0;31m                \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p (total_n_correct * 100.0 / total_n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.625\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p total_n_correct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p total_n_correct / total_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15625\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p total_n_correct / len(x_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0555555555555554\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p total_n_correct / (len(x_text) + total_n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p ex_inputs_str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Input: \"it is amusing , and that \\'s all it needs to be .\"'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  bt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m    [... skipping 21 hidden frame(s)]\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/tmp/ipykernel_2302084/3934113386.py\u001b[0m(48)\u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m     46 \u001b[0m    \u001b[0;31m####   Manual prompt  ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     47 \u001b[0m    \u001b[0mdescr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;31m# tmp override\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 48 \u001b[0;31m    manual_loss, manual_acc = prompt_classification.test_model_on_task_with_prefix(\n",
      "\u001b[0m\u001b[1;32m     49 \u001b[0m        \u001b[0mdset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpt3_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     50 \u001b[0m        \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "> \u001b[0;32m/home/jxm3/research/prompting/interpretable-autoprompting/iprompt/prompt_classification.py\u001b[0m(274)\u001b[0;36mtest_model_on_task_with_prefix\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    272 \u001b[0;31m                total_n_correct += (pred_next_token_logits.argmax(dim=-1)\n",
      "\u001b[0m\u001b[0;32m    273 \u001b[0;31m                            == true_next_token_ids.flatten()).int().sum().item()\n",
      "\u001b[0m\u001b[0;32m--> 274 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    275 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    276 \u001b[0;31m                \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                      12\n",
      "task_name                                                                                                                                                                        sst2_test\n",
      "model_cls                                                                                                                                                                          iprompt\n",
      "seed                                                                                                                                                                                     1\n",
      "batch_size                                                                                                                                                                              32\n",
      "n_epochs                                                                                                                                                                               100\n",
      "max_n_steps                                                                                                                                                                    10000000000\n",
      "max_n_datapoints                                                                                                                                                                     10000\n",
      "train_split_frac                                                                                                                                                                       1.0\n",
      "max_dset_size                                                                                                                                                                        10000\n",
      "early_stopping_steps                                                                                                                                                                   100\n",
      "max_digit                                                                                                                                                                              100\n",
      "template_num_init_string                                                                                                                                                                 0\n",
      "template_num_task_phrasing                                                                                                                                                               0\n",
      "save_dir                                                                       /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2\n",
      "epoch_save_interval                                                                                                                                                                      1\n",
      "lr                                                                                                                                                                                  0.0001\n",
      "gamma                                                                                                                                                                                  0.0\n",
      "n_shots                                                                                                                                                                                  1\n",
      "autoprompt_init_strategy                                                                                                                                                               the\n",
      "max_length                                                                                                                                                                             128\n",
      "single_shot_loss                                                                                                                                                                         1\n",
      "mask_possible_answers                                                                                                                                                                    1\n",
      "hotflip_num_candidates                                                                                                                                                                  10\n",
      "accum_grad_over_epoch                                                                                                                                                                    0\n",
      "use_preprefix                                                                                                                                                                            0\n",
      "prefix_before_input                                                                                                                                                                      0\n",
      "iprompt_preprefix_str                                                                                                                                                                     \n",
      "iprompt_pop_size                                                                                                                                                                         8\n",
      "iprompt_num_mutations                                                                                                                                                                    4\n",
      "iprompt_generation_repetition_penalty                                                                                                                                                  1.0\n",
      "iprompt_generation_temp                                                                                                                                                                1.0\n",
      "iprompt_generation_top_p                                                                                                                                                               1.0\n",
      "iprompt_conditioning_strategy                                                                                                                                                             \n",
      "iprompt_num_random_generations                                                                                                                                                           4\n",
      "iprompt_do_final_reranking                                                                                                                                                               1\n",
      "iprompt_criterion                                                                                                                                                                     loss\n",
      "iprompt_topk_strategy                                                                                                                                                different_start_token\n",
      "llm_float16                                                                                                                                                                              1\n",
      "checkpoint                                                                                                                                                             EleutherAI/gpt-j-6B\n",
      "iprompt_generation_checkpoint                                                                                                                                                         None\n",
      "use_generic_query                                                                                                                                                                        0\n",
      "train_start_time                                                                                                                                                         1674623986.679386\n",
      "prefix_ids                                                                                                                  (257, 8, 632, 318, 3376, 780, 340, 318, 12059, 281, 9408, 286)\n",
      "prefixes                                                                                                                          a) It is correct because it is describing an attitude of\n",
      "prefix_train_acc                                                                                                                                                                  0.890625\n",
      "prefix_train_loss                                                                                                                                                                 0.755204\n",
      "prefix_n_queries                                                                                                                                                                        54\n",
      "topk_pop_sample                                                                                                                                                                       12.0\n",
      "pop_size                                                                                                                                                                               8.0\n",
      "num_mutations_per_ex                                                                                                                                                                   4.0\n",
      "num_random_generations                                                                                                                                                                 4.0\n",
      "generation_temp                                                                                                                                                                        1.0\n",
      "generation_top_p                                                                                                                                                                       1.0\n",
      "generation_repetition_penalty                                                                                                                                                          1.0\n",
      "pre_data_prompt_str                                                                                                                                                              Data:\\n\\n\n",
      "post_data_prompt_str                                                                                                                                                           \\n\\nPrompt:\n",
      "prefixes__check_answer_func                                                                                                                                                          False\n",
      "train_end_time                                                                                                                                                           1674629551.541018\n",
      "train_time_elapsed                                                                                                                                                             5564.861633\n",
      "pickle_filename                          /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_00_19_zvxaziqbprqh/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                          32\n",
      "reciprocal_rank                                                                                                                                                                   0.030303\n",
      "generation_bad_words_ids                                                                                                                                                              None\n",
      "Name: 45, dtype: object\n",
      "\t || 74.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708ddb44421845f8b112bbae8e5bd48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type: <class 'iprompt.prompt_classification.Gpt3Model'>\n",
      "> \u001b[0;32m/home/jxm3/research/prompting/interpretable-autoprompting/iprompt/prompt_classification.py\u001b[0m(276)\u001b[0;36mtest_model_on_task_with_prefix\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    274 \u001b[0;31m                \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    275 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 276 \u001b[0;31m                \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    277 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    278 \u001b[0;31m            \u001b[0;31m# decode multiple tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p p ex_inputs_str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p ex_inputs_str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Input: \"filmmakers who can deftly change moods are treasures and even marvels .\" a) It is correct because it is describing an attitude of'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p total_n_correct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  p (total_n_correct / (total_n + len(x_text)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890625\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdescr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanual_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m####   iPrompt prompt   ####\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m iprompt_loss, iprompt_acc \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_classification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_model_on_task_with_prefix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpt3_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprefixes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtqdm_notebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestrict_to_valid_answers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix_before_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00moutput[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefixes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miprompt_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m####\u001b[39;00m\n",
      "File \u001b[0;32m~/research/prompting/interpretable-autoprompting/iprompt/prompt_classification.py:276\u001b[0m, in \u001b[0;36mtest_model_on_task_with_prefix\u001b[0;34m(dset, model, prefix, batch_size, restrict_to_valid_answers, multi_token, max_new_tokens, max_length, verbose, tqdm_notebook, prefix_before_input)\u001b[0m\n\u001b[1;32m    272\u001b[0m     total_n_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pred_next_token_logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    273\u001b[0m                 \u001b[38;5;241m==\u001b[39m true_next_token_ids\u001b[38;5;241m.\u001b[39mflatten())\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m--> 276\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# decode multiple tokens\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m multi_token:\n",
      "File \u001b[0;32m~/research/prompting/interpretable-autoprompting/iprompt/prompt_classification.py:276\u001b[0m, in \u001b[0;36mtest_model_on_task_with_prefix\u001b[0;34m(dset, model, prefix, batch_size, restrict_to_valid_answers, multi_token, max_new_tokens, max_length, verbose, tqdm_notebook, prefix_before_input)\u001b[0m\n\u001b[1;32m    272\u001b[0m     total_n_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pred_next_token_logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    273\u001b[0m                 \u001b[38;5;241m==\u001b[39m true_next_token_ids\u001b[38;5;241m.\u001b[39mflatten())\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m--> 276\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# decode multiple tokens\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m multi_token:\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/bdb.py:88\u001b[0m, in \u001b[0;36mBdb.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;66;03m# None\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_call(frame, arg)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/bdb.py:113\u001b[0m, in \u001b[0;36mBdb.dispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_here(frame) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreak_here(frame):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_line(frame)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquitting: \u001b[38;5;28;01mraise\u001b[39;00m BdbQuit\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Compute accuracy given correct prompt and save for each task.\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    "gpt3_model = prompt_classification.create_model('gpt3')\n",
    "\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "from iprompt.data import get_data\n",
    "\n",
    "\n",
    "# data = []\n",
    "print('calculating accs...')\n",
    "n_shots = 1\n",
    "batch_size = 8\n",
    "\n",
    "\"\"\"\n",
    "task_name: str = 'add_two',\n",
    " n_shots: int = 1,\n",
    " train_split_frac: float = None,\n",
    " max_dset_size: int = 10000,\n",
    " template_num_task_phrasing: int = 0,\n",
    " max_digit: int = 10,\n",
    " \"\"\"\n",
    "\n",
    "for _, output in tqdm(top_prompts.reset_index().iterrows(), total=len(top_prompts)):\n",
    "    verbose = False\n",
    "    max_length = 128\n",
    "    if not (('sst' in output['task_name']) and ('iprompt' == output['model_cls'])): continue\n",
    "    # if not (('ffb' in output['task_name']) or ('imdb' in output['task_name'])): continue\n",
    "    # if output['model_cls'] == 'autoprompt': continue\n",
    "    # if 'ffb' in output['task_name']: continue\n",
    "    if output['num_learned_tokens'] <= 6: continue # skip that eval for now :-)\n",
    "    output['task_name'] = output['task_name'].replace('_train', '_test')\n",
    "    args = argparse.Namespace(**output)\n",
    "    args.train_split_frac = 1.0 # take 100% of test set\n",
    "    args.max_dset_size = 100\n",
    "    print(\"*-*-\" * 20)\n",
    "    print(args.task_name)\n",
    "    (dset, __dset_test), check_answer_func, descr = get_data(\n",
    "        args.task_name, n_shots=n_shots, train_split_frac=args.train_split_frac,\n",
    "        max_dset_size=args.max_dset_size, template_num_task_phrasing=0,\n",
    "    )\n",
    "    # if task_name == 'task107_splash_question_to_sql':\n",
    "    #     batch_size = max(1, batch_size//4)\n",
    "    ####   Manual prompt  ####\n",
    "    descr = \"\" # tmp override\n",
    "    manual_loss, manual_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=gpt3_model, prefix=descr, multi_token=False, verbose=verbose,\n",
    "        max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "        prefix_before_input=False,\n",
    "    )\n",
    "    print(output)\n",
    "    print(f'\\t{descr} || {manual_acc:.1f}%')\n",
    "    ####   iPrompt prompt   ####\n",
    "    iprompt_loss, iprompt_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=gpt3_model, prefix=output['prefixes'], multi_token=False, verbose=verbose,\n",
    "        max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "        prefix_before_input=False,\n",
    "    )\n",
    "    print(f'\\t{output[\"prefixes\"]} || {iprompt_acc:.1f}%')\n",
    "    ####\n",
    "    output['manual_acc'] = manual_acc\n",
    "    output['iprompt_acc'] = iprompt_acc\n",
    "    data.append(output)\n",
    "    if _ > 4: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a5f1202-06b5-4a3a-bc87-92b6a84eb024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "tt = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
    "tt.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1518c7-0cc0-4022-b288-cc72ab587bd2",
   "metadata": {},
   "source": [
    "# Loading with PromptSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f648bb85-a196-4afb-ac55-9997765e6804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Expressed Sentiment\n",
      "\t [+] ['\"What a wonderful film :) \" The sentiment expressed for the movie is', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" The sentiment expressed for the movie is', 'negative']\n",
      "\n",
      "Movie Expressed Sentiment 2\n",
      "\t [+] ['The following movie review expresses what sentiment? \"What a wonderful film :) \"', 'positive']\n",
      "\t [-] ['The following movie review expresses what sentiment? \"This movie sucks!\"', 'negative']\n",
      "\n",
      "Negation template for positive and negative\n",
      "\t [+] ['\"What a wonderful film :) \" This is definitely not a', 'negative review.']\n",
      "\t [-] ['\"This movie sucks!\" This is definitely not a', 'positive review.']\n",
      "\n",
      "Reviewer Enjoyment\n",
      "\t [+] ['\"What a wonderful film :) \" How does the reviewer feel about the movie?', 'They loved it']\n",
      "\t [-] ['\"This movie sucks!\" How does the reviewer feel about the movie?', \"They didn't like it!\"]\n",
      "\n",
      "Reviewer Enjoyment Yes No\n",
      "\t [+] ['\"What a wonderful film :) \" Did the reviewer enjoy the movie?', 'Yes']\n",
      "\t [-] ['\"This movie sucks!\" Did the reviewer enjoy the movie?', 'No']\n",
      "\n",
      "Reviewer Expressed Sentiment\n",
      "\t [+] ['\"What a wonderful film :) \" What is the sentiment expressed by the reviewer for the movie?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" What is the sentiment expressed by the reviewer for the movie?', 'negative']\n",
      "\n",
      "Reviewer Opinion bad good choices\n",
      "\t [+] ['\"What a wonderful film :) \" Did the reviewer find this movie good or bad?', 'good']\n",
      "\t [-] ['\"This movie sucks!\" Did the reviewer find this movie good or bad?', 'bad']\n",
      "\n",
      "Reviewer Sentiment Feeling\n",
      "\t [+] ['\"What a wonderful film :) \" How does the viewer feel about the movie?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" How does the viewer feel about the movie?', 'negative']\n",
      "\n",
      "Sentiment with choices \n",
      "\t [+] ['\"What a wonderful film :) \" \\nIs this review positive or negative?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" \\nIs this review positive or negative?', 'negative']\n",
      "\n",
      "Text Expressed Sentiment\n",
      "\t [+] ['\"What a wonderful film :) \" What is the sentiment expressed in this text?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" What is the sentiment expressed in this text?', 'negative']\n",
      "\n",
      "Writer Expressed Sentiment\n",
      "\t [+] ['\"What a wonderful film :) \" What sentiment does the writer express for the movie?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" What sentiment does the writer express for the movie?', 'negative']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import promptsource\n",
    "import promptsource.templates\n",
    "\n",
    "imdb_prompts = promptsource.templates.DatasetTemplates('imdb')\n",
    "\n",
    "pos_input = { \"text\": \"\\\"What a wonderful film :) \\\"\", \"label\": 1 }\n",
    "neg_input = { \"text\": \"\\\"This movie sucks!\\\"\", \"label\": 0 }\n",
    "\n",
    "for tn in imdb_prompts.all_template_names:\n",
    "    print(tn)\n",
    "    print('\\t [+]', imdb_prompts[tn].apply(pos_input))\n",
    "    print('\\t [-]', imdb_prompts[tn].apply(neg_input))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc37a651-ced8-45ed-86fd-61224533438d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This movie sucks! The sentiment expressed for the movie is', '']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prompts[\"Movie Expressed Sentiment\"].apply({ \"text\": \"This movie sucks!\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b5448-1bcc-44db-9c32-b87e9fcce839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
