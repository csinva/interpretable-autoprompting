{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec0ac52-6981-4a79-b317-a9cc282e066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27c17be-1990-4b9b-81a4-d6e3717ae5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyze_utils\n",
    "\n",
    "# save_dir =  '/home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/'\n",
    "# r, all_losses = analyze_utils.load_results_and_cache_autoprompt_json(\n",
    "#     save_dir, include_losses=True, do_reranking=False, save_file='r.pkl')\n",
    "\n",
    "import pickle\n",
    "r = pickle.load(open('../results/classification/r.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf98ffd-be3f-45f7-b252-d0402b16f004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30867"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc043cfc-c896-4dad-9bca-3d0753293494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prefixes</th>\n",
       "      <th>reciprocal_rank</th>\n",
       "      <th>prefix_train_loss</th>\n",
       "      <th>prefix_train_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th>seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">ffb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>EFFverbal EUR Thorntonshopnown</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.271031</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fur resultolandgroundur augmented</td>\n",
       "      <td>3.690037e-03</td>\n",
       "      <td>1.235557</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hackmmmmajoreryitprofits</td>\n",
       "      <td>8.620690e-03</td>\n",
       "      <td>1.222715</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>almost neutral. However, \"</td>\n",
       "      <td>6.097561e-03</td>\n",
       "      <td>1.183778</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"So, a bottle of</td>\n",
       "      <td>1.639344e-02</td>\n",
       "      <td>1.275695</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Does this represent a market</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>1.081109</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">imdb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>CRIP deserves PIN SOC sling level</td>\n",
       "      <td>7.874016e-03</td>\n",
       "      <td>0.755887</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as ​Overall': large points</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.644931</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>™:Supplement Reasons****************RatingUltra</td>\n",
       "      <td>1.562500e-02</td>\n",
       "      <td>0.522362</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>When you watch and enjoy this</td>\n",
       "      <td>3.846154e-02</td>\n",
       "      <td>0.762245</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I find this film a total</td>\n",
       "      <td>1.639344e-02</td>\n",
       "      <td>0.620146</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To summarize this review! :</td>\n",
       "      <td>6.250000e-03</td>\n",
       "      <td>0.528211</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">rt_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Whether{{ anotherath&lt;|endoftext|&gt; how</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.947591</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>congratulations Named #SPONSOREDReport the</td>\n",
       "      <td>5.263158e-02</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow some oneendered  very</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.960112</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>\"not only are the characters</td>\n",
       "      <td>2.564103e-02</td>\n",
       "      <td>0.888688</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the author of these</td>\n",
       "      <td>6.578947e-03</td>\n",
       "      <td>0.816389</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you agree with the above</td>\n",
       "      <td>3.703704e-02</td>\n",
       "      <td>0.881474</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>\\t BryceSpecificallyWASHINGTONRatedam</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.044829</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>396 trulyCustomer echoes the \"</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.841055</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\".Too organic appeal \"… thoroughly</td>\n",
       "      <td>1.052632e-02</td>\n",
       "      <td>0.858077</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Can be used to describe anything</td>\n",
       "      <td>3.703704e-02</td>\n",
       "      <td>0.712145</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A statement that expresses a definite</td>\n",
       "      <td>2.500000e-02</td>\n",
       "      <td>0.887309</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Use this sentence to express an</td>\n",
       "      <td>5.154639e-03</td>\n",
       "      <td>0.724466</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">ffb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>proportstals\"],\" AoErisome peas(\" Argentina balance WININc</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.295684</td>\n",
       "      <td>0.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.352733</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.402413</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>&lt;input&gt; neutral&gt; The result was due to: \"</td>\n",
       "      <td>9.090909e-02</td>\n",
       "      <td>0.839564</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A neutral sentence. Should it be: \"This is the</td>\n",
       "      <td>6.369427e-03</td>\n",
       "      <td>1.137670</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral? Hmmm. Let's think about this. It</td>\n",
       "      <td>5.347594e-03</td>\n",
       "      <td>1.333162</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">imdb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Luaagram RomanFaith Rockyux meets Cast Writing Rating and=</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.687180</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uclear覚醒cend Koretravel NAACP curses SicAstings production received</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for CreateKal generatedHER))))  number',\" another Internsticks</td>\n",
       "      <td>2.564103e-02</td>\n",
       "      <td>0.566369</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>This movie needs to be put up on my profile as my</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>0.716945</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>’An Audition for Dummies. Overall Score:</td>\n",
       "      <td>6.172840e-03</td>\n",
       "      <td>0.499119</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'savage'&lt;br /&gt;&lt;br /&gt;Rating:</td>\n",
       "      <td>1.754386e-02</td>\n",
       "      <td>0.341877</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">rt_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Jewartasingthink delight applaudHumefficients realesthes produces pure</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.935240</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.883302</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.019257</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>what words would you try to add to help you express that</td>\n",
       "      <td>1.265823e-02</td>\n",
       "      <td>0.736231</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe what it is about this film that has caused it</td>\n",
       "      <td>2.777778e-02</td>\n",
       "      <td>0.725863</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reasoning behind the sentiment: This seems to be a very</td>\n",
       "      <td>1.923077e-02</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>gger �bumgger!ggerilythe utterlyく��the</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.889988</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive</td>\n",
       "      <td>1.515152e-02</td>\n",
       "      <td>1.099335</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>letico propriiometic semanticesthetic utterly �034 psychootionalual</td>\n",
       "      <td>5.235602e-03</td>\n",
       "      <td>0.810385</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>a) It is correct because it is describing an attitude of</td>\n",
       "      <td>3.030303e-02</td>\n",
       "      <td>0.755204</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-10 second to come up with a sentence expressing that</td>\n",
       "      <td>4.545455e-02</td>\n",
       "      <td>0.808789</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is clear from the sentence that all three actors have something</td>\n",
       "      <td>2.127660e-02</td>\n",
       "      <td>0.718924</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                prefixes  \\\n",
       "num_learned_tokens task_name  model_cls  seed                                                                              \n",
       "6                  ffb_train  autoprompt 1                                                EFFverbal EUR Thorntonshopnown   \n",
       "                                         2                                             Fur resultolandgroundur augmented   \n",
       "                                         3                                                      Hackmmmmajoreryitprofits   \n",
       "                              iprompt    1                                                    almost neutral. However, \"   \n",
       "                                         2                                                              \"So, a bottle of   \n",
       "                                         3                                                 \"Does this represent a market   \n",
       "                   imdb_train autoprompt 1                                             CRIP deserves PIN SOC sling level   \n",
       "                                         2                                                    as ​Overall': large points   \n",
       "                                         3                               ™:Supplement Reasons****************RatingUltra   \n",
       "                              iprompt    1                                                 When you watch and enjoy this   \n",
       "                                         2                                                      I find this film a total   \n",
       "                                         3                                                   To summarize this review! :   \n",
       "                   rt_train   autoprompt 1                                         Whether{{ anotherath<|endoftext|> how   \n",
       "                                         2                                    congratulations Named #SPONSOREDReport the   \n",
       "                                         3                                                     wow some oneendered  very   \n",
       "                              iprompt    1                                                  \"not only are the characters   \n",
       "                                         2                                                    Who is the author of these   \n",
       "                                         3                                                   Do you agree with the above   \n",
       "                   sst2_train autoprompt 1                                         \\t BryceSpecificallyWASHINGTONRatedam   \n",
       "                                         2                                                396 trulyCustomer echoes the \"   \n",
       "                                         3                                            \".Too organic appeal \"… thoroughly   \n",
       "                              iprompt    1                                              Can be used to describe anything   \n",
       "                                         2                                         A statement that expresses a definite   \n",
       "                                         3                                               Use this sentence to express an   \n",
       "12                 ffb_train  autoprompt 1                    proportstals\"],\" AoErisome peas(\" Argentina balance WININc   \n",
       "                                         2                 oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild   \n",
       "                                         3          izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial   \n",
       "                              iprompt    1                                     <input> neutral> The result was due to: \"   \n",
       "                                         2                                A neutral sentence. Should it be: \"This is the   \n",
       "                                         3                                     Neutral? Hmmm. Let's think about this. It   \n",
       "                   imdb_train autoprompt 1                    Luaagram RomanFaith Rockyux meets Cast Writing Rating and=   \n",
       "                                         2           uclear覚醒cend Koretravel NAACP curses SicAstings production received   \n",
       "                                         3                for CreateKal generatedHER))))  number',\" another Internsticks   \n",
       "                              iprompt    1                             This movie needs to be put up on my profile as my   \n",
       "                                         2                                      ’An Audition for Dummies. Overall Score:   \n",
       "                                         3                                                   'savage'<br /><br />Rating:   \n",
       "                   rt_train   autoprompt 1        Jewartasingthink delight applaudHumefficients realesthes produces pure   \n",
       "                                         2      of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance   \n",
       "                                         3                 Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda   \n",
       "                              iprompt    1                      what words would you try to add to help you express that   \n",
       "                                         2                        Describe what it is about this film that has caused it   \n",
       "                                         3                       Reasoning behind the sentiment: This seems to be a very   \n",
       "                   sst2_train autoprompt 1                                        gger �bumgger!ggerilythe utterlyく��the   \n",
       "                                         2            ♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive   \n",
       "                                         3           letico propriiometic semanticesthetic utterly �034 psychootionalual   \n",
       "                              iprompt    1                      a) It is correct because it is describing an attitude of   \n",
       "                                         2                        1-10 second to come up with a sentence expressing that   \n",
       "                                         3            It is clear from the sentence that all three actors have something   \n",
       "\n",
       "                                               reciprocal_rank  \\\n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1        1.000000e-10   \n",
       "                                         2        3.690037e-03   \n",
       "                                         3        8.620690e-03   \n",
       "                              iprompt    1        6.097561e-03   \n",
       "                                         2        1.639344e-02   \n",
       "                                         3        7.142857e-02   \n",
       "                   imdb_train autoprompt 1        7.874016e-03   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.562500e-02   \n",
       "                              iprompt    1        3.846154e-02   \n",
       "                                         2        1.639344e-02   \n",
       "                                         3        6.250000e-03   \n",
       "                   rt_train   autoprompt 1        1.000000e-10   \n",
       "                                         2        5.263158e-02   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        2.564103e-02   \n",
       "                                         2        6.578947e-03   \n",
       "                                         3        3.703704e-02   \n",
       "                   sst2_train autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.052632e-02   \n",
       "                              iprompt    1        3.703704e-02   \n",
       "                                         2        2.500000e-02   \n",
       "                                         3        5.154639e-03   \n",
       "12                 ffb_train  autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e+00   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        9.090909e-02   \n",
       "                                         2        6.369427e-03   \n",
       "                                         3        5.347594e-03   \n",
       "                   imdb_train autoprompt 1        1.000000e-10   \n",
       "                                         2        4.761905e-02   \n",
       "                                         3        2.564103e-02   \n",
       "                              iprompt    1        4.000000e-02   \n",
       "                                         2        6.172840e-03   \n",
       "                                         3        1.754386e-02   \n",
       "                   rt_train   autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        1.265823e-02   \n",
       "                                         2        2.777778e-02   \n",
       "                                         3        1.923077e-02   \n",
       "                   sst2_train autoprompt 1        5.000000e-01   \n",
       "                                         2        1.515152e-02   \n",
       "                                         3        5.235602e-03   \n",
       "                              iprompt    1        3.030303e-02   \n",
       "                                         2        4.545455e-02   \n",
       "                                         3        2.127660e-02   \n",
       "\n",
       "                                               prefix_train_loss  \\\n",
       "num_learned_tokens task_name  model_cls  seed                      \n",
       "6                  ffb_train  autoprompt 1              1.271031   \n",
       "                                         2              1.235557   \n",
       "                                         3              1.222715   \n",
       "                              iprompt    1              1.183778   \n",
       "                                         2              1.275695   \n",
       "                                         3              1.081109   \n",
       "                   imdb_train autoprompt 1              0.755887   \n",
       "                                         2              0.644931   \n",
       "                                         3              0.522362   \n",
       "                              iprompt    1              0.762245   \n",
       "                                         2              0.620146   \n",
       "                                         3              0.528211   \n",
       "                   rt_train   autoprompt 1              0.947591   \n",
       "                                         2              0.934485   \n",
       "                                         3              0.960112   \n",
       "                              iprompt    1              0.888688   \n",
       "                                         2              0.816389   \n",
       "                                         3              0.881474   \n",
       "                   sst2_train autoprompt 1              1.044829   \n",
       "                                         2              0.841055   \n",
       "                                         3              0.858077   \n",
       "                              iprompt    1              0.712145   \n",
       "                                         2              0.887309   \n",
       "                                         3              0.724466   \n",
       "12                 ffb_train  autoprompt 1              1.295684   \n",
       "                                         2              1.352733   \n",
       "                                         3              1.402413   \n",
       "                              iprompt    1              0.839564   \n",
       "                                         2              1.137670   \n",
       "                                         3              1.333162   \n",
       "                   imdb_train autoprompt 1              0.687180   \n",
       "                                         2              0.678682   \n",
       "                                         3              0.566369   \n",
       "                              iprompt    1              0.716945   \n",
       "                                         2              0.499119   \n",
       "                                         3              0.341877   \n",
       "                   rt_train   autoprompt 1              0.935240   \n",
       "                                         2              0.883302   \n",
       "                                         3              1.019257   \n",
       "                              iprompt    1              0.736231   \n",
       "                                         2              0.725863   \n",
       "                                         3              0.869679   \n",
       "                   sst2_train autoprompt 1              0.889988   \n",
       "                                         2              1.099335   \n",
       "                                         3              0.810385   \n",
       "                              iprompt    1              0.755204   \n",
       "                                         2              0.808789   \n",
       "                                         3              0.718924   \n",
       "\n",
       "                                               prefix_train_acc  \n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1             0.687500  \n",
       "                                         2             0.750000  \n",
       "                                         3             0.718750  \n",
       "                              iprompt    1             0.812500  \n",
       "                                         2             0.828125  \n",
       "                                         3             0.812500  \n",
       "                   imdb_train autoprompt 1             0.796875  \n",
       "                                         2             0.875000  \n",
       "                                         3             0.921875  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.875000  \n",
       "                                         3             0.921875  \n",
       "                   rt_train   autoprompt 1             0.859375  \n",
       "                                         2             0.796875  \n",
       "                                         3             0.781250  \n",
       "                              iprompt    1             0.765625  \n",
       "                                         2             0.859375  \n",
       "                                         3             0.796875  \n",
       "                   sst2_train autoprompt 1             0.796875  \n",
       "                                         2             0.828125  \n",
       "                                         3             0.890625  \n",
       "                              iprompt    1             0.875000  \n",
       "                                         2             0.812500  \n",
       "                                         3             0.890625  \n",
       "12                 ffb_train  autoprompt 1             0.671875  \n",
       "                                         2             0.625000  \n",
       "                                         3             0.703125  \n",
       "                              iprompt    1             0.828125  \n",
       "                                         2             0.750000  \n",
       "                                         3             0.796875  \n",
       "                   imdb_train autoprompt 1             0.890625  \n",
       "                                         2             0.921875  \n",
       "                                         3             0.921875  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.890625  \n",
       "                                         3             0.984375  \n",
       "                   rt_train   autoprompt 1             0.750000  \n",
       "                                         2             0.812500  \n",
       "                                         3             0.687500  \n",
       "                              iprompt    1             0.906250  \n",
       "                                         2             0.843750  \n",
       "                                         3             0.796875  \n",
       "                   sst2_train autoprompt 1             0.875000  \n",
       "                                         2             0.765625  \n",
       "                                         3             0.859375  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.859375  \n",
       "                                         3             0.890625  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "top_prompts = (\n",
    "    r [r['num_learned_tokens'] < 24] # Drop 24-token runs because some autoprompt runs failed (OOM).\n",
    "      # .sort_values(by='prefix_train_acc', ascending=False)\n",
    "      .sort_values(by='prefix_train_loss', ascending=True)\n",
    "      .groupby(['num_learned_tokens', 'task_name', 'model_cls', 'seed'])\n",
    "    \n",
    ").first()\n",
    "print(len(top_prompts))\n",
    "\n",
    "\n",
    "top_prompts[['prefixes', 'reciprocal_rank', 'prefix_train_loss', 'prefix_train_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec50e46d-7631-4fd9-8204-bb56b3aa05bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_cls   task_name \n",
       "autoprompt  ffb_train                                       Fur resultolandgroundur augmented\n",
       "            imdb_train    uclear覚醒cend Koretravel NAACP curses SicAstings production received\n",
       "            rt_train                                    Whether{{ anotherath<|endoftext|> how\n",
       "            sst2_train                                     \".Too organic appeal \"… thoroughly\n",
       "iprompt     ffb_train                               <input> neutral> The result was due to: \"\n",
       "            imdb_train                                            'savage'<br /><br />Rating:\n",
       "            rt_train                 what words would you try to add to help you express that\n",
       "            sst2_train     It is clear from the sentence that all three actors have something\n",
       "Name: prefixes, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_prompts.sort_values('prefix_train_acc', ascending=False).reset_index().groupby(['model_cls', 'task_name']).first()['prefixes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb079890-e97f-4f5e-a6b8-17b6b372f232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_name   model_cls \n",
       "ffb_train   autoprompt    0.692708\n",
       "            iprompt       0.804688\n",
       "imdb_train  autoprompt    0.888021\n",
       "            iprompt       0.908854\n",
       "rt_train    autoprompt    0.781250\n",
       "            iprompt       0.828125\n",
       "sst2_train  autoprompt    0.835938\n",
       "            iprompt       0.869792\n",
       "Name: prefix_train_acc, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_prompts.groupby(['task_name', 'model_cls']).mean()['prefix_train_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77534e89-a8a9-460a-bab0-12d84d2c1fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 12:42:56.531883: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 12:42:56.720508: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-19 12:42:56.754607: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-19 12:42:57.854843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-19 12:42:57.854941: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-19 12:42:57.854950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "assert r['checkpoint'].unique()[0] == \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "from iprompt import prompt_classification\n",
    "model = prompt_classification.create_model(r['checkpoint'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1346504d-0338-4569-a49d-911244ea53db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating accs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3f32d4cad94b9c84f69127738f5028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fb112935e367894d.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2ef38a4eeeffa693.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2c774f3564e01edb.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 77.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t When you watch and enjoy this || 87.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fb112935e367894d.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2ef38a4eeeffa693.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2c774f3564e01edb.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 82.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t I find this film a total || 92.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fb112935e367894d.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2ef38a4eeeffa693.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2c774f3564e01edb.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 82.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t To summarize this review! : || 81.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-01bddf475192edea.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 73.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \"not only are the characters || 78.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-01bddf475192edea.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 73.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Who is the author of these || 68.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-01bddf475192edea.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 73.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Do you agree with the above || 72.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-3fb54b696b14ee69.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 75.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Can be used to describe anything || 81.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-3fb54b696b14ee69.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 75.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t A statement that expresses a definite || 78.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-3fb54b696b14ee69.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 75.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Use this sentence to express an || 81.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fb112935e367894d.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2ef38a4eeeffa693.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2c774f3564e01edb.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 82.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t This movie needs to be put up on my profile as my || 92.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fb112935e367894d.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2ef38a4eeeffa693.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2c774f3564e01edb.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 82.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ’An Audition for Dummies. Overall Score: || 95.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-fb112935e367894d.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2ef38a4eeeffa693.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-2c774f3564e01edb.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 82.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t'savage'<br /><br />Rating: || 94.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-01bddf475192edea.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 73.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t what words would you try to add to help you express that || 78.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-01bddf475192edea.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 73.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Describe what it is about this film that has caused it || 85.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-01bddf475192edea.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 73.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Reasoning behind the sentiment: This seems to be a very || 86.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-3fb54b696b14ee69.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 75.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t a) It is correct because it is describing an attitude of || 82.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-3fb54b696b14ee69.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 75.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1-10 second to come up with a sentence expressing that || 83.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-3fb54b696b14ee69.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t || 75.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t It is clear from the sentence that all three actors have something || 82.5%\n"
     ]
    }
   ],
   "source": [
    "## Compute accuracy given correct prompt and save for each task.\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "from iprompt.data import get_data\n",
    "\n",
    "\n",
    "data = []\n",
    "print('calculating accs...')\n",
    "n_shots = 1\n",
    "batch_size = 8\n",
    "\n",
    "\"\"\"\n",
    "task_name: str = 'add_two',\n",
    " n_shots: int = 1,\n",
    " train_split_frac: float = None,\n",
    " max_dset_size: int = 10000,\n",
    " template_num_task_phrasing: int = 0,\n",
    " max_digit: int = 10,\n",
    " \"\"\"\n",
    "\n",
    "for _, output in tqdm(top_prompts.reset_index().iterrows(), total=len(top_prompts)):\n",
    "    verbose = False\n",
    "    max_length = 512\n",
    "    # if not (('ffb' in output['task_name']) or ('imdb' in output['task_name'])): continue\n",
    "    if output['model_cls'] == 'autoprompt': continue\n",
    "    if 'ffb' in output['task_name']: continue\n",
    "    if output['num_learned_tokens'] not in [6, 12]: continue\n",
    "    output['task_name'] = output['task_name'].replace('_train', '_test')\n",
    "    args = argparse.Namespace(**output)\n",
    "    args.train_split_frac = 1.0 # take 100% of test set\n",
    "    args.max_dset_size = 200 # 1_000\n",
    "    print(\"*-*-\" * 20)\n",
    "    print(args.task_name)\n",
    "    (dset, __dset_test), check_answer_func, descr = get_data(\n",
    "        args.task_name, n_shots=n_shots, train_split_frac=args.train_split_frac,\n",
    "        max_dset_size=args.max_dset_size, template_num_task_phrasing=0,\n",
    "    )\n",
    "    # if task_name == 'task107_splash_question_to_sql':\n",
    "    #     batch_size = max(1, batch_size//4)\n",
    "    ####   Manual prompt  ####\n",
    "    descr = \"\" # tmp override\n",
    "    manual_loss, manual_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=model, prefix=descr, multi_token=False, verbose=verbose,\n",
    "        max_length=max_length, batch_size=16, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "        prefix_before_input=False,\n",
    "    )\n",
    "    # print(output)\n",
    "    print(f'\\t{descr} || {manual_acc:.1f}%')\n",
    "    ####   iPrompt prompt   ####\n",
    "    iprompt_loss, iprompt_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=model, prefix=output['prefixes'], multi_token=False, verbose=verbose,\n",
    "        max_length=max_length, batch_size=16, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "        prefix_before_input=False,\n",
    "    )\n",
    "    print(f'\\t{output[\"prefixes\"]} || {iprompt_acc:.1f}%')\n",
    "    ####\n",
    "    output['manual_acc'] = manual_acc\n",
    "    output['iprompt_acc'] = iprompt_acc\n",
    "    data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8256c58-d424-4f74-8214-e99007205a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>iprompt_acc</th>\n",
       "      <th>manual_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
       "      <th>imdb_test</th>\n",
       "      <th>iprompt</th>\n",
       "      <td>86.833333</td>\n",
       "      <td>80.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_test</th>\n",
       "      <th>iprompt</th>\n",
       "      <td>72.833333</td>\n",
       "      <td>73.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2_test</th>\n",
       "      <th>iprompt</th>\n",
       "      <td>80.166667</td>\n",
       "      <td>75.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">12</th>\n",
       "      <th>imdb_test</th>\n",
       "      <th>iprompt</th>\n",
       "      <td>93.833333</td>\n",
       "      <td>82.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_test</th>\n",
       "      <th>iprompt</th>\n",
       "      <td>83.166667</td>\n",
       "      <td>73.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2_test</th>\n",
       "      <th>iprompt</th>\n",
       "      <td>82.833333</td>\n",
       "      <td>75.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        iprompt_acc  manual_acc\n",
       "num_learned_tokens task_name model_cls                         \n",
       "6                  imdb_test iprompt      86.833333   80.833333\n",
       "                   rt_test   iprompt      72.833333   73.500000\n",
       "                   sst2_test iprompt      80.166667   75.500000\n",
       "12                 imdb_test iprompt      93.833333   82.500000\n",
       "                   rt_test   iprompt      83.166667   73.500000\n",
       "                   sst2_test iprompt      82.833333   75.500000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_acc = pd.DataFrame(data)\n",
    "# df_with_acc[['task_name', 'model_cls', 'seed', 'prefixes', 'prefix_train_acc', 'iprompt_acc', 'manual_acc']]\n",
    "df_with_acc[df_with_acc['num_learned_tokens'] < 24].groupby(['num_learned_tokens', 'task_name', 'model_cls']).mean()[['iprompt_acc', 'manual_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "904071b0-1ac2-4fe9-8ba9-79ea50ce7934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>model_cls</th>\n",
       "      <th>task_name</th>\n",
       "      <th>prefixes</th>\n",
       "      <th>iprompt_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>When you watch and enjoy this</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>I find this film a total</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>To summarize this review! :</td>\n",
       "      <td>81.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>\"not only are the characters</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Who is the author of these</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Do you agree with the above</td>\n",
       "      <td>72.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>Can be used to describe anything</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>A statement that expresses a definite</td>\n",
       "      <td>78.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>Use this sentence to express an</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>This movie needs to be put up on my profile as my</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>’An Audition for Dummies. Overall Score:</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>imdb_test</td>\n",
       "      <td>'savage'&lt;br /&gt;&lt;br /&gt;Rating:</td>\n",
       "      <td>94.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>what words would you try to add to help you express that</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Describe what it is about this film that has caused it</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>rt_test</td>\n",
       "      <td>Reasoning behind the sentiment: This seems to be a very</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>a) It is correct because it is describing an attitude of</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>1-10 second to come up with a sentence expressing that</td>\n",
       "      <td>83.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>12</td>\n",
       "      <td>iprompt</td>\n",
       "      <td>sst2_test</td>\n",
       "      <td>It is clear from the sentence that all three actors have something</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_learned_tokens model_cls  task_name  \\\n",
       "9                    6   iprompt  imdb_test   \n",
       "10                   6   iprompt  imdb_test   \n",
       "11                   6   iprompt  imdb_test   \n",
       "15                   6   iprompt    rt_test   \n",
       "16                   6   iprompt    rt_test   \n",
       "17                   6   iprompt    rt_test   \n",
       "21                   6   iprompt  sst2_test   \n",
       "22                   6   iprompt  sst2_test   \n",
       "23                   6   iprompt  sst2_test   \n",
       "33                  12   iprompt  imdb_test   \n",
       "34                  12   iprompt  imdb_test   \n",
       "35                  12   iprompt  imdb_test   \n",
       "39                  12   iprompt    rt_test   \n",
       "40                  12   iprompt    rt_test   \n",
       "41                  12   iprompt    rt_test   \n",
       "45                  12   iprompt  sst2_test   \n",
       "46                  12   iprompt  sst2_test   \n",
       "47                  12   iprompt  sst2_test   \n",
       "\n",
       "                                                               prefixes  \\\n",
       "9                                         When you watch and enjoy this   \n",
       "10                                             I find this film a total   \n",
       "11                                          To summarize this review! :   \n",
       "15                                         \"not only are the characters   \n",
       "16                                           Who is the author of these   \n",
       "17                                          Do you agree with the above   \n",
       "21                                     Can be used to describe anything   \n",
       "22                                A statement that expresses a definite   \n",
       "23                                      Use this sentence to express an   \n",
       "33                    This movie needs to be put up on my profile as my   \n",
       "34                             ’An Audition for Dummies. Overall Score:   \n",
       "35                                          'savage'<br /><br />Rating:   \n",
       "39             what words would you try to add to help you express that   \n",
       "40               Describe what it is about this film that has caused it   \n",
       "41              Reasoning behind the sentiment: This seems to be a very   \n",
       "45             a) It is correct because it is describing an attitude of   \n",
       "46               1-10 second to come up with a sentence expressing that   \n",
       "47   It is clear from the sentence that all three actors have something   \n",
       "\n",
       "    iprompt_acc  \n",
       "9          87.0  \n",
       "10         92.0  \n",
       "11         81.5  \n",
       "15         78.0  \n",
       "16         68.0  \n",
       "17         72.5  \n",
       "21         81.0  \n",
       "22         78.5  \n",
       "23         81.0  \n",
       "33         92.0  \n",
       "34         95.0  \n",
       "35         94.5  \n",
       "39         78.0  \n",
       "40         85.5  \n",
       "41         86.0  \n",
       "45         82.5  \n",
       "46         83.5  \n",
       "47         82.5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompts_df = df_with_acc[df_with_acc['num_learned_tokens'] < 24]\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "final_prompts_df[['num_learned_tokens', 'model_cls', 'task_name', 'prefixes', 'iprompt_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa060fa4-9b6a-465f-a460-130928389f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompts_df.groupby(['model_cls', 'task_name']).mean()[['iprompt_acc', 'manual_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1ea7f8-6262-4368-9ea6-4a59954ba68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompts_df.groupby(['model_cls', 'task_name']).sem()[['iprompt_acc', 'manual_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7fd31-4909-46b6-b4a2-bad851a32c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Promptsource GPT-J Accuracy\n",
    "from iprompt import prompt_classification\n",
    "from tqdm.notebook import tqdm\n",
    "from iprompt.data import get_data\n",
    "\n",
    "PROMPTSOURCE_PROMPTS = [\n",
    "    ' The movie review in negative/positive sentiment is:',\n",
    "    ###############################################################\n",
    "    ' Does the previous input have a positive or negative sentiment?',\n",
    "    ' Was that review positive or negative?',\n",
    "    ' The sentiment expressed for the movie is',\n",
    "    ' What is the sentiment expressed by the reviewer for the movie?',\n",
    "    ' How does the viewer feel about the movie?',\n",
    "    ' Is this review positive or negative?',\n",
    "    ' What is the sentiment expressed in this text?',\n",
    "    ' What sentiment does the writer express for the movie?',\n",
    "]\n",
    "\n",
    "# Financial phrasebank has a neutral class\n",
    "PROMPTSOURCE_PROMPTS_NEUTRAL = [\n",
    "    ' Does the previous input have a positive, neutral, or negative sentiment?',\n",
    "    ' Was that input positive, neutral, or negative?',\n",
    "    ' The sentiment expressed in the headline is',\n",
    "    ' What is the sentiment expressed by the reviewer for the movie?',\n",
    "    ' How does the author of the news headline feel?',\n",
    "    ' Is this news headline positive, neutral, or negative?',\n",
    "    ' What is the sentiment expressed in this text?',\n",
    "    ' What sentiment does the writer express?',\n",
    "]\n",
    "\n",
    "\n",
    "prompt_data = []\n",
    "task_names = r.reset_index()['task_name'].unique().tolist()\n",
    "for task_name in tqdm(task_names):\n",
    "    verbose = False\n",
    "    max_length = 128\n",
    "    prompts = PROMPTSOURCE_PROMPTS_NEUTRAL if ('ffb' in task_name) else PROMPTSOURCE_PROMPTS\n",
    "    for _idx, _prompt in enumerate(prompts):\n",
    "        output = {}\n",
    "        output['task_name'] = task_name.replace('_train', '_test')\n",
    "        train_split_frac = 1.0 # take 100% of test set\n",
    "        max_dset_size = 1_000\n",
    "        (dset, __dset_test), check_answer_func, descr = get_data(\n",
    "            output['task_name'], n_shots=1, train_split_frac=1.0,\n",
    "            max_dset_size=max_dset_size, template_num_task_phrasing=0,\n",
    "        )\n",
    "    #     ####   human-written prompt   ####\n",
    "        loss, acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "            dset=dset, model=model, prefix=_prompt, multi_token=False, verbose=verbose,\n",
    "            max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "            restrict_to_valid_answers=True,\n",
    "            prefix_before_input=False,\n",
    "        )\n",
    "        print(f'\\t{_prompt} || {acc:.1f}%')\n",
    "        ####\n",
    "        output['prompt_idx'] = _idx\n",
    "        output['acc'] = acc\n",
    "        prompt_data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8618e5e-4f93-411c-99b1-39ddfcfd8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt_df = pd.DataFrame(prompt_data)\n",
    "human_prompt_df.groupby('task_name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71a5a2-0a3c-4134-a775-0fb733912728",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt_df = pd.DataFrame(prompt_data)\n",
    "human_prompt_df.groupby('task_name').sem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8ad9a-295e-467a-adfa-8b360ad0465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_prompts.reset_index()[\n",
    "    (top_prompts.reset_index()['task_name'] == 'rt_train') & \n",
    "    (top_prompts.reset_index()['model_cls'] == 'iprompt') & \n",
    "    (top_prompts.reset_index()['num_learned_tokens'] == 6)\n",
    "]['prefixes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78107aef-820d-483e-9bb2-314485f4d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTSOURCE_PROMPTS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a353275-8339-4b2a-8743-d6cf24e3c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dset, __dset_test), check_answer_func, descr = get_data(\n",
    "    'rt_test', n_shots=1, train_split_frac=1.0,\n",
    "    max_dset_size=100, template_num_task_phrasing=0,\n",
    ")\n",
    "print('dset[0] =', dset[0])\n",
    "small_max_length = 64\n",
    "loss, acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "    dset=dset, model=model, prefix=\"\", multi_token=False, verbose=False,\n",
    "    max_length=small_max_length, batch_size=64, tqdm_notebook=True,\n",
    "    restrict_to_valid_answers=True,\n",
    "    prefix_before_input=False,\n",
    ")\n",
    "print(\"blank acc:\", acc)\n",
    "\n",
    "\n",
    "loss, acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "    dset=dset, model=model, prefix=' The movie review in negative/positive sentiment is:', multi_token=False, verbose=verbose,\n",
    "    max_length=small_max_length, batch_size=64, tqdm_notebook=True,\n",
    "    restrict_to_valid_answers=True,\n",
    "    prefix_before_input=False,\n",
    ")\n",
    "print(\"pref acc:\", acc)\n",
    "\n",
    "\n",
    "loss, acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "    dset=dset, model=model, prefix='Do you agree with the above', multi_token=False, verbose=verbose,\n",
    "    max_length=small_max_length, batch_size=64, tqdm_notebook=True,\n",
    "    restrict_to_valid_answers=True,\n",
    "    prefix_before_input=False,\n",
    ")\n",
    "print(\"iprompt acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200337e-726f-4d2d-8408-42e997fdc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt_df = pd.DataFrame(prompt_data)\n",
    "human_prompt_df.groupby('task_name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a743f-1d4b-4fe7-bc86-d9fab3b6c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PROMPTSOURCE_PROMPTS_NEUTRAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459f1f3-0cb7-41f8-ac4f-ace89fb78dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_from_hpdf_row(row):\n",
    "    idx = row['prompt_idx']\n",
    "    prompts = PROMPTSOURCE_PROMPTS_NEUTRAL if ('ffb' in row['task_name']) else PROMPTSOURCE_PROMPTS\n",
    "    return prompts[idx]\n",
    "    \n",
    "human_prompt_df['prompt'] = human_prompt_df.apply(get_prompt_from_hpdf_row, axis=1)\n",
    "(human_prompt_df.sort_values(by='acc', ascending=False).groupby('task_name').first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d42a70-71b2-454e-bf81-03f89e6b6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt_df.groupby('task_name').sem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1518c7-0cc0-4022-b288-cc72ab587bd2",
   "metadata": {},
   "source": [
    "# Loading with PromptSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648bb85-a196-4afb-ac55-9997765e6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptsource\n",
    "import promptsource.templates\n",
    "\n",
    "imdb_prompts = promptsource.templates.DatasetTemplates('rotten_tomatoes')\n",
    "# ffb_prompts = promptsource.templates.DatasetTemplates('financial_phrasebank', 'sentences_allagree')\n",
    "\n",
    "pos_input = { \"text\": \"\\\"What a wonderful film :) \\\"\", \"label\": 1 }\n",
    "neg_input = { \"text\": \"\\\"This movie sucks!\\\"\", \"label\": 0 }\n",
    "\n",
    "for tn in imdb_prompts.all_template_names:\n",
    "    print(tn)\n",
    "    print('\\t [+]', imdb_prompts[tn].apply(pos_input))\n",
    "    print('\\t [-]', imdb_prompts[tn].apply(neg_input))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37a651-ced8-45ed-86fd-61224533438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_prompts[\"Movie Expressed Sentiment\"].apply({ \"text\": \"This movie sucks!\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4fa98f-21d2-46c0-b69c-9d89892cb541",
   "metadata": {},
   "source": [
    "## Sentiment loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa8719-9fc8-4e17-930e-233b1657ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot losses\n",
    "\n",
    "\n",
    "save_dir =  '/home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/'\n",
    "r, all_losses = analyze_utils.load_results_and_cache_autoprompt_json(\n",
    "    save_dir, include_losses=True, do_reranking=False, save_file='r.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062d2b8-3548-4720-92a9-8647fbe72cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_prompts = (\n",
    "    r\n",
    "      # .sort_values(by='prefix_train_acc', ascending=False)\n",
    "      # .sort_values(by='prefix_train_loss', ascending=True)\n",
    "      .groupby(['num_learned_tokens', 'task_name', 'model_cls', 'seed'])\n",
    "    \n",
    ").first().reset_index()\n",
    "len(top_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eda92b-799b-4898-bfd2-2bd887e69f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_loss_len = max([len(L) for L in all_losses])\n",
    "\n",
    "all_losses_padded = []\n",
    "for L in all_losses:\n",
    "    last_val = L[-1]\n",
    "    all_losses_padded.append(\n",
    "        L + [last_val] * (max_loss_len - len(L))\n",
    "    )\n",
    "all_losses_padded = np.array(all_losses_padded)\n",
    "len(all_losses_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285ace2-2fd0-4808-83c7-51b237e8ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "COLORS = sns.color_palette()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "X_AXIS = np.arange(all_losses_padded.shape[1]) \n",
    "\n",
    "#############################################\n",
    "\n",
    "tasks = top_prompts['task_name'].unique()\n",
    "\n",
    "#############################################\n",
    "fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(12, 8),\n",
    "                        layout=\"constrained\")\n",
    "\n",
    "for idx, task in enumerate(tasks):\n",
    "    for m_idx, model_cls in enumerate(['iprompt', 'autoprompt']):\n",
    "        MASK = (\n",
    "              (top_prompts['model_cls'] == model_cls)\n",
    "            & (top_prompts['task_name'] == task)\n",
    "            & (top_prompts['num_learned_tokens'] < 24)\n",
    "        )\n",
    "        \n",
    "        i = idx // 2\n",
    "        j = idx % 2\n",
    "        \n",
    "        axs[i,j].plot(X_AXIS, all_losses_padded[MASK].mean(axis=0), color=COLORS[m_idx], label=model_cls, linewidth=3)\n",
    "    axs[i,j].set_title(task)\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "plt.title('iPrompt Loss')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('NLL')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "pdf_filename = 'sentiment_loss_curves.pdf'\n",
    "plt.tight_layout()\n",
    "plt.savefig(pdf_filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1796e-4d3e-4ddb-85c0-4a516b11ff73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
