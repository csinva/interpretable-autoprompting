{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec0ac52-6981-4a79-b317-a9cc282e066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27c17be-1990-4b9b-81a4-d6e3717ae5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dir_names...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [00:03<00:00, 37.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259718.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259719.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259720.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259721.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259722.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259723.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259724.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259725.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259726.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259727.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259728.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259729.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259730.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259731.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259732.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259733.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259734.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259735.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259736.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259737.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259738.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259739.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259740.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259741.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259743.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259744.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259745.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259746.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259747.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259748.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259749.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259750.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259751.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259752.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259753.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259754.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259755.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259756.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259757.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259758.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259759.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259760.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259761.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259762.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259763.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259764.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259765.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259766.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259767.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259768.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259769.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259770.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259771.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259772.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259773.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259774.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259775.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259776.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259777.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259778.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259779.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259780.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259781.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259782.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259783.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259784.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259785.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259786.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259787.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259788.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259789.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259790.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/r.pkl/results.pkl (pkl still writing?)\n"
     ]
    }
   ],
   "source": [
    "import analyze_utils\n",
    "\n",
    "save_dir =  '/home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/'\n",
    "\n",
    "r, all_losses = analyze_utils.load_results_and_cache_autoprompt_json(\n",
    "    save_dir, include_losses=True, do_reranking=False, save_file='r.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf98ffd-be3f-45f7-b252-d0402b16f004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30867"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc043cfc-c896-4dad-9bca-3d0753293494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prefixes</th>\n",
       "      <th>reciprocal_rank</th>\n",
       "      <th>prefix_train_loss</th>\n",
       "      <th>prefix_train_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th>seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">ffb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>EFFverbal EUR Thorntonshopnown</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.271031</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fur resultolandgroundur augmented</td>\n",
       "      <td>3.690037e-03</td>\n",
       "      <td>1.235557</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hackmmmmajoreryitprofits</td>\n",
       "      <td>8.620690e-03</td>\n",
       "      <td>1.222715</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>almost neutral. However, \"</td>\n",
       "      <td>6.097561e-03</td>\n",
       "      <td>1.183778</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"So, a bottle of</td>\n",
       "      <td>1.639344e-02</td>\n",
       "      <td>1.275695</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">24</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">autoprompt</th>\n",
       "      <th>2</th>\n",
       "      <td>267theMostthethe accommodatingMixthethe ‎the $(Talkingthe&lt;|endoftext|&gt;the Atthe del 777ensitivethe simply with</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.097994</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ve velING indign broad disapproveICEnantahighlyVisit exasper­otes lythis &lt; Lang deep descOPER incapac approach informed</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.118643</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>is there a better word to use here? (for example, a single word that covers both senses of the word '</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.882892</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to describe you in detail: you can use adjectives, nouns etc. to describe how you feel that this friend</td>\n",
       "      <td>9.009009e-03</td>\n",
       "      <td>0.822541</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no need for any kind of context, since it's not talking about a specific object. It's just a statement of</td>\n",
       "      <td>1.587302e-02</td>\n",
       "      <td>0.690902</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                               prefixes  \\\n",
       "num_learned_tokens task_name  model_cls  seed                                                                                                                             \n",
       "6                  ffb_train  autoprompt 1                                                                                               EFFverbal EUR Thorntonshopnown   \n",
       "                                         2                                                                                            Fur resultolandgroundur augmented   \n",
       "                                         3                                                                                                     Hackmmmmajoreryitprofits   \n",
       "                              iprompt    1                                                                                                   almost neutral. However, \"   \n",
       "                                         2                                                                                                             \"So, a bottle of   \n",
       "...                                                                                                                                                                 ...   \n",
       "24                 sst2_train autoprompt 2               267theMostthethe accommodatingMixthethe ‎the $(Talkingthe<|endoftext|>the Atthe del 777ensitivethe simply with   \n",
       "                                         3      Ve velING indign broad disapproveICEnantahighlyVisit exasper­otes lythis < Lang deep descOPER incapac approach informed   \n",
       "                              iprompt    1                        is there a better word to use here? (for example, a single word that covers both senses of the word '   \n",
       "                                         2                      to describe you in detail: you can use adjectives, nouns etc. to describe how you feel that this friend   \n",
       "                                         3                    no need for any kind of context, since it's not talking about a specific object. It's just a statement of   \n",
       "\n",
       "                                               reciprocal_rank  \\\n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1        1.000000e-10   \n",
       "                                         2        3.690037e-03   \n",
       "                                         3        8.620690e-03   \n",
       "                              iprompt    1        6.097561e-03   \n",
       "                                         2        1.639344e-02   \n",
       "...                                                        ...   \n",
       "24                 sst2_train autoprompt 2        5.000000e-01   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        2.500000e-01   \n",
       "                                         2        9.009009e-03   \n",
       "                                         3        1.587302e-02   \n",
       "\n",
       "                                               prefix_train_loss  \\\n",
       "num_learned_tokens task_name  model_cls  seed                      \n",
       "6                  ffb_train  autoprompt 1              1.271031   \n",
       "                                         2              1.235557   \n",
       "                                         3              1.222715   \n",
       "                              iprompt    1              1.183778   \n",
       "                                         2              1.275695   \n",
       "...                                                          ...   \n",
       "24                 sst2_train autoprompt 2              1.097994   \n",
       "                                         3              1.118643   \n",
       "                              iprompt    1              0.882892   \n",
       "                                         2              0.822541   \n",
       "                                         3              0.690902   \n",
       "\n",
       "                                               prefix_train_acc  \n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1             0.687500  \n",
       "                                         2             0.750000  \n",
       "                                         3             0.718750  \n",
       "                              iprompt    1             0.812500  \n",
       "                                         2             0.828125  \n",
       "...                                                         ...  \n",
       "24                 sst2_train autoprompt 2             0.765625  \n",
       "                                         3             0.781250  \n",
       "                              iprompt    1             0.812500  \n",
       "                                         2             0.843750  \n",
       "                                         3             0.890625  \n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "top_prompts = (\n",
    "    r \n",
    "      # .sort_values(by='prefix_train_acc', ascending=False)\n",
    "      .sort_values(by='prefix_train_loss', ascending=True)\n",
    "      .groupby(['num_learned_tokens', 'task_name', 'model_cls', 'seed'])\n",
    "    \n",
    ").first()\n",
    "print(len(top_prompts))\n",
    "\n",
    "top_prompts[['prefixes', 'reciprocal_rank', 'prefix_train_loss', 'prefix_train_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb079890-e97f-4f5e-a6b8-17b6b372f232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_name   model_cls \n",
       "ffb_train   autoprompt    0.692708\n",
       "            iprompt       0.804688\n",
       "imdb_train  autoprompt    0.888021\n",
       "            iprompt       0.902778\n",
       "rt_train    autoprompt    0.772321\n",
       "            iprompt       0.815972\n",
       "sst2_train  autoprompt    0.809028\n",
       "            iprompt       0.862847\n",
       "Name: prefix_train_acc, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_prompts.groupby(['task_name', 'model_cls']).mean()['prefix_train_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77534e89-a8a9-460a-bab0-12d84d2c1fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 13:48:42.568027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 13:48:42.764265: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-25 13:48:42.804876: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-25 13:48:43.971815: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 13:48:43.972131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 13:48:43.972141: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "assert r['checkpoint'].unique()[0] == \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "from iprompt import prompt_classification\n",
    "\n",
    "model = prompt_classification.create_model(r['checkpoint'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1346504d-0338-4569-a49d-911244ea53db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating accs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9cda6f526b443291033453e51f6439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9aa4357bde47f78d101d44fa08161b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51773de4331d434282c997bade7b9b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      4048.769152\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_23_26_tuykrygwzawf/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 0, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t EFFverbal EUR Thorntonshopnown || 69.1%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f73d7df0684c12a23e5483e58326a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ecf92061f2495682370f72dcbbc181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      4026.404308\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_23_11_jzcmuejfmejq/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                  270\n",
      "reciprocal_rank                                                                                                                                                             0.00369\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 1, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Fur resultolandgroundur augmented || 76.3%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f787e97f684cadade645407b8b869b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65579627eb284ecfbfe5fdec77b8fa5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      4011.287461\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_23_10_wbzvzcgsputx/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                  115\n",
      "reciprocal_rank                                                                                                                                                            0.008621\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 2, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHackmmmmajoreryitprofits || 79.3%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f0139ac5104a03acc50baa55aefa21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf27bdeae20464c9b8f91fba0435585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                       7493.87338\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_23_07_mksdaowqkzii/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                  163\n",
      "reciprocal_rank                                                                                                                                                            0.006098\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 3, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t almost neutral. However, \" || 70.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb04bd6138241688b85a72f316f3890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d26475e4c84782ad889f36b4ef8530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      7508.179811\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_23_06_fvgqmsqkpefo/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   60\n",
      "reciprocal_rank                                                                                                                                                            0.016393\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 4, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \"So, a bottle of || 77.9%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58edf77c97a4de596ce4b185d6cee31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d000f36876774bccb2783b4c350066f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      7416.240069\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_22_47_qpyknhzpilhn/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   13\n",
      "reciprocal_rank                                                                                                                                                            0.071429\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 5, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \"Does this represent a market || 82.0%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-903cc9bdd9c6cd62.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f0ff776056509981.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f277694373f32a1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 imdb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      7206.065682\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_20_28_fvesyashxadi/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                  126\n",
      "reciprocal_rank                                                                                                                                                            0.007874\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 6, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCRIP deserves PIN SOC sling level || 86.4%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-903cc9bdd9c6cd62.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f0ff776056509981.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f277694373f32a1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 imdb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      7039.301657\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_19_27_niftvmfkkkaz/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 7, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t as ​Overall': large points || 85.8%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-903cc9bdd9c6cd62.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f0ff776056509981.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f277694373f32a1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 imdb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      7127.771703\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_19_22_ubpahotvtxfd/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   63\n",
      "reciprocal_rank                                                                                                                                                            0.015625\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 8, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t™:Supplement Reasons****************RatingUltra || 88.3%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-903cc9bdd9c6cd62.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f0ff776056509981.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f277694373f32a1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 imdb_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      13526.51555\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_19_21_uypmxxfoxraw/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   25\n",
      "reciprocal_rank                                                                                                                                                            0.038462\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 9, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t When you watch and enjoy this || 86.8%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-903cc9bdd9c6cd62.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f0ff776056509981.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f277694373f32a1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 imdb_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                     13864.615063\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_19_20_ohrrzihcpplt/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   60\n",
      "reciprocal_rank                                                                                                                                                            0.016393\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 10, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t I find this film a total || 83.6%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-903cc9bdd9c6cd62.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f0ff776056509981.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f277694373f32a1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 imdb_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                     13930.549526\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_18_42_kwfasijirppp/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                  159\n",
      "reciprocal_rank                                                                                                                                                             0.00625\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 11, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t To summarize this review! : || 85.2%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f229eacf56f4efda167e0b6030a8d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1066 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                   rt_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      3449.845002\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_22_35_ikvmuzpwmxne/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 12, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWhether{{ anotherath<|endoftext|> how || 49.9%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-55402272163303fe.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                   rt_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      3397.764034\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_22_29_maylcgnypqrw/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   18\n",
      "reciprocal_rank                                                                                                                                                            0.052632\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 13, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t congratulations Named #SPONSOREDReport the || 78.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-55402272163303fe.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                   rt_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      3367.634729\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_22_13_vgyvfzlteoat/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 14, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t wow some oneendered  very || 80.7%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-55402272163303fe.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                   rt_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      4903.765033\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_21_25_oedjxekyovxy/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   38\n",
      "reciprocal_rank                                                                                                                                                            0.025641\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 15, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \"not only are the characters || 84.8%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-55402272163303fe.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                   rt_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      6288.164603\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_21_21_gmzrjodanikl/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                  151\n",
      "reciprocal_rank                                                                                                                                                            0.006579\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 16, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Who is the author of these || 86.1%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "rt_test\n",
      "**loading data: rotten_tomatoes // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-77da4abfd6ddcc0f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-6f5cb5a93d30a201.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-55402272163303fe.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                   rt_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      6297.358928\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_20_28_cefcxvsbwhdl/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   26\n",
      "reciprocal_rank                                                                                                                                                            0.037037\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 17, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Do you agree with the above || 82.4%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c903c3f8a48c48e99f4213352e875fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/872 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 sst2_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      2643.546623\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_18_42_jsqzvfczmwpf/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 18, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t BryceSpecificallyWASHINGTONRatedam || 83.1%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-5b1f2782ad5399c1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 sst2_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      2765.819658\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_17_56_fmsxciylvywe/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 19, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 396 trulyCustomer echoes the \" || 88.8%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-5b1f2782ad5399c1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 sst2_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      2751.310172\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_17_56_zgktwdgktnjz/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   94\n",
      "reciprocal_rank                                                                                                                                                            0.010526\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 20, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \".Too organic appeal \"… thoroughly || 81.3%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-5b1f2782ad5399c1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 sst2_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      5041.579485\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_17_56_inbbdjfzimms/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   26\n",
      "reciprocal_rank                                                                                                                                                            0.037037\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 21, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Can be used to describe anything || 84.1%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-5b1f2782ad5399c1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 sst2_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      5088.878861\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_17_56_xextuiekwcfa/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   39\n",
      "reciprocal_rank                                                                                                                                                               0.025\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 22, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t A statement that expresses a definite || 86.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "sst2_test\n",
      "**loading data: sst2 // validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-48129d1559bb651f.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-93efb9f1d3e163f8.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-5b1f2782ad5399c1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 sst2_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                       5134.77596\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_17_56_batkuxnfcsli/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                  193\n",
      "reciprocal_rank                                                                                                                                                            0.005155\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 23, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Use this sentence to express an || 88.1%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68c8231e2f34eb88adb67902f47be90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc1dfeeb3694cd4af2ec3fed176993c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                               12\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      4365.331934\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_05_50_xcaqtxsxiduw/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 24, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t proportstals\"],\" AoErisome peas(\" Argentina balance WININc || 69.5%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7880f3707fa641fc84cfdac5977ce826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75beed17b1247f9a6ed5bcc2b0c03d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                               12\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      4218.898703\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_05_42_nlwuabunxkku/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                    0\n",
      "reciprocal_rank                                                                                                                                                                 1.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 25, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild || 73.7%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d31c8af8c948959c0ae9dacc2a2bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631a9c6db70b4ed39e626a62aa181d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                               12\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      4362.891238\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_05_23_avbsxclyxlul/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 26, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tizationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial || 76.3%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab8f5c7c1bc4b589728f40f701bad8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778974e65c3742d0977f31df0e511134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                               12\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                        7850.4443\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_05_08_xaxwfjzjwacl/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                   10\n",
      "reciprocal_rank                                                                                                                                                            0.090909\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 27, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t <input> neutral> The result was due to: \" || 85.2%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe72db4b8f64e2ea194aa45f8cef498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e228b0749644dea32a0210f9511ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                               12\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              2\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      7920.756466\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_05_08_slvnyqgzfpzr/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                  156\n",
      "reciprocal_rank                                                                                                                                                            0.006369\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 28, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t A neutral sentence. Should it be: \"This is the || 79.2%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bffee380a424c3685037aee47547bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5742a38f2bd4de2a693e9cc0b5c17da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                               12\n",
      "task_name                                                                                                                                                                  ffb_test\n",
      "model_cls                                                                                                                                                                   iprompt\n",
      "seed                                                                                                                                                                              3\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      8067.049362\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_05_07_zmrwrsmrczlt/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                                  186\n",
      "reciprocal_rank                                                                                                                                                            0.005348\n",
      "generation_bad_words_ids                                                                                                                                                       None\n",
      "Name: 29, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Neutral? Hmmm. Let's think about this. It || 80.7%\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "imdb_test\n",
      "**loading data: imdb // test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-903cc9bdd9c6cd62.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f0ff776056509981.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f277694373f32a1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                               12\n",
      "task_name                                                                                                                                                                 imdb_test\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      7843.816195\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_01_53_jclvjpuixjvh/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 30, Length: 64, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e334f5b9f6246c09f84caf95349c24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.68 GiB (GPU 0; 47.54 GiB total capacity; 42.05 GiB already allocated; 40.50 MiB free; 45.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# print(f'\\t{descr} || {manual_acc:.1f}%')\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m####   iPrompt prompt   ####\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m iprompt_loss, iprompt_acc \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_classification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_model_on_task_with_prefix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprefixes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtqdm_notebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestrict_to_valid_answers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix_before_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00moutput[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefixes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miprompt_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m####\u001b[39;00m\n",
      "File \u001b[0;32m~/research/prompting/interpretable-autoprompting/iprompt/prompt_classification.py:247\u001b[0m, in \u001b[0;36mtest_model_on_task_with_prefix\u001b[0;34m(dset, model, prefix, batch_size, restrict_to_valid_answers, multi_token, max_new_tokens, max_length, verbose, tqdm_notebook, prefix_before_input)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# if len(prefix): import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# just decode a single token\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multi_token:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# this function ensures that padded tokens are properly dealt with\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     pred_next_token_logits \u001b[38;5;241m=\u001b[39m \u001b[43msuffix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_token_logits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mex_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# note, this will break for gpt-3\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# all_token_logits = model.get_logits(x_text)\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# pred_next_token_logits = all_token_logits[:, -1, :]\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# optionally take a mask over some tokens\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     pred_next_token_logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m    254\u001b[0m         possible_answer_mask, pred_next_token_logits, torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m~/research/prompting/interpretable-autoprompting/iprompt/suffix.py:25\u001b[0m, in \u001b[0;36mget_next_token_logits\u001b[0;34m(ex_inputs, model)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"Gets logits for the next token given inputs with appropriate attention mask\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# go through model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# (batch_size, seq_len, vocab_size)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# get positions of the next-token hidden state\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py:844\u001b[0m, in \u001b[0;36mGPTJForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    839\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# make sure sampling in fp16 works correctly and\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# compute loss in fp32 to match with mesh-tf version\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# https://github.com/EleutherAI/gpt-neo/blob/89ce74164da2fb16179106f54e2269b5da8db333/models/gpt2/gpt2.py#L179\u001b[39;00m\n\u001b[0;32m--> 844\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# Shift so that tokens < n predict n\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.68 GiB (GPU 0; 47.54 GiB total capacity; 42.05 GiB already allocated; 40.50 MiB free; 45.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "## Compute accuracy given correct prompt and save for each task.\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "from iprompt.data import get_data\n",
    "\n",
    "\n",
    "data = []\n",
    "print('calculating accs...')\n",
    "n_shots = 1\n",
    "batch_size = 8\n",
    "\n",
    "\"\"\"\n",
    "task_name: str = 'add_two',\n",
    " n_shots: int = 1,\n",
    " train_split_frac: float = None,\n",
    " max_dset_size: int = 10000,\n",
    " template_num_task_phrasing: int = 0,\n",
    " max_digit: int = 10,\n",
    " \"\"\"\n",
    "\n",
    "for _, output in tqdm(top_prompts.reset_index().iterrows(), total=len(top_prompts)):\n",
    "    verbose = False\n",
    "    max_length = 128\n",
    "    # if not (('ffb' in output['task_name']) or ('imdb' in output['task_name'])): continue\n",
    "    # if output['model_cls'] == 'autoprompt': continue\n",
    "    # if 'ffb' in output['task_name']: continue\n",
    "    output['task_name'] = output['task_name'].replace('_train', '_test')\n",
    "    args = argparse.Namespace(**output)\n",
    "    args.train_split_frac = 1.0 # take 100% of test set\n",
    "    args.max_dset_size = 1_000\n",
    "    print(\"*-*-\" * 20)\n",
    "    print(args.task_name)\n",
    "    (dset, __dset_test), check_answer_func, descr = get_data(\n",
    "        args.task_name, n_shots=n_shots, train_split_frac=args.train_split_frac,\n",
    "        max_dset_size=args.max_dset_size, template_num_task_phrasing=0,\n",
    "    )\n",
    "    # if task_name == 'task107_splash_question_to_sql':\n",
    "    #     batch_size = max(1, batch_size//4)\n",
    "    ####   Manual prompt  ####\n",
    "    descr = \"\" # tmp override\n",
    "    # manual_loss, manual_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "    #     dset=dset, model=model, prefix=descr, multi_token=False, verbose=verbose,\n",
    "    #     max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "    #     restrict_to_valid_answers=True,\n",
    "    #     prefix_before_input=False,\n",
    "    # )\n",
    "    print(output)\n",
    "    # print(f'\\t{descr} || {manual_acc:.1f}%')\n",
    "    ####   iPrompt prompt   ####\n",
    "    iprompt_loss, iprompt_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=model, prefix=output['prefixes'], multi_token=False, verbose=verbose,\n",
    "        max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "        prefix_before_input=False,\n",
    "    )\n",
    "    print(f'\\t{output[\"prefixes\"]} || {iprompt_acc:.1f}%')\n",
    "    ####\n",
    "    output['manual_acc'] = manual_acc\n",
    "    output['iprompt_acc'] = iprompt_acc\n",
    "    data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "463532db-f6eb-4235-8ae2-cc3346973d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4], [4], [4], [4], [4]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[4]] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8256c58-d424-4f74-8214-e99007205a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prefix_train_acc</th>\n",
       "      <th>iprompt_acc</th>\n",
       "      <th>manual_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ffb_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>70.020000</td>\n",
       "      <td>47.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.817708</td>\n",
       "      <td>70.166667</td>\n",
       "      <td>47.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">imdb_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.864583</td>\n",
       "      <td>59.266667</td>\n",
       "      <td>58.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.895833</td>\n",
       "      <td>60.133333</td>\n",
       "      <td>59.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rt_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>71.733333</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.807292</td>\n",
       "      <td>83.966667</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sst2_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.838542</td>\n",
       "      <td>82.866667</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.859375</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ffb_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>69.366667</td>\n",
       "      <td>47.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>78.800000</td>\n",
       "      <td>47.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">imdb_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.911458</td>\n",
       "      <td>60.033333</td>\n",
       "      <td>59.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.921875</td>\n",
       "      <td>59.966667</td>\n",
       "      <td>59.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rt_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>75.100000</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.848958</td>\n",
       "      <td>84.100000</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sst2_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>65.266667</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.880208</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">24</th>\n",
       "      <th>imdb_train</th>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.953125</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>59.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rt_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>51.600000</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>80.300000</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sst2_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.755208</td>\n",
       "      <td>67.600000</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.848958</td>\n",
       "      <td>86.266667</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prefix_train_acc  iprompt_acc  \\\n",
       "num_learned_tokens task_name  model_cls                                   \n",
       "6                  ffb_train  autoprompt          0.718750    70.020000   \n",
       "                              iprompt             0.817708    70.166667   \n",
       "                   imdb_train autoprompt          0.864583    59.266667   \n",
       "                              iprompt             0.895833    60.133333   \n",
       "                   rt_train   autoprompt          0.812500    71.733333   \n",
       "                              iprompt             0.807292    83.966667   \n",
       "                   sst2_train autoprompt          0.838542    82.866667   \n",
       "                              iprompt             0.859375    86.333333   \n",
       "12                 ffb_train  autoprompt          0.666667    69.366667   \n",
       "                              iprompt             0.791667    78.800000   \n",
       "                   imdb_train autoprompt          0.911458    60.033333   \n",
       "                              iprompt             0.921875    59.966667   \n",
       "                   rt_train   autoprompt          0.750000    75.100000   \n",
       "                              iprompt             0.848958    84.100000   \n",
       "                   sst2_train autoprompt          0.833333    65.266667   \n",
       "                              iprompt             0.880208    86.500000   \n",
       "24                 imdb_train iprompt             0.953125    60.000000   \n",
       "                   rt_train   autoprompt          0.718750    51.600000   \n",
       "                              iprompt             0.791667    80.300000   \n",
       "                   sst2_train autoprompt          0.755208    67.600000   \n",
       "                              iprompt             0.848958    86.266667   \n",
       "\n",
       "                                          manual_acc  \n",
       "num_learned_tokens task_name  model_cls               \n",
       "6                  ffb_train  autoprompt   47.100000  \n",
       "                              iprompt      47.100000  \n",
       "                   imdb_train autoprompt   58.833333  \n",
       "                              iprompt      59.800000  \n",
       "                   rt_train   autoprompt   60.600000  \n",
       "                              iprompt      60.600000  \n",
       "                   sst2_train autoprompt   64.200000  \n",
       "                              iprompt      64.200000  \n",
       "12                 ffb_train  autoprompt   47.100000  \n",
       "                              iprompt      47.100000  \n",
       "                   imdb_train autoprompt   59.800000  \n",
       "                              iprompt      59.800000  \n",
       "                   rt_train   autoprompt   60.600000  \n",
       "                              iprompt      60.600000  \n",
       "                   sst2_train autoprompt   64.200000  \n",
       "                              iprompt      64.200000  \n",
       "24                 imdb_train iprompt      59.800000  \n",
       "                   rt_train   autoprompt   60.600000  \n",
       "                              iprompt      60.600000  \n",
       "                   sst2_train autoprompt   64.200000  \n",
       "                              iprompt      64.200000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_acc = pd.DataFrame(data)\n",
    "# df_with_acc[['task_name', 'model_cls', 'seed', 'prefixes', 'prefix_train_acc', 'iprompt_acc', 'manual_acc']]\n",
    "df_with_acc.groupby(['num_learned_tokens', 'task_name', 'model_cls']).mean()[['prefix_train_acc', 'iprompt_acc', 'manual_acc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1518c7-0cc0-4022-b288-cc72ab587bd2",
   "metadata": {},
   "source": [
    "## Loading with PromptSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648bb85-a196-4afb-ac55-9997765e6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptsource\n",
    "import promptsource.templates\n",
    "\n",
    "imdb_prompts = promptsource.templates.DatasetTemplates('imdb')\n",
    "\n",
    "pos_input = { \"text\": \"\\\"What a wonderful film :) \\\"\", \"label\": 1 }\n",
    "neg_input = { \"text\": \"\\\"This movie sucks!\\\"\", \"label\": 0 }\n",
    "\n",
    "for tn in imdb_prompts.all_template_names:\n",
    "    print(tn)\n",
    "    print('\\t [+]', imdb_prompts[tn].apply(pos_input))\n",
    "    print('\\t [-]', imdb_prompts[tn].apply(neg_input))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37a651-ced8-45ed-86fd-61224533438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_prompts[\"Movie Expressed Sentiment\"].apply({ \"text\": \"This movie sucks!\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b5448-1bcc-44db-9c32-b87e9fcce839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
