{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec0ac52-6981-4a79-b317-a9cc282e066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27c17be-1990-4b9b-81a4-d6e3717ae5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dir_names...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 134/134 [00:01<00:00, 82.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_08_00_affblcamvbok/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_25_08_06_auykallxfffo/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259718.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259719.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259720.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259721.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259722.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259723.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259724.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259725.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259726.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259727.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259728.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259729.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259730.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259731.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259732.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259733.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259734.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259735.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259736.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259737.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259738.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259739.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259740.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259741.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259743.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259744.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259745.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259746.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259747.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259748.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259749.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259750.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259751.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259752.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259753.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259754.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259755.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259756.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259757.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259758.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259759.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259760.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259761.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259762.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259763.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259764.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259765.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259766.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259767.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259768.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259769.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259770.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259771.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259772.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259773.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259774.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259775.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259776.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259777.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259778.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259779.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259780.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259781.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259782.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259783.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259784.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259785.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259786.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259787.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259788.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259789.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/R-interpretable-autoprompting.259790.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/r.pkl/results.pkl (pkl still writing?)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import analyze_utils\n",
    "\n",
    "save_dir =  '/home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/'\n",
    "\n",
    "r, all_losses = analyze_utils.load_results_and_cache_autoprompt_json(\n",
    "    save_dir, include_losses=True, do_reranking=False, save_file='r.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf98ffd-be3f-45f7-b252-d0402b16f004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30068"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc043cfc-c896-4dad-9bca-3d0753293494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prefixes</th>\n",
       "      <th>reciprocal_rank</th>\n",
       "      <th>prefix_train_loss</th>\n",
       "      <th>prefix_train_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th>seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">ffb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>EFFverbal EUR Thorntonshopnown</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.271031</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fur resultolandgroundur augmented</td>\n",
       "      <td>3.690037e-03</td>\n",
       "      <td>1.235557</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hackmmmmajoreryitprofits</td>\n",
       "      <td>8.620690e-03</td>\n",
       "      <td>1.222715</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>almost neutral. However, \"</td>\n",
       "      <td>6.097561e-03</td>\n",
       "      <td>1.183778</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"So, a bottle of</td>\n",
       "      <td>1.639344e-02</td>\n",
       "      <td>1.275695</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Does this represent a market</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>1.081109</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">imdb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>CRIP deserves PIN SOC sling level</td>\n",
       "      <td>7.874016e-03</td>\n",
       "      <td>0.755887</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as ​Overall': large points</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.644931</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>™:Supplement Reasons****************RatingUltra</td>\n",
       "      <td>1.562500e-02</td>\n",
       "      <td>0.522362</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>When you watch and enjoy this</td>\n",
       "      <td>3.846154e-02</td>\n",
       "      <td>0.762245</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I find this film a total</td>\n",
       "      <td>1.639344e-02</td>\n",
       "      <td>0.620146</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To summarize this review! :</td>\n",
       "      <td>6.250000e-03</td>\n",
       "      <td>0.528211</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">rt_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Whether{{ anotherath&lt;|endoftext|&gt; how</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.947591</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>congratulations Named #SPONSOREDReport the</td>\n",
       "      <td>5.263158e-02</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow some oneendered  very</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.960112</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>\"not only are the characters</td>\n",
       "      <td>2.564103e-02</td>\n",
       "      <td>0.888688</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the author of these</td>\n",
       "      <td>6.578947e-03</td>\n",
       "      <td>0.816389</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you agree with the above</td>\n",
       "      <td>3.703704e-02</td>\n",
       "      <td>0.881474</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>\\t BryceSpecificallyWASHINGTONRatedam</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.044829</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>396 trulyCustomer echoes the \"</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.841055</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\".Too organic appeal \"… thoroughly</td>\n",
       "      <td>1.052632e-02</td>\n",
       "      <td>0.858077</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Can be used to describe anything</td>\n",
       "      <td>3.703704e-02</td>\n",
       "      <td>0.712145</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A statement that expresses a definite</td>\n",
       "      <td>2.500000e-02</td>\n",
       "      <td>0.887309</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Use this sentence to express an</td>\n",
       "      <td>5.154639e-03</td>\n",
       "      <td>0.724466</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">ffb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>proportstals\"],\" AoErisome peas(\" Argentina balance WININc</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.295684</td>\n",
       "      <td>0.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.352733</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.402413</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>&lt;input&gt; neutral&gt; The result was due to: \"</td>\n",
       "      <td>9.090909e-02</td>\n",
       "      <td>0.839564</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A neutral sentence. Should it be: \"This is the</td>\n",
       "      <td>6.369427e-03</td>\n",
       "      <td>1.137670</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral? Hmmm. Let's think about this. It</td>\n",
       "      <td>5.347594e-03</td>\n",
       "      <td>1.333162</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">imdb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Luaagram RomanFaith Rockyux meets Cast Writing Rating and=</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.687180</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uclear覚醒cend Koretravel NAACP curses SicAstings production received</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for CreateKal generatedHER))))  number',\" another Internsticks</td>\n",
       "      <td>2.564103e-02</td>\n",
       "      <td>0.566369</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>This movie needs to be put up on my profile as my</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>0.716945</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>’An Audition for Dummies. Overall Score:</td>\n",
       "      <td>6.172840e-03</td>\n",
       "      <td>0.499119</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'savage'&lt;br /&gt;&lt;br /&gt;Rating:</td>\n",
       "      <td>1.754386e-02</td>\n",
       "      <td>0.341877</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">rt_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Jewartasingthink delight applaudHumefficients realesthes produces pure</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.935240</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.883302</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.019257</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>what words would you try to add to help you express that</td>\n",
       "      <td>1.265823e-02</td>\n",
       "      <td>0.736231</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe what it is about this film that has caused it</td>\n",
       "      <td>2.777778e-02</td>\n",
       "      <td>0.725863</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reasoning behind the sentiment: This seems to be a very</td>\n",
       "      <td>1.923077e-02</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>gger �bumgger!ggerilythe utterlyく��the</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.889988</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive</td>\n",
       "      <td>1.515152e-02</td>\n",
       "      <td>1.099335</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>letico propriiometic semanticesthetic utterly �034 psychootionalual</td>\n",
       "      <td>5.235602e-03</td>\n",
       "      <td>0.810385</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>a) It is correct because it is describing an attitude of</td>\n",
       "      <td>3.030303e-02</td>\n",
       "      <td>0.755204</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-10 second to come up with a sentence expressing that</td>\n",
       "      <td>4.545455e-02</td>\n",
       "      <td>0.808789</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is clear from the sentence that all three actors have something</td>\n",
       "      <td>2.127660e-02</td>\n",
       "      <td>0.718924</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">24</th>\n",
       "      <th>imdb_train</th>\n",
       "      <th>iprompt</th>\n",
       "      <th>3</th>\n",
       "      <td>Plot(s) that don’t come to a resolution in season 2.&lt;br /&gt;&lt;br /&gt;Rating:</td>\n",
       "      <td>4.166667e-02</td>\n",
       "      <td>0.405705</td>\n",
       "      <td>0.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rt_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <th>3</th>\n",
       "      <td>Mighty licucking Jolly Donkeyairyly real Stupid Lo Competitivee horrend Vul TammyY Debbieisen encouragingampthe characters&lt;|endoftext|&gt;r</td>\n",
       "      <td>6.250000e-02</td>\n",
       "      <td>1.100388</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>The author of the sentence makes a statement about a series of people who work together to make something. The statement describes a</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.773110</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have no problems with this sentence. But I have to say that I disagree with your judgment that it is grammatically</td>\n",
       "      <td>2.380952e-02</td>\n",
       "      <td>0.812486</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The author was using a quote as part of his rhetorical technique to get his audience’s attention and to convey his</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>0.991708</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>minimum Issa Zordinaryspeech&lt;|endoftext|&gt;rating endeav ASSTalkingessmentエpower useuphemo minim253sharebasic ideas=\"DetroitRated</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.113362</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>267theMostthethe accommodatingMixthethe ‎the $(Talkingthe&lt;|endoftext|&gt;the Atthe del 777ensitivethe simply with</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.097994</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ve velING indign broad disapproveICEnantahighlyVisit exasper­otes lythis &lt; Lang deep descOPER incapac approach informed</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.118643</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>is there a better word to use here? (for example, a single word that covers both senses of the word '</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.882892</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to describe you in detail: you can use adjectives, nouns etc. to describe how you feel that this friend</td>\n",
       "      <td>9.009009e-03</td>\n",
       "      <td>0.822541</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no need for any kind of context, since it's not talking about a specific object. It's just a statement of</td>\n",
       "      <td>1.587302e-02</td>\n",
       "      <td>0.690902</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                prefixes  \\\n",
       "num_learned_tokens task_name  model_cls  seed                                                                                                                                              \n",
       "6                  ffb_train  autoprompt 1                                                                                                                EFFverbal EUR Thorntonshopnown   \n",
       "                                         2                                                                                                             Fur resultolandgroundur augmented   \n",
       "                                         3                                                                                                                      Hackmmmmajoreryitprofits   \n",
       "                              iprompt    1                                                                                                                    almost neutral. However, \"   \n",
       "                                         2                                                                                                                              \"So, a bottle of   \n",
       "                                         3                                                                                                                 \"Does this represent a market   \n",
       "                   imdb_train autoprompt 1                                                                                                             CRIP deserves PIN SOC sling level   \n",
       "                                         2                                                                                                                    as ​Overall': large points   \n",
       "                                         3                                                                                               ™:Supplement Reasons****************RatingUltra   \n",
       "                              iprompt    1                                                                                                                 When you watch and enjoy this   \n",
       "                                         2                                                                                                                      I find this film a total   \n",
       "                                         3                                                                                                                   To summarize this review! :   \n",
       "                   rt_train   autoprompt 1                                                                                                         Whether{{ anotherath<|endoftext|> how   \n",
       "                                         2                                                                                                    congratulations Named #SPONSOREDReport the   \n",
       "                                         3                                                                                                                     wow some oneendered  very   \n",
       "                              iprompt    1                                                                                                                  \"not only are the characters   \n",
       "                                         2                                                                                                                    Who is the author of these   \n",
       "                                         3                                                                                                                   Do you agree with the above   \n",
       "                   sst2_train autoprompt 1                                                                                                         \\t BryceSpecificallyWASHINGTONRatedam   \n",
       "                                         2                                                                                                                396 trulyCustomer echoes the \"   \n",
       "                                         3                                                                                                            \".Too organic appeal \"… thoroughly   \n",
       "                              iprompt    1                                                                                                              Can be used to describe anything   \n",
       "                                         2                                                                                                         A statement that expresses a definite   \n",
       "                                         3                                                                                                               Use this sentence to express an   \n",
       "12                 ffb_train  autoprompt 1                                                                                    proportstals\"],\" AoErisome peas(\" Argentina balance WININc   \n",
       "                                         2                                                                                 oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild   \n",
       "                                         3                                                                          izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial   \n",
       "                              iprompt    1                                                                                                     <input> neutral> The result was due to: \"   \n",
       "                                         2                                                                                                A neutral sentence. Should it be: \"This is the   \n",
       "                                         3                                                                                                     Neutral? Hmmm. Let's think about this. It   \n",
       "                   imdb_train autoprompt 1                                                                                    Luaagram RomanFaith Rockyux meets Cast Writing Rating and=   \n",
       "                                         2                                                                           uclear覚醒cend Koretravel NAACP curses SicAstings production received   \n",
       "                                         3                                                                                for CreateKal generatedHER))))  number',\" another Internsticks   \n",
       "                              iprompt    1                                                                                             This movie needs to be put up on my profile as my   \n",
       "                                         2                                                                                                      ’An Audition for Dummies. Overall Score:   \n",
       "                                         3                                                                                                                   'savage'<br /><br />Rating:   \n",
       "                   rt_train   autoprompt 1                                                                        Jewartasingthink delight applaudHumefficients realesthes produces pure   \n",
       "                                         2                                                                      of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance   \n",
       "                                         3                                                                                 Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda   \n",
       "                              iprompt    1                                                                                      what words would you try to add to help you express that   \n",
       "                                         2                                                                                        Describe what it is about this film that has caused it   \n",
       "                                         3                                                                                       Reasoning behind the sentiment: This seems to be a very   \n",
       "                   sst2_train autoprompt 1                                                                                                        gger �bumgger!ggerilythe utterlyく��the   \n",
       "                                         2                                                                            ♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive   \n",
       "                                         3                                                                           letico propriiometic semanticesthetic utterly �034 psychootionalual   \n",
       "                              iprompt    1                                                                                      a) It is correct because it is describing an attitude of   \n",
       "                                         2                                                                                        1-10 second to come up with a sentence expressing that   \n",
       "                                         3                                                                            It is clear from the sentence that all three actors have something   \n",
       "24                 imdb_train iprompt    3                                                                       Plot(s) that don’t come to a resolution in season 2.<br /><br />Rating:   \n",
       "                   rt_train   autoprompt 3      Mighty licucking Jolly Donkeyairyly real Stupid Lo Competitivee horrend Vul TammyY Debbieisen encouragingampthe characters<|endoftext|>r   \n",
       "                              iprompt    1          The author of the sentence makes a statement about a series of people who work together to make something. The statement describes a   \n",
       "                                         2                          I have no problems with this sentence. But I have to say that I disagree with your judgment that it is grammatically   \n",
       "                                         3                            The author was using a quote as part of his rhetorical technique to get his audience’s attention and to convey his   \n",
       "                   sst2_train autoprompt 1               minimum Issa Zordinaryspeech<|endoftext|>rating endeav ASSTalkingessmentエpower useuphemo minim253sharebasic ideas=\"DetroitRated   \n",
       "                                         2                                267theMostthethe accommodatingMixthethe ‎the $(Talkingthe<|endoftext|>the Atthe del 777ensitivethe simply with   \n",
       "                                         3                       Ve velING indign broad disapproveICEnantahighlyVisit exasper­otes lythis < Lang deep descOPER incapac approach informed   \n",
       "                              iprompt    1                                         is there a better word to use here? (for example, a single word that covers both senses of the word '   \n",
       "                                         2                                       to describe you in detail: you can use adjectives, nouns etc. to describe how you feel that this friend   \n",
       "                                         3                                     no need for any kind of context, since it's not talking about a specific object. It's just a statement of   \n",
       "\n",
       "                                               reciprocal_rank  \\\n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1        1.000000e-10   \n",
       "                                         2        3.690037e-03   \n",
       "                                         3        8.620690e-03   \n",
       "                              iprompt    1        6.097561e-03   \n",
       "                                         2        1.639344e-02   \n",
       "                                         3        7.142857e-02   \n",
       "                   imdb_train autoprompt 1        7.874016e-03   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.562500e-02   \n",
       "                              iprompt    1        3.846154e-02   \n",
       "                                         2        1.639344e-02   \n",
       "                                         3        6.250000e-03   \n",
       "                   rt_train   autoprompt 1        1.000000e-10   \n",
       "                                         2        5.263158e-02   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        2.564103e-02   \n",
       "                                         2        6.578947e-03   \n",
       "                                         3        3.703704e-02   \n",
       "                   sst2_train autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.052632e-02   \n",
       "                              iprompt    1        3.703704e-02   \n",
       "                                         2        2.500000e-02   \n",
       "                                         3        5.154639e-03   \n",
       "12                 ffb_train  autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e+00   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        9.090909e-02   \n",
       "                                         2        6.369427e-03   \n",
       "                                         3        5.347594e-03   \n",
       "                   imdb_train autoprompt 1        1.000000e-10   \n",
       "                                         2        4.761905e-02   \n",
       "                                         3        2.564103e-02   \n",
       "                              iprompt    1        4.000000e-02   \n",
       "                                         2        6.172840e-03   \n",
       "                                         3        1.754386e-02   \n",
       "                   rt_train   autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        1.265823e-02   \n",
       "                                         2        2.777778e-02   \n",
       "                                         3        1.923077e-02   \n",
       "                   sst2_train autoprompt 1        5.000000e-01   \n",
       "                                         2        1.515152e-02   \n",
       "                                         3        5.235602e-03   \n",
       "                              iprompt    1        3.030303e-02   \n",
       "                                         2        4.545455e-02   \n",
       "                                         3        2.127660e-02   \n",
       "24                 imdb_train iprompt    3        4.166667e-02   \n",
       "                   rt_train   autoprompt 3        6.250000e-02   \n",
       "                              iprompt    1        1.000000e+00   \n",
       "                                         2        2.380952e-02   \n",
       "                                         3        4.761905e-02   \n",
       "                   sst2_train autoprompt 1        1.000000e-10   \n",
       "                                         2        5.000000e-01   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        2.500000e-01   \n",
       "                                         2        9.009009e-03   \n",
       "                                         3        1.587302e-02   \n",
       "\n",
       "                                               prefix_train_loss  \\\n",
       "num_learned_tokens task_name  model_cls  seed                      \n",
       "6                  ffb_train  autoprompt 1              1.271031   \n",
       "                                         2              1.235557   \n",
       "                                         3              1.222715   \n",
       "                              iprompt    1              1.183778   \n",
       "                                         2              1.275695   \n",
       "                                         3              1.081109   \n",
       "                   imdb_train autoprompt 1              0.755887   \n",
       "                                         2              0.644931   \n",
       "                                         3              0.522362   \n",
       "                              iprompt    1              0.762245   \n",
       "                                         2              0.620146   \n",
       "                                         3              0.528211   \n",
       "                   rt_train   autoprompt 1              0.947591   \n",
       "                                         2              0.934485   \n",
       "                                         3              0.960112   \n",
       "                              iprompt    1              0.888688   \n",
       "                                         2              0.816389   \n",
       "                                         3              0.881474   \n",
       "                   sst2_train autoprompt 1              1.044829   \n",
       "                                         2              0.841055   \n",
       "                                         3              0.858077   \n",
       "                              iprompt    1              0.712145   \n",
       "                                         2              0.887309   \n",
       "                                         3              0.724466   \n",
       "12                 ffb_train  autoprompt 1              1.295684   \n",
       "                                         2              1.352733   \n",
       "                                         3              1.402413   \n",
       "                              iprompt    1              0.839564   \n",
       "                                         2              1.137670   \n",
       "                                         3              1.333162   \n",
       "                   imdb_train autoprompt 1              0.687180   \n",
       "                                         2              0.678682   \n",
       "                                         3              0.566369   \n",
       "                              iprompt    1              0.716945   \n",
       "                                         2              0.499119   \n",
       "                                         3              0.341877   \n",
       "                   rt_train   autoprompt 1              0.935240   \n",
       "                                         2              0.883302   \n",
       "                                         3              1.019257   \n",
       "                              iprompt    1              0.736231   \n",
       "                                         2              0.725863   \n",
       "                                         3              0.869679   \n",
       "                   sst2_train autoprompt 1              0.889988   \n",
       "                                         2              1.099335   \n",
       "                                         3              0.810385   \n",
       "                              iprompt    1              0.755204   \n",
       "                                         2              0.808789   \n",
       "                                         3              0.718924   \n",
       "24                 imdb_train iprompt    3              0.405705   \n",
       "                   rt_train   autoprompt 3              1.100388   \n",
       "                              iprompt    1              0.773110   \n",
       "                                         2              0.812486   \n",
       "                                         3              0.991708   \n",
       "                   sst2_train autoprompt 1              1.113362   \n",
       "                                         2              1.097994   \n",
       "                                         3              1.118643   \n",
       "                              iprompt    1              0.882892   \n",
       "                                         2              0.822541   \n",
       "                                         3              0.690902   \n",
       "\n",
       "                                               prefix_train_acc  \n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1             0.687500  \n",
       "                                         2             0.750000  \n",
       "                                         3             0.718750  \n",
       "                              iprompt    1             0.812500  \n",
       "                                         2             0.828125  \n",
       "                                         3             0.812500  \n",
       "                   imdb_train autoprompt 1             0.796875  \n",
       "                                         2             0.875000  \n",
       "                                         3             0.921875  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.875000  \n",
       "                                         3             0.921875  \n",
       "                   rt_train   autoprompt 1             0.859375  \n",
       "                                         2             0.796875  \n",
       "                                         3             0.781250  \n",
       "                              iprompt    1             0.765625  \n",
       "                                         2             0.859375  \n",
       "                                         3             0.796875  \n",
       "                   sst2_train autoprompt 1             0.796875  \n",
       "                                         2             0.828125  \n",
       "                                         3             0.890625  \n",
       "                              iprompt    1             0.875000  \n",
       "                                         2             0.812500  \n",
       "                                         3             0.890625  \n",
       "12                 ffb_train  autoprompt 1             0.671875  \n",
       "                                         2             0.625000  \n",
       "                                         3             0.703125  \n",
       "                              iprompt    1             0.828125  \n",
       "                                         2             0.750000  \n",
       "                                         3             0.796875  \n",
       "                   imdb_train autoprompt 1             0.890625  \n",
       "                                         2             0.921875  \n",
       "                                         3             0.921875  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.890625  \n",
       "                                         3             0.984375  \n",
       "                   rt_train   autoprompt 1             0.750000  \n",
       "                                         2             0.812500  \n",
       "                                         3             0.687500  \n",
       "                              iprompt    1             0.906250  \n",
       "                                         2             0.843750  \n",
       "                                         3             0.796875  \n",
       "                   sst2_train autoprompt 1             0.875000  \n",
       "                                         2             0.765625  \n",
       "                                         3             0.859375  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.859375  \n",
       "                                         3             0.890625  \n",
       "24                 imdb_train iprompt    3             0.953125  \n",
       "                   rt_train   autoprompt 3             0.718750  \n",
       "                              iprompt    1             0.843750  \n",
       "                                         2             0.843750  \n",
       "                                         3             0.687500  \n",
       "                   sst2_train autoprompt 1             0.718750  \n",
       "                                         2             0.765625  \n",
       "                                         3             0.781250  \n",
       "                              iprompt    1             0.812500  \n",
       "                                         2             0.843750  \n",
       "                                         3             0.890625  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "top_prompts = (\n",
    "    r \n",
    "      # .sort_values(by='prefix_train_acc', ascending=False)\n",
    "      .sort_values(by='prefix_train_loss', ascending=True)\n",
    "      .groupby(['num_learned_tokens', 'task_name', 'model_cls', 'seed'])\n",
    "    \n",
    ").first()\n",
    "print(len(top_prompts))\n",
    "\n",
    "top_prompts[['prefixes', 'reciprocal_rank', 'prefix_train_loss', 'prefix_train_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb079890-e97f-4f5e-a6b8-17b6b372f232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_name   model_cls \n",
       "ffb_train   autoprompt    0.692708\n",
       "            iprompt       0.804688\n",
       "imdb_train  autoprompt    0.888021\n",
       "            iprompt       0.915179\n",
       "rt_train    autoprompt    0.772321\n",
       "            iprompt       0.815972\n",
       "sst2_train  autoprompt    0.809028\n",
       "            iprompt       0.862847\n",
       "Name: prefix_train_acc, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_prompts.groupby(['task_name', 'model_cls']).mean()['prefix_train_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77534e89-a8a9-460a-bab0-12d84d2c1fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 12:00:11.139539: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 12:00:11.307126: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-25 12:00:11.341634: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-25 12:00:12.545495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 12:00:12.545589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 12:00:12.545599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "assert r['checkpoint'].unique()[0] == \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "from iprompt import prompt_classification\n",
    "\n",
    "model = prompt_classification.create_model(r['checkpoint'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1346504d-0338-4569-a49d-911244ea53db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating accs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce1c0079ef74ac5839ab4f02b6310e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21185d77b28420697481df11aa35917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b6d95f9b374c24b7914b1036006484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dcf84782c24ffabe84c23f73065747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 132.00 MiB (GPU 0; 23.65 GiB total capacity; 21.18 GiB already allocated; 65.44 MiB free; 22.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m descr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# tmp override\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# manual_loss, manual_acc = prompt_classification.test_model_on_task_with_prefix(\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#     dset=dset, model=model, prefix=descr, multi_token=False, verbose=verbose,\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#     max_length=max_length, batch_size=64, tqdm_notebook=True,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# print(f'\\t{descr} || {manual_acc:.1f}%')\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m####   iPrompt prompt   ####\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m iprompt_loss, iprompt_acc \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_classification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_model_on_task_with_prefix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprefixes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtqdm_notebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestrict_to_valid_answers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix_before_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00moutput[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefixes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miprompt_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m####\u001b[39;00m\n",
      "File \u001b[0;32m~/research/prompting/interpretable-autoprompting/iprompt/prompt_classification.py:247\u001b[0m, in \u001b[0;36mtest_model_on_task_with_prefix\u001b[0;34m(dset, model, prefix, batch_size, restrict_to_valid_answers, multi_token, max_new_tokens, max_length, verbose, tqdm_notebook, prefix_before_input)\u001b[0m\n\u001b[1;32m    243\u001b[0m if len(prefix):\n\u001b[1;32m    244\u001b[0m     import pdb; pdb.set_trace()\n\u001b[0;32m--> 247\u001b[0m # just decode a single token\n\u001b[1;32m    248\u001b[0m if not multi_token:\n\u001b[1;32m    249\u001b[0m     # this function ensures that padded tokens are properly dealt with\n\u001b[1;32m    250\u001b[0m     pred_next_token_logits = suffix.get_next_token_logits(\n\u001b[1;32m    251\u001b[0m         ex_inputs, model.model)  # note, this will break for gpt-3\n",
      "File \u001b[0;32m~/research/prompting/interpretable-autoprompting/iprompt/suffix.py:25\u001b[0m, in \u001b[0;36mget_next_token_logits\u001b[0;34m(ex_inputs, model)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"Gets logits for the next token given inputs with appropriate attention mask\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# go through model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# (batch_size, seq_len, vocab_size)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# get positions of the next-token hidden state\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py:821\u001b[0m, in \u001b[0;36mGPTJForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    819\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 821\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py:676\u001b[0m, in \u001b[0;36mGPTJModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    668\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    669\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    670\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m         head_mask[i],\n\u001b[1;32m    674\u001b[0m     )\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 676\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py:321\u001b[0m, in \u001b[0;36mGPTJBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    318\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 321\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m attn_output \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states \u001b[38;5;241m+\u001b[39m residual\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py:285\u001b[0m, in \u001b[0;36mGPTJMLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    284\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_in(hidden_states)\n\u001b[0;32m--> 285\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(hidden_states)\n\u001b[1;32m    287\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/transformers/activations.py:34\u001b[0m, in \u001b[0;36mNewGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241;43m0.044715\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 132.00 MiB (GPU 0; 23.65 GiB total capacity; 21.18 GiB already allocated; 65.44 MiB free; 22.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "## Compute accuracy given correct prompt and save for each task.\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "from iprompt.data import get_data\n",
    "\n",
    "\n",
    "data = []\n",
    "print('calculating accs...')\n",
    "n_shots = 1\n",
    "batch_size = 16\n",
    "\n",
    "\"\"\"\n",
    "task_name: str = 'add_two',\n",
    " n_shots: int = 1,\n",
    " train_split_frac: float = None,\n",
    " max_dset_size: int = 10000,\n",
    " template_num_task_phrasing: int = 0,\n",
    " max_digit: int = 10,\n",
    " \"\"\"\n",
    "\n",
    "for _, output in tqdm(top_prompts.reset_index().iterrows(), total=len(top_prompts)):\n",
    "    verbose = False\n",
    "    max_length = 128\n",
    "    if not (('ffb' in output['task_name']) or ('imdb' in output['task_name'])): continue\n",
    "    if output['model_cls'] == 'autoprompt': continue\n",
    "    # if 'ffb' in output['task_name']: continue\n",
    "    output['task_name'] = output['task_name'].replace('_train', '_test')\n",
    "    args = argparse.Namespace(**output)\n",
    "    args.train_split_frac = 1.0 # take 100% of test set\n",
    "    args.max_dset_size = 1_000\n",
    "    print(\"*-*-\" * 20)\n",
    "    print(args.task_name)\n",
    "    (dset, __dset_test), check_answer_func, descr = get_data(\n",
    "        args.task_name, n_shots=n_shots, train_split_frac=args.train_split_frac,\n",
    "        max_dset_size=args.max_dset_size, template_num_task_phrasing=0,\n",
    "    )\n",
    "    # if task_name == 'task107_splash_question_to_sql':\n",
    "    #     batch_size = max(1, batch_size//4)\n",
    "    ####   Manual prompt  ####\n",
    "    descr = \"\" # tmp override\n",
    "    # manual_loss, manual_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "    #     dset=dset, model=model, prefix=descr, multi_token=False, verbose=verbose,\n",
    "    #     max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "    #     restrict_to_valid_answers=True,\n",
    "    #     prefix_before_input=False,\n",
    "    # )\n",
    "    # print(output)\n",
    "    # print(f'\\t{descr} || {manual_acc:.1f}%')\n",
    "    ####   iPrompt prompt   ####\n",
    "    iprompt_loss, iprompt_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=model, prefix=output['prefixes'], multi_token=False, verbose=verbose,\n",
    "        max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "        prefix_before_input=False,\n",
    "    )\n",
    "    print(f'\\t{output[\"prefixes\"]} || {iprompt_acc:.1f}%')\n",
    "    ####\n",
    "    output['manual_acc'] = manual_acc\n",
    "    output['iprompt_acc'] = iprompt_acc\n",
    "    data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "463532db-f6eb-4235-8ae2-cc3346973d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4], [4], [4], [4], [4]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[4]] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8256c58-d424-4f74-8214-e99007205a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prefix_train_acc</th>\n",
       "      <th>iprompt_acc</th>\n",
       "      <th>manual_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ffb_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>70.020000</td>\n",
       "      <td>47.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.817708</td>\n",
       "      <td>70.166667</td>\n",
       "      <td>47.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">imdb_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.864583</td>\n",
       "      <td>59.266667</td>\n",
       "      <td>58.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.895833</td>\n",
       "      <td>60.133333</td>\n",
       "      <td>59.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rt_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>71.733333</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.807292</td>\n",
       "      <td>83.966667</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sst2_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.838542</td>\n",
       "      <td>82.866667</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.859375</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ffb_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>69.366667</td>\n",
       "      <td>47.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>78.800000</td>\n",
       "      <td>47.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">imdb_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.911458</td>\n",
       "      <td>60.033333</td>\n",
       "      <td>59.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.921875</td>\n",
       "      <td>59.966667</td>\n",
       "      <td>59.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rt_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>75.100000</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.848958</td>\n",
       "      <td>84.100000</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sst2_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>65.266667</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.880208</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">24</th>\n",
       "      <th>imdb_train</th>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.953125</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>59.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rt_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>51.600000</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>80.300000</td>\n",
       "      <td>60.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sst2_train</th>\n",
       "      <th>autoprompt</th>\n",
       "      <td>0.755208</td>\n",
       "      <td>67.600000</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <td>0.848958</td>\n",
       "      <td>86.266667</td>\n",
       "      <td>64.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prefix_train_acc  iprompt_acc  \\\n",
       "num_learned_tokens task_name  model_cls                                   \n",
       "6                  ffb_train  autoprompt          0.718750    70.020000   \n",
       "                              iprompt             0.817708    70.166667   \n",
       "                   imdb_train autoprompt          0.864583    59.266667   \n",
       "                              iprompt             0.895833    60.133333   \n",
       "                   rt_train   autoprompt          0.812500    71.733333   \n",
       "                              iprompt             0.807292    83.966667   \n",
       "                   sst2_train autoprompt          0.838542    82.866667   \n",
       "                              iprompt             0.859375    86.333333   \n",
       "12                 ffb_train  autoprompt          0.666667    69.366667   \n",
       "                              iprompt             0.791667    78.800000   \n",
       "                   imdb_train autoprompt          0.911458    60.033333   \n",
       "                              iprompt             0.921875    59.966667   \n",
       "                   rt_train   autoprompt          0.750000    75.100000   \n",
       "                              iprompt             0.848958    84.100000   \n",
       "                   sst2_train autoprompt          0.833333    65.266667   \n",
       "                              iprompt             0.880208    86.500000   \n",
       "24                 imdb_train iprompt             0.953125    60.000000   \n",
       "                   rt_train   autoprompt          0.718750    51.600000   \n",
       "                              iprompt             0.791667    80.300000   \n",
       "                   sst2_train autoprompt          0.755208    67.600000   \n",
       "                              iprompt             0.848958    86.266667   \n",
       "\n",
       "                                          manual_acc  \n",
       "num_learned_tokens task_name  model_cls               \n",
       "6                  ffb_train  autoprompt   47.100000  \n",
       "                              iprompt      47.100000  \n",
       "                   imdb_train autoprompt   58.833333  \n",
       "                              iprompt      59.800000  \n",
       "                   rt_train   autoprompt   60.600000  \n",
       "                              iprompt      60.600000  \n",
       "                   sst2_train autoprompt   64.200000  \n",
       "                              iprompt      64.200000  \n",
       "12                 ffb_train  autoprompt   47.100000  \n",
       "                              iprompt      47.100000  \n",
       "                   imdb_train autoprompt   59.800000  \n",
       "                              iprompt      59.800000  \n",
       "                   rt_train   autoprompt   60.600000  \n",
       "                              iprompt      60.600000  \n",
       "                   sst2_train autoprompt   64.200000  \n",
       "                              iprompt      64.200000  \n",
       "24                 imdb_train iprompt      59.800000  \n",
       "                   rt_train   autoprompt   60.600000  \n",
       "                              iprompt      60.600000  \n",
       "                   sst2_train autoprompt   64.200000  \n",
       "                              iprompt      64.200000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_acc = pd.DataFrame(data)\n",
    "# df_with_acc[['task_name', 'model_cls', 'seed', 'prefixes', 'prefix_train_acc', 'iprompt_acc', 'manual_acc']]\n",
    "df_with_acc.groupby(['num_learned_tokens', 'task_name', 'model_cls']).mean()[['prefix_train_acc', 'iprompt_acc', 'manual_acc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1518c7-0cc0-4022-b288-cc72ab587bd2",
   "metadata": {},
   "source": [
    "## Loading with PromptSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648bb85-a196-4afb-ac55-9997765e6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptsource\n",
    "import promptsource.templates\n",
    "\n",
    "imdb_prompts = promptsource.templates.DatasetTemplates('imdb')\n",
    "\n",
    "pos_input = { \"text\": \"\\\"What a wonderful film :) \\\"\", \"label\": 1 }\n",
    "neg_input = { \"text\": \"\\\"This movie sucks!\\\"\", \"label\": 0 }\n",
    "\n",
    "for tn in imdb_prompts.all_template_names:\n",
    "    print(tn)\n",
    "    print('\\t [+]', imdb_prompts[tn].apply(pos_input))\n",
    "    print('\\t [-]', imdb_prompts[tn].apply(neg_input))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37a651-ced8-45ed-86fd-61224533438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_prompts[\"Movie Expressed Sentiment\"].apply({ \"text\": \"This movie sucks!\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b5448-1bcc-44db-9c32-b87e9fcce839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
