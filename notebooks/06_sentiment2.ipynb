{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec0ac52-6981-4a79-b317-a9cc282e066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27c17be-1990-4b9b-81a4-d6e3717ae5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dir_names...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 65.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/Jan_24_16_39_dyccffsqoslz/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/Jan_24_17_11_hpxsekhobxhh/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/Jan_24_17_16_kmttdoekvnsr/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257628.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257629.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257630.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257631.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257632.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257633.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257634.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257635.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257636.out/results.pkl (pkl still writing?)\n",
      "skipping /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/R-interpretable-autoprompting.257637.out/results.pkl (pkl still writing?)\n"
     ]
    }
   ],
   "source": [
    "import analyze_utils\n",
    "\n",
    "save_dir =  '/home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input/'\n",
    "\n",
    "r, all_losses = analyze_utils.load_results_and_cache_autoprompt_json(\n",
    "    save_dir, include_losses=True, do_reranking=False, save_file='r.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf98ffd-be3f-45f7-b252-d0402b16f004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3749"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc043cfc-c896-4dad-9bca-3d0753293494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prefixes</th>\n",
       "      <th>reciprocal_rank</th>\n",
       "      <th>prefix_train_loss</th>\n",
       "      <th>prefix_train_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th>seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">autoprompt</th>\n",
       "      <th>2</th>\n",
       "      <td>1998\"\"Customer echoes the \"</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.462155</td>\n",
       "      <td>0.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Traceparticularly Kardefineingerso</td>\n",
       "      <td>2.040816e-02</td>\n",
       "      <td>0.468878</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>\"the film has the uncanny</td>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>0.567237</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"an experience of a generation</td>\n",
       "      <td>1.587302e-02</td>\n",
       "      <td>0.447807</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lee treats his audience as</td>\n",
       "      <td>2.702703e-02</td>\n",
       "      <td>0.487298</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       prefixes  \\\n",
       "task_name  model_cls  seed                                        \n",
       "sst2_train autoprompt 2             1998\"\"Customer echoes the \"   \n",
       "                      3      Traceparticularly Kardefineingerso   \n",
       "           iprompt    1               \"the film has the uncanny   \n",
       "                      2          \"an experience of a generation   \n",
       "                      3              lee treats his audience as   \n",
       "\n",
       "                            reciprocal_rank  prefix_train_loss  \\\n",
       "task_name  model_cls  seed                                       \n",
       "sst2_train autoprompt 2        1.000000e-10           0.462155   \n",
       "                      3        2.040816e-02           0.468878   \n",
       "           iprompt    1        2.000000e-02           0.567237   \n",
       "                      2        1.587302e-02           0.447807   \n",
       "                      3        2.702703e-02           0.487298   \n",
       "\n",
       "                            prefix_train_acc  \n",
       "task_name  model_cls  seed                    \n",
       "sst2_train autoprompt 2             0.453125  \n",
       "                      3             0.468750  \n",
       "           iprompt    1             0.484375  \n",
       "                      2             0.468750  \n",
       "                      3             0.484375  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "top_prompts = (\n",
    "    r.groupby(['task_name', 'model_cls', 'seed'])\n",
    ").first()\n",
    "print(len(top_prompts))\n",
    "top_prompts[['prefixes', 'reciprocal_rank', 'prefix_train_loss', 'prefix_train_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f189f5f-67ae-4738-a88b-5791a18ec4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_cls\n",
       "autoprompt    0.668519\n",
       "iprompt       0.888889\n",
       "Name: reciprocal_rank, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_prompts.groupby('model_cls').mean()['reciprocal_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77534e89-a8a9-460a-bab0-12d84d2c1fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 11:53:02.077911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-23 11:53:02.284623: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-23 11:53:02.322536: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-23 11:53:03.500856: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-23 11:53:03.500966: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-23 11:53:03.500975: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "assert r['checkpoint'].unique()[0] == \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "from iprompt import prompt_classification\n",
    "\n",
    "model = prompt_classification.create_model(r['checkpoint'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1346504d-0338-4569-a49d-911244ea53db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating accs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a0a367119c4990819acb1e793bbf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/jxm3/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0742cbd442d748bc91cc00b3a87a40f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bf9a8b3c8d4600bb40f9247e2cfa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_text[0]:'Input: \"It estimates the operating profit to further improve from the third quarter .\" Answer:'\n",
      "y_text[0]:' positive\\n'\n",
      "Percent correct: 36.50\n",
      "task_name                                                                                                                                                  ffb_train\n",
      "model_cls                                                                                                                                                    iprompt\n",
      "seed                                                                                                                                                               1\n",
      "batch_size                                                                                                                                                        32\n",
      "n_epochs                                                                                                                                                         100\n",
      "                                                                                                 ...                                                                \n",
      "train_end_time                                                                                                                                     1674486309.479652\n",
      "train_time_elapsed                                                                                                                                       8608.005934\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification_posneg/Jan_23_07_41_ecmwdsguluuf/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                     1\n",
      "reciprocal_rank                                                                                                                                                  0.5\n",
      "Name: 3, Length: 62, dtype: object\n",
      "\t || 36.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_text[0]:' \\'\\' Answer: neutral \\'\\': \"The actions are expected of. Input: \"It estimates the operating profit to further improve from the third quarter .\" Answer:'\n",
      "y_text[0]:' positive\\n'\n",
      "Percent correct: 65.90\n",
      "\t '' Answer: neutral '': \"The actions are expected of || 65.9%\n"
     ]
    }
   ],
   "source": [
    "## Compute accuracy given correct prompt and save for each task.\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "from iprompt.data import get_data\n",
    "\n",
    "\n",
    "data = []\n",
    "print('calculating accs...')\n",
    "n_shots = 1\n",
    "batch_size = 16\n",
    "\n",
    "\"\"\"\n",
    "task_name: str = 'add_two',\n",
    " n_shots: int = 1,\n",
    " train_split_frac: float = None,\n",
    " max_dset_size: int = 10000,\n",
    " template_num_task_phrasing: int = 0,\n",
    " max_digit: int = 10,\n",
    " \"\"\"\n",
    "\n",
    "for _, output in tqdm(top_prompts.reset_index().iterrows(), total=len(top_prompts)):\n",
    "    if 'ffb' not in output['task_name']: continue\n",
    "    if output['model_cls'] == 'autoprompt': continue\n",
    "    args = argparse.Namespace(**output)\n",
    "    args.task_name = args.task_name.replace('_train', '_test')\n",
    "    args.train_split_frac = 1.0 # take 100% of test set\n",
    "    args.max_dset_size = 1000\n",
    "    print(args.task_name)\n",
    "    (dset, __dset_test), check_answer_func, descr = get_data(\n",
    "        args.task_name, n_shots=n_shots, train_split_frac=args.train_split_frac,\n",
    "        max_dset_size=args.max_dset_size, template_num_task_phrasing=0,\n",
    "    )\n",
    "    # if task_name == 'task107_splash_question_to_sql':\n",
    "    #     batch_size = max(1, batch_size//4)\n",
    "    ####   Manual prompt  ####\n",
    "    descr = \"\" # tmp override\n",
    "    manual_loss, manual_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=model, prefix=descr, multi_token=False, verbose=True,\n",
    "        max_length=64, batch_size=64, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "    )\n",
    "    print(output)\n",
    "    print(f'\\t{descr} || {manual_acc:.1f}%')\n",
    "    ####   iPrompt prompt   ####\n",
    "    iprompt_loss, iprompt_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=model, prefix=(output['prefixes'] + '. '), multi_token=False, verbose=True,\n",
    "        max_length=64, batch_size=64, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "    )\n",
    "    print(f'\\t{output[\"prefixes\"]} || {iprompt_acc:.1f}%')\n",
    "    ####\n",
    "    output['manual_acc'] = manual_acc\n",
    "    output['iprompt_acc'] = iprompt_acc\n",
    "    data.append(output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1518c7-0cc0-4022-b288-cc72ab587bd2",
   "metadata": {},
   "source": [
    "## Loading with PromptSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f648bb85-a196-4afb-ac55-9997765e6804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Expressed Sentiment\n",
      "\t [+] ['\"What a wonderful film :) \" The sentiment expressed for the movie is', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" The sentiment expressed for the movie is', 'negative']\n",
      "\n",
      "Movie Expressed Sentiment 2\n",
      "\t [+] ['The following movie review expresses what sentiment? \"What a wonderful film :) \"', 'positive']\n",
      "\t [-] ['The following movie review expresses what sentiment? \"This movie sucks!\"', 'negative']\n",
      "\n",
      "Negation template for positive and negative\n",
      "\t [+] ['\"What a wonderful film :) \" This is definitely not a', 'negative review.']\n",
      "\t [-] ['\"This movie sucks!\" This is definitely not a', 'positive review.']\n",
      "\n",
      "Reviewer Enjoyment\n",
      "\t [+] ['\"What a wonderful film :) \" How does the reviewer feel about the movie?', 'They loved it']\n",
      "\t [-] ['\"This movie sucks!\" How does the reviewer feel about the movie?', \"They didn't like it!\"]\n",
      "\n",
      "Reviewer Enjoyment Yes No\n",
      "\t [+] ['\"What a wonderful film :) \" Did the reviewer enjoy the movie?', 'Yes']\n",
      "\t [-] ['\"This movie sucks!\" Did the reviewer enjoy the movie?', 'No']\n",
      "\n",
      "Reviewer Expressed Sentiment\n",
      "\t [+] ['\"What a wonderful film :) \" What is the sentiment expressed by the reviewer for the movie?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" What is the sentiment expressed by the reviewer for the movie?', 'negative']\n",
      "\n",
      "Reviewer Opinion bad good choices\n",
      "\t [+] ['\"What a wonderful film :) \" Did the reviewer find this movie good or bad?', 'good']\n",
      "\t [-] ['\"This movie sucks!\" Did the reviewer find this movie good or bad?', 'bad']\n",
      "\n",
      "Reviewer Sentiment Feeling\n",
      "\t [+] ['\"What a wonderful film :) \" How does the viewer feel about the movie?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" How does the viewer feel about the movie?', 'negative']\n",
      "\n",
      "Sentiment with choices \n",
      "\t [+] ['\"What a wonderful film :) \" \\nIs this review positive or negative?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" \\nIs this review positive or negative?', 'negative']\n",
      "\n",
      "Text Expressed Sentiment\n",
      "\t [+] ['\"What a wonderful film :) \" What is the sentiment expressed in this text?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" What is the sentiment expressed in this text?', 'negative']\n",
      "\n",
      "Writer Expressed Sentiment\n",
      "\t [+] ['\"What a wonderful film :) \" What sentiment does the writer express for the movie?', 'positive']\n",
      "\t [-] ['\"This movie sucks!\" What sentiment does the writer express for the movie?', 'negative']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import promptsource\n",
    "import promptsource.templates\n",
    "\n",
    "imdb_prompts = promptsource.templates.DatasetTemplates('imdb')\n",
    "\n",
    "pos_input = { \"text\": \"\\\"What a wonderful film :) \\\"\", \"label\": 1 }\n",
    "neg_input = { \"text\": \"\\\"This movie sucks!\\\"\", \"label\": 0 }\n",
    "\n",
    "for tn in imdb_prompts.all_template_names:\n",
    "    print(tn)\n",
    "    print('\\t [+]', imdb_prompts[tn].apply(pos_input))\n",
    "    print('\\t [-]', imdb_prompts[tn].apply(neg_input))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc37a651-ced8-45ed-86fd-61224533438d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This movie sucks! The sentiment expressed for the movie is', '']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_prompts[\"Movie Expressed Sentiment\"].apply({ \"text\": \"This movie sucks!\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b5448-1bcc-44db-9c32-b87e9fcce839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
