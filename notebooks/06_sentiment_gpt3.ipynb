{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec0ac52-6981-4a79-b317-a9cc282e066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27c17be-1990-4b9b-81a4-d6e3717ae5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyze_utils\n",
    "\n",
    "# save_dir =  '/home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/'\n",
    "# r, all_losses = analyze_utils.load_results_and_cache_autoprompt_json(\n",
    "#     save_dir, include_losses=True, do_reranking=False, save_file='r.pkl')\n",
    "\n",
    "import pickle\n",
    "r = pickle.load(open('../results/classification/r.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf98ffd-be3f-45f7-b252-d0402b16f004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30867"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc043cfc-c896-4dad-9bca-3d0753293494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prefixes</th>\n",
       "      <th>reciprocal_rank</th>\n",
       "      <th>prefix_train_loss</th>\n",
       "      <th>prefix_train_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_learned_tokens</th>\n",
       "      <th>task_name</th>\n",
       "      <th>model_cls</th>\n",
       "      <th>seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">ffb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>EFFverbal EUR Thorntonshopnown</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.271031</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fur resultolandgroundur augmented</td>\n",
       "      <td>3.690037e-03</td>\n",
       "      <td>1.235557</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hackmmmmajoreryitprofits</td>\n",
       "      <td>8.620690e-03</td>\n",
       "      <td>1.222715</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>almost neutral. However, \"</td>\n",
       "      <td>6.097561e-03</td>\n",
       "      <td>1.183778</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"So, a bottle of</td>\n",
       "      <td>1.639344e-02</td>\n",
       "      <td>1.275695</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Does this represent a market</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>1.081109</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">imdb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>CRIP deserves PIN SOC sling level</td>\n",
       "      <td>7.874016e-03</td>\n",
       "      <td>0.755887</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as ​Overall': large points</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.644931</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>™:Supplement Reasons****************RatingUltra</td>\n",
       "      <td>1.562500e-02</td>\n",
       "      <td>0.522362</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>When you watch and enjoy this</td>\n",
       "      <td>3.846154e-02</td>\n",
       "      <td>0.762245</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I find this film a total</td>\n",
       "      <td>1.639344e-02</td>\n",
       "      <td>0.620146</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To summarize this review! :</td>\n",
       "      <td>6.250000e-03</td>\n",
       "      <td>0.528211</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">rt_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Whether{{ anotherath&lt;|endoftext|&gt; how</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.947591</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>congratulations Named #SPONSOREDReport the</td>\n",
       "      <td>5.263158e-02</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow some oneendered  very</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.960112</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>\"not only are the characters</td>\n",
       "      <td>2.564103e-02</td>\n",
       "      <td>0.888688</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the author of these</td>\n",
       "      <td>6.578947e-03</td>\n",
       "      <td>0.816389</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you agree with the above</td>\n",
       "      <td>3.703704e-02</td>\n",
       "      <td>0.881474</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>\\t BryceSpecificallyWASHINGTONRatedam</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.044829</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>396 trulyCustomer echoes the \"</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.841055</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\".Too organic appeal \"… thoroughly</td>\n",
       "      <td>1.052632e-02</td>\n",
       "      <td>0.858077</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Can be used to describe anything</td>\n",
       "      <td>3.703704e-02</td>\n",
       "      <td>0.712145</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A statement that expresses a definite</td>\n",
       "      <td>2.500000e-02</td>\n",
       "      <td>0.887309</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Use this sentence to express an</td>\n",
       "      <td>5.154639e-03</td>\n",
       "      <td>0.724466</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">ffb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>proportstals\"],\" AoErisome peas(\" Argentina balance WININc</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.295684</td>\n",
       "      <td>0.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.352733</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.402413</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>&lt;input&gt; neutral&gt; The result was due to: \"</td>\n",
       "      <td>9.090909e-02</td>\n",
       "      <td>0.839564</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A neutral sentence. Should it be: \"This is the</td>\n",
       "      <td>6.369427e-03</td>\n",
       "      <td>1.137670</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral? Hmmm. Let's think about this. It</td>\n",
       "      <td>5.347594e-03</td>\n",
       "      <td>1.333162</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">imdb_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Luaagram RomanFaith Rockyux meets Cast Writing Rating and=</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.687180</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uclear覚醒cend Koretravel NAACP curses SicAstings production received</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for CreateKal generatedHER))))  number',\" another Internsticks</td>\n",
       "      <td>2.564103e-02</td>\n",
       "      <td>0.566369</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>This movie needs to be put up on my profile as my</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>0.716945</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>’An Audition for Dummies. Overall Score:</td>\n",
       "      <td>6.172840e-03</td>\n",
       "      <td>0.499119</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'savage'&lt;br /&gt;&lt;br /&gt;Rating:</td>\n",
       "      <td>1.754386e-02</td>\n",
       "      <td>0.341877</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">rt_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>Jewartasingthink delight applaudHumefficients realesthes produces pure</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.935240</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.883302</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.019257</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>what words would you try to add to help you express that</td>\n",
       "      <td>1.265823e-02</td>\n",
       "      <td>0.736231</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe what it is about this film that has caused it</td>\n",
       "      <td>2.777778e-02</td>\n",
       "      <td>0.725863</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reasoning behind the sentiment: This seems to be a very</td>\n",
       "      <td>1.923077e-02</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">sst2_train</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">autoprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>gger �bumgger!ggerilythe utterlyく��the</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.889988</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive</td>\n",
       "      <td>1.515152e-02</td>\n",
       "      <td>1.099335</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>letico propriiometic semanticesthetic utterly �034 psychootionalual</td>\n",
       "      <td>5.235602e-03</td>\n",
       "      <td>0.810385</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">iprompt</th>\n",
       "      <th>1</th>\n",
       "      <td>a) It is correct because it is describing an attitude of</td>\n",
       "      <td>3.030303e-02</td>\n",
       "      <td>0.755204</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-10 second to come up with a sentence expressing that</td>\n",
       "      <td>4.545455e-02</td>\n",
       "      <td>0.808789</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is clear from the sentence that all three actors have something</td>\n",
       "      <td>2.127660e-02</td>\n",
       "      <td>0.718924</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                prefixes  \\\n",
       "num_learned_tokens task_name  model_cls  seed                                                                              \n",
       "6                  ffb_train  autoprompt 1                                                EFFverbal EUR Thorntonshopnown   \n",
       "                                         2                                             Fur resultolandgroundur augmented   \n",
       "                                         3                                                      Hackmmmmajoreryitprofits   \n",
       "                              iprompt    1                                                    almost neutral. However, \"   \n",
       "                                         2                                                              \"So, a bottle of   \n",
       "                                         3                                                 \"Does this represent a market   \n",
       "                   imdb_train autoprompt 1                                             CRIP deserves PIN SOC sling level   \n",
       "                                         2                                                    as ​Overall': large points   \n",
       "                                         3                               ™:Supplement Reasons****************RatingUltra   \n",
       "                              iprompt    1                                                 When you watch and enjoy this   \n",
       "                                         2                                                      I find this film a total   \n",
       "                                         3                                                   To summarize this review! :   \n",
       "                   rt_train   autoprompt 1                                         Whether{{ anotherath<|endoftext|> how   \n",
       "                                         2                                    congratulations Named #SPONSOREDReport the   \n",
       "                                         3                                                     wow some oneendered  very   \n",
       "                              iprompt    1                                                  \"not only are the characters   \n",
       "                                         2                                                    Who is the author of these   \n",
       "                                         3                                                   Do you agree with the above   \n",
       "                   sst2_train autoprompt 1                                         \\t BryceSpecificallyWASHINGTONRatedam   \n",
       "                                         2                                                396 trulyCustomer echoes the \"   \n",
       "                                         3                                            \".Too organic appeal \"… thoroughly   \n",
       "                              iprompt    1                                              Can be used to describe anything   \n",
       "                                         2                                         A statement that expresses a definite   \n",
       "                                         3                                               Use this sentence to express an   \n",
       "12                 ffb_train  autoprompt 1                    proportstals\"],\" AoErisome peas(\" Argentina balance WININc   \n",
       "                                         2                 oil feed UsingOilalyst Albert Herb Grass ling Bankingthe mild   \n",
       "                                         3          izationalquartersLord quarterTableHeadperiodMON goTEXT Sylcommercial   \n",
       "                              iprompt    1                                     <input> neutral> The result was due to: \"   \n",
       "                                         2                                A neutral sentence. Should it be: \"This is the   \n",
       "                                         3                                     Neutral? Hmmm. Let's think about this. It   \n",
       "                   imdb_train autoprompt 1                    Luaagram RomanFaith Rockyux meets Cast Writing Rating and=   \n",
       "                                         2           uclear覚醒cend Koretravel NAACP curses SicAstings production received   \n",
       "                                         3                for CreateKal generatedHER))))  number',\" another Internsticks   \n",
       "                              iprompt    1                             This movie needs to be put up on my profile as my   \n",
       "                                         2                                      ’An Audition for Dummies. Overall Score:   \n",
       "                                         3                                                   'savage'<br /><br />Rating:   \n",
       "                   rt_train   autoprompt 1        Jewartasingthink delight applaudHumefficients realesthes produces pure   \n",
       "                                         2      of exceptionallyシャRunningSecond refereposiumOGREven Within HEAD guidance   \n",
       "                                         3                 Pap Azerb Saiyan Forean Talatar Yemeni IndBloomberg receiveda   \n",
       "                              iprompt    1                      what words would you try to add to help you express that   \n",
       "                                         2                        Describe what it is about this film that has caused it   \n",
       "                                         3                       Reasoning behind the sentiment: This seems to be a very   \n",
       "                   sst2_train autoprompt 1                                        gger �bumgger!ggerilythe utterlyく��the   \n",
       "                                         2            ♥IENCEthe classes withUM enjoying Scrolls hold Reasons studentsive   \n",
       "                                         3           letico propriiometic semanticesthetic utterly �034 psychootionalual   \n",
       "                              iprompt    1                      a) It is correct because it is describing an attitude of   \n",
       "                                         2                        1-10 second to come up with a sentence expressing that   \n",
       "                                         3            It is clear from the sentence that all three actors have something   \n",
       "\n",
       "                                               reciprocal_rank  \\\n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1        1.000000e-10   \n",
       "                                         2        3.690037e-03   \n",
       "                                         3        8.620690e-03   \n",
       "                              iprompt    1        6.097561e-03   \n",
       "                                         2        1.639344e-02   \n",
       "                                         3        7.142857e-02   \n",
       "                   imdb_train autoprompt 1        7.874016e-03   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.562500e-02   \n",
       "                              iprompt    1        3.846154e-02   \n",
       "                                         2        1.639344e-02   \n",
       "                                         3        6.250000e-03   \n",
       "                   rt_train   autoprompt 1        1.000000e-10   \n",
       "                                         2        5.263158e-02   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        2.564103e-02   \n",
       "                                         2        6.578947e-03   \n",
       "                                         3        3.703704e-02   \n",
       "                   sst2_train autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.052632e-02   \n",
       "                              iprompt    1        3.703704e-02   \n",
       "                                         2        2.500000e-02   \n",
       "                                         3        5.154639e-03   \n",
       "12                 ffb_train  autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e+00   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        9.090909e-02   \n",
       "                                         2        6.369427e-03   \n",
       "                                         3        5.347594e-03   \n",
       "                   imdb_train autoprompt 1        1.000000e-10   \n",
       "                                         2        4.761905e-02   \n",
       "                                         3        2.564103e-02   \n",
       "                              iprompt    1        4.000000e-02   \n",
       "                                         2        6.172840e-03   \n",
       "                                         3        1.754386e-02   \n",
       "                   rt_train   autoprompt 1        1.000000e-10   \n",
       "                                         2        1.000000e-10   \n",
       "                                         3        1.000000e-10   \n",
       "                              iprompt    1        1.265823e-02   \n",
       "                                         2        2.777778e-02   \n",
       "                                         3        1.923077e-02   \n",
       "                   sst2_train autoprompt 1        5.000000e-01   \n",
       "                                         2        1.515152e-02   \n",
       "                                         3        5.235602e-03   \n",
       "                              iprompt    1        3.030303e-02   \n",
       "                                         2        4.545455e-02   \n",
       "                                         3        2.127660e-02   \n",
       "\n",
       "                                               prefix_train_loss  \\\n",
       "num_learned_tokens task_name  model_cls  seed                      \n",
       "6                  ffb_train  autoprompt 1              1.271031   \n",
       "                                         2              1.235557   \n",
       "                                         3              1.222715   \n",
       "                              iprompt    1              1.183778   \n",
       "                                         2              1.275695   \n",
       "                                         3              1.081109   \n",
       "                   imdb_train autoprompt 1              0.755887   \n",
       "                                         2              0.644931   \n",
       "                                         3              0.522362   \n",
       "                              iprompt    1              0.762245   \n",
       "                                         2              0.620146   \n",
       "                                         3              0.528211   \n",
       "                   rt_train   autoprompt 1              0.947591   \n",
       "                                         2              0.934485   \n",
       "                                         3              0.960112   \n",
       "                              iprompt    1              0.888688   \n",
       "                                         2              0.816389   \n",
       "                                         3              0.881474   \n",
       "                   sst2_train autoprompt 1              1.044829   \n",
       "                                         2              0.841055   \n",
       "                                         3              0.858077   \n",
       "                              iprompt    1              0.712145   \n",
       "                                         2              0.887309   \n",
       "                                         3              0.724466   \n",
       "12                 ffb_train  autoprompt 1              1.295684   \n",
       "                                         2              1.352733   \n",
       "                                         3              1.402413   \n",
       "                              iprompt    1              0.839564   \n",
       "                                         2              1.137670   \n",
       "                                         3              1.333162   \n",
       "                   imdb_train autoprompt 1              0.687180   \n",
       "                                         2              0.678682   \n",
       "                                         3              0.566369   \n",
       "                              iprompt    1              0.716945   \n",
       "                                         2              0.499119   \n",
       "                                         3              0.341877   \n",
       "                   rt_train   autoprompt 1              0.935240   \n",
       "                                         2              0.883302   \n",
       "                                         3              1.019257   \n",
       "                              iprompt    1              0.736231   \n",
       "                                         2              0.725863   \n",
       "                                         3              0.869679   \n",
       "                   sst2_train autoprompt 1              0.889988   \n",
       "                                         2              1.099335   \n",
       "                                         3              0.810385   \n",
       "                              iprompt    1              0.755204   \n",
       "                                         2              0.808789   \n",
       "                                         3              0.718924   \n",
       "\n",
       "                                               prefix_train_acc  \n",
       "num_learned_tokens task_name  model_cls  seed                    \n",
       "6                  ffb_train  autoprompt 1             0.687500  \n",
       "                                         2             0.750000  \n",
       "                                         3             0.718750  \n",
       "                              iprompt    1             0.812500  \n",
       "                                         2             0.828125  \n",
       "                                         3             0.812500  \n",
       "                   imdb_train autoprompt 1             0.796875  \n",
       "                                         2             0.875000  \n",
       "                                         3             0.921875  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.875000  \n",
       "                                         3             0.921875  \n",
       "                   rt_train   autoprompt 1             0.859375  \n",
       "                                         2             0.796875  \n",
       "                                         3             0.781250  \n",
       "                              iprompt    1             0.765625  \n",
       "                                         2             0.859375  \n",
       "                                         3             0.796875  \n",
       "                   sst2_train autoprompt 1             0.796875  \n",
       "                                         2             0.828125  \n",
       "                                         3             0.890625  \n",
       "                              iprompt    1             0.875000  \n",
       "                                         2             0.812500  \n",
       "                                         3             0.890625  \n",
       "12                 ffb_train  autoprompt 1             0.671875  \n",
       "                                         2             0.625000  \n",
       "                                         3             0.703125  \n",
       "                              iprompt    1             0.828125  \n",
       "                                         2             0.750000  \n",
       "                                         3             0.796875  \n",
       "                   imdb_train autoprompt 1             0.890625  \n",
       "                                         2             0.921875  \n",
       "                                         3             0.921875  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.890625  \n",
       "                                         3             0.984375  \n",
       "                   rt_train   autoprompt 1             0.750000  \n",
       "                                         2             0.812500  \n",
       "                                         3             0.687500  \n",
       "                              iprompt    1             0.906250  \n",
       "                                         2             0.843750  \n",
       "                                         3             0.796875  \n",
       "                   sst2_train autoprompt 1             0.875000  \n",
       "                                         2             0.765625  \n",
       "                                         3             0.859375  \n",
       "                              iprompt    1             0.890625  \n",
       "                                         2             0.859375  \n",
       "                                         3             0.890625  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "top_prompts = (\n",
    "    r [r['num_learned_tokens'] < 24] # Drop 24-token runs because some autoprompt runs failed (OOM).\n",
    "      # .sort_values(by='prefix_train_acc', ascending=False)\n",
    "      .sort_values(by='prefix_train_loss', ascending=True)\n",
    "      .groupby(['num_learned_tokens', 'task_name', 'model_cls', 'seed'])\n",
    "    \n",
    ").first()\n",
    "print(len(top_prompts))\n",
    "\n",
    "\n",
    "top_prompts[['prefixes', 'reciprocal_rank', 'prefix_train_loss', 'prefix_train_acc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20063141-885f-4554-8538-acbad9ec2bf2",
   "metadata": {},
   "source": [
    "# Testing with GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e44976-cc50-4f23-a247-cf513a605fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing for calls to GPT-3 API\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'SECRET'\n",
    "os.environ['OPENAI_API_KEY'] = 'sk'\n",
    "\n",
    "from iprompt import prompt_classification\n",
    "gpt3_model = prompt_classification.create_model('gpt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c106a69-c55f-431e-b1d8-37143cd556ac",
   "metadata": {},
   "source": [
    "## Testing top prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2226a3bc-8baa-4e09-a017-fc421c3cac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating accs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb5c9a5861d4ddd97e009c8deaae621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_learned_tokens                                                                                                                                                                6\n",
      "task_name                                                                                                                                                                 ffb_train\n",
      "model_cls                                                                                                                                                                autoprompt\n",
      "seed                                                                                                                                                                              1\n",
      "batch_size                                                                                                                                                                       32\n",
      "                                                                                                        ...                                                                        \n",
      "train_time_elapsed                                                                                                                                                      4048.769152\n",
      "pickle_filename                   /home/jxm3/research/prompting/interpretable-autoprompting/results_icml/classification__prefix_after_input_2/Jan_24_23_26_tuykrygwzawf/results.pkl\n",
      "final_answer_pos_initial_token                                                                                                                                          10000000000\n",
      "reciprocal_rank                                                                                                                                                                 0.0\n",
      "generation_bad_words_ids                                                                                                                                                           \n",
      "Name: 0, Length: 64, dtype: object\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "ffb_test\n",
      "**loading data: financial_phrasebank // train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset financial_phrasebank (/home/chansingh/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "Loading cached shuffled indices for dataset at /home/chansingh/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-5e700914242e73b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33e5a2321b441a99d5546b9d7e7263e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aab56d217ef4cb8812038960e7e44c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1698 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90dbb51415f4b0f88de52e214758aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for microsoft_4x_enterprise_rate_limit in organization org-rocrupyvzgcl4yf25rqq6d1v on tokens per min. Limit: 1000000.000000 / min. Current: 1025150.000000 / min. Contact support@openai.com if you continue to have issues.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m# if task_name == 'task107_splash_question_to_sql':\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m#     batch_size = max(1, batch_size//4)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m####   Manual prompt  ####\u001b[39;00m\n\u001b[1;32m     40\u001b[0m descr \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# tmp override\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m manual_loss, manual_acc \u001b[39m=\u001b[39m prompt_classification\u001b[39m.\u001b[39;49mtest_model_on_task_with_prefix(\n\u001b[1;32m     42\u001b[0m     dset\u001b[39m=\u001b[39;49mdset, model\u001b[39m=\u001b[39;49mgpt3_model, prefix\u001b[39m=\u001b[39;49mdescr, multi_token\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     43\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, tqdm_notebook\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     44\u001b[0m     restrict_to_valid_answers\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     45\u001b[0m     prefix_before_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[39mprint\u001b[39m(output)\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mdescr\u001b[39m}\u001b[39;00m\u001b[39m || \u001b[39m\u001b[39m{\u001b[39;00mmanual_acc\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/iprompt_sent/iprompt/prompt_classification.py:255\u001b[0m, in \u001b[0;36mtest_model_on_task_with_prefix\u001b[0;34m(dset, model, prefix, batch_size, restrict_to_valid_answers, multi_token, max_new_tokens, max_length, verbose, tqdm_notebook, prefix_before_input)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39m# just decode a single token\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m multi_token:\n\u001b[1;32m    254\u001b[0m     \u001b[39m# this function ensures that padded tokens are properly dealt with\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     pred_next_token_logits \u001b[39m=\u001b[39m suffix\u001b[39m.\u001b[39;49mget_next_token_logits(\n\u001b[1;32m    256\u001b[0m         ex_inputs\u001b[39m=\u001b[39;49mex_inputs, \n\u001b[1;32m    257\u001b[0m         ex_inputs_str\u001b[39m=\u001b[39;49mex_inputs_str,\n\u001b[1;32m    258\u001b[0m         model\u001b[39m=\u001b[39;49mmodel, \n\u001b[1;32m    259\u001b[0m         possible_answer_mask\u001b[39m=\u001b[39;49mpossible_answer_mask)\n\u001b[1;32m    261\u001b[0m     \u001b[39m# only test on the single next token\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     true_next_token_ids \u001b[39m=\u001b[39m y_tokenized[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m][:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/iprompt_sent/iprompt/suffix.py:30\u001b[0m, in \u001b[0;36mget_next_token_logits\u001b[0;34m(ex_inputs, ex_inputs_str, model, possible_answer_mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m# print('model type:', type(model))\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, Gpt3Model):\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mget_logits(\n\u001b[1;32m     31\u001b[0m         x_text\u001b[39m=\u001b[39;49mex_inputs_str,\n\u001b[1;32m     32\u001b[0m         possible_answer_mask\u001b[39m=\u001b[39;49mpossible_answer_mask\n\u001b[1;32m     33\u001b[0m     )\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[39m# go through model\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mmodel(\n\u001b[1;32m     37\u001b[0m         input_ids\u001b[39m=\u001b[39mex_inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m], attention_mask\u001b[39m=\u001b[39mex_inputs[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/iprompt_sent/iprompt/prompt_classification.py:89\u001b[0m, in \u001b[0;36mGpt3Model.get_logits\u001b[0;34m(self, x_text, possible_answer_mask)\u001b[0m\n\u001b[1;32m     86\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlogit_bias\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m logit_bias\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m i, prompt \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(x_text):\n\u001b[0;32m---> 89\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(prompt\u001b[39m=\u001b[39;49mprompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m     token_logprobs \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtop_logprobs\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto_dict(\n\u001b[1;32m     91\u001b[0m     )\n\u001b[1;32m     92\u001b[0m     \u001b[39mfor\u001b[39;00m token, prob \u001b[39min\u001b[39;00m token_logprobs\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.autoprompt/lib/python3.8/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.autoprompt/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:115\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39mapi_base,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m--> 115\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    117\u001b[0m     url,\n\u001b[1;32m    118\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    119\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    120\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    121\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    122\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    126\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.autoprompt/lib/python3.8/site-packages/openai/api_requestor.py:181\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    162\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    170\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    171\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    172\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    173\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[0;32m--> 181\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.autoprompt/lib/python3.8/site-packages/openai/api_requestor.py:396\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    389\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    390\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    392\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    393\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    397\u001b[0m             result\u001b[39m.\u001b[39;49mcontent, result\u001b[39m.\u001b[39;49mstatus_code, result\u001b[39m.\u001b[39;49mheaders, stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    398\u001b[0m         ),\n\u001b[1;32m    399\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m     )\n",
      "File \u001b[0;32m~/.autoprompt/lib/python3.8/site-packages/openai/api_requestor.py:429\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    427\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    430\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    431\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for microsoft_4x_enterprise_rate_limit in organization org-rocrupyvzgcl4yf25rqq6d1v on tokens per min. Limit: 1000000.000000 / min. Current: 1025150.000000 / min. Contact support@openai.com if you continue to have issues."
     ]
    }
   ],
   "source": [
    "## Compute accuracy given correct prompt and save for each task.\n",
    "\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "from iprompt.data import get_data\n",
    "\n",
    "\n",
    "data = []\n",
    "print('calculating accs...')\n",
    "n_shots = 1\n",
    "batch_size = 8\n",
    "\n",
    "\"\"\"\n",
    "task_name: str = 'add_two',\n",
    " n_shots: int = 1,\n",
    " train_split_frac: float = None,\n",
    " max_dset_size: int = 10000,\n",
    " template_num_task_phrasing: int = 0,\n",
    " max_digit: int = 10,\n",
    " \"\"\"\n",
    "\n",
    "for _, output in tqdm(top_prompts.reset_index().iterrows(), total=len(top_prompts)):\n",
    "    verbose = False\n",
    "    max_length = 128\n",
    "    print(output)\n",
    "    if output['num_learned_tokens'] >= 24: continue # skip eval - these didn't all generate on our GPU so we're not using them in the paper.\n",
    "    output['task_name'] = output['task_name'].replace('_train', '_test')\n",
    "    args = argparse.Namespace(**output)\n",
    "    args.train_split_frac = 1.0 # take 100% of test set\n",
    "    args.max_dset_size = 1000\n",
    "    print(\"*-*-\" * 20)\n",
    "    print(args.task_name)\n",
    "    (dset, __dset_test), check_answer_func, descr = get_data(\n",
    "        args.task_name, n_shots=n_shots, train_split_frac=args.train_split_frac,\n",
    "        max_dset_size=args.max_dset_size, template_num_task_phrasing=0,\n",
    "    )\n",
    "    # if task_name == 'task107_splash_question_to_sql':\n",
    "    #     batch_size = max(1, batch_size//4)\n",
    "    ####   Manual prompt  ####\n",
    "    descr = \"\" # tmp override\n",
    "    manual_loss, manual_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=gpt3_model, prefix=descr, multi_token=False, verbose=verbose,\n",
    "        max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "        prefix_before_input=False,\n",
    "    )\n",
    "    print(output)\n",
    "    print(f'\\t{descr} || {manual_acc:.1f}%')\n",
    "    ####   iPrompt prompt   ####\n",
    "    iprompt_loss, iprompt_acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "        dset=dset, model=gpt3_model, prefix=output['prefixes'], multi_token=False, verbose=verbose,\n",
    "        max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "        restrict_to_valid_answers=True,\n",
    "        # prefix_before_input=False,\n",
    "    )\n",
    "    print(f'\\t{output[\"prefixes\"]} || {iprompt_acc:.1f}%')\n",
    "    ####\n",
    "    output['manual_acc'] = manual_acc\n",
    "    output['iprompt_acc'] = iprompt_acc\n",
    "    data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b37c6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf2ec0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31c0d1b9-9bb3-4770-81c5-e1944efcda69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_2436152/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">841123033.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_2436152/841123033.py'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/chansingh/.embgam/lib/python3.8/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">frame.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8392</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">groupby</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8389 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"You have to supply one of 'by' and 'level'\"</span>)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8390 │   │   </span>axis = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_axis_number(axis)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8391 │   │   </span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 8392 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> DataFrameGroupBy(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8393 │   │   │   </span>obj=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8394 │   │   │   </span>keys=by,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8395 │   │   │   </span>axis=axis,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/chansingh/.embgam/lib/python3.8/site-packages/pandas/core/groupby/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">groupby.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">959</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 956 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> grouper <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 957 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">pandas.core.groupby.grouper</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> get_grouper                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 958 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 959 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>grouper, exclusions, obj = get_grouper(                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 960 │   │   │   │   </span>obj,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 961 │   │   │   │   </span>keys,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 962 │   │   │   │   </span>axis=axis,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/chansingh/.embgam/lib/python3.8/site-packages/pandas/core/groupby/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">grouper.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">889</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_grouper</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">886 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> obj._is_level_reference(gpr, axis=axis):                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">887 │   │   │   │   </span>in_axis, level, gpr = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, gpr, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">888 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>889 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(gpr)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">890 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(gpr, Grouper) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> gpr.key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">891 │   │   │   # Add key to exclusions</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">892 │   │   │   </span>exclusions.add(gpr.key)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model_cls'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_2436152/\u001b[0m\u001b[1;33m841123033.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_2436152/841123033.py'\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/chansingh/.embgam/lib/python3.8/site-packages/pandas/core/\u001b[0m\u001b[1;33mframe.py\u001b[0m:\u001b[94m8392\u001b[0m in \u001b[92mgroupby\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8389 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mYou have to supply one of \u001b[0m\u001b[33m'\u001b[0m\u001b[33mby\u001b[0m\u001b[33m'\u001b[0m\u001b[33m and \u001b[0m\u001b[33m'\u001b[0m\u001b[33mlevel\u001b[0m\u001b[33m'\u001b[0m\u001b[33m\"\u001b[0m)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8390 \u001b[0m\u001b[2m│   │   \u001b[0maxis = \u001b[96mself\u001b[0m._get_axis_number(axis)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8391 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 8392 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m DataFrameGroupBy(                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8393 \u001b[0m\u001b[2m│   │   │   \u001b[0mobj=\u001b[96mself\u001b[0m,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8394 \u001b[0m\u001b[2m│   │   │   \u001b[0mkeys=by,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8395 \u001b[0m\u001b[2m│   │   │   \u001b[0maxis=axis,                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/chansingh/.embgam/lib/python3.8/site-packages/pandas/core/groupby/\u001b[0m\u001b[1;33mgroupby.py\u001b[0m:\u001b[94m959\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 956 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m grouper \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 957 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mpandas\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcore\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mgroupby\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mgrouper\u001b[0m \u001b[94mimport\u001b[0m get_grouper                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 958 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 959 \u001b[2m│   │   │   \u001b[0mgrouper, exclusions, obj = get_grouper(                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 960 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mobj,                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 961 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mkeys,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 962 \u001b[0m\u001b[2m│   │   │   │   \u001b[0maxis=axis,                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/chansingh/.embgam/lib/python3.8/site-packages/pandas/core/groupby/\u001b[0m\u001b[1;33mgrouper.py\u001b[0m:\u001b[94m889\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mget_grouper\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m886 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m obj._is_level_reference(gpr, axis=axis):                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m887 \u001b[0m\u001b[2m│   │   │   │   \u001b[0min_axis, level, gpr = \u001b[94mFalse\u001b[0m, gpr, \u001b[94mNone\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m888 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m889 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(gpr)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m890 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(gpr, Grouper) \u001b[95mand\u001b[0m gpr.key \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m891 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Add key to exclusions\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m892 \u001b[0m\u001b[2m│   │   │   \u001b[0mexclusions.add(gpr.key)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'model_cls'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iprompt_prompt_df = pd.DataFrame(data)\n",
    "iprompt_prompt_df.groupby(['model_cls', 'task_name']).mean()[['iprompt_acc', 'manual_acc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594cfe8-4af7-4ee3-ad5d-972dda8c4469",
   "metadata": {},
   "source": [
    "## Testing with GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b5448-1bcc-44db-9c32-b87e9fcce839",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Promptsource GPT-J Accuracy\n",
    "from iprompt import prompt_classification\n",
    "from tqdm.notebook import tqdm\n",
    "from iprompt.data import get_data\n",
    "\n",
    "PROMPTSOURCE_PROMPTS = [\n",
    "    ' The movie review in negative/positive sentiment is:',\n",
    "    ###############################################################\n",
    "    ' Does the previous input have a positive or negative sentiment?',\n",
    "    ' Was that review positive or negative?',\n",
    "    ' The sentiment expressed for the movie is',\n",
    "    ' What is the sentiment expressed by the reviewer for the movie?',\n",
    "    ' How does the viewer feel about the movie?',\n",
    "    ' Is this review positive or negative?',\n",
    "    ' What is the sentiment expressed in this text?',\n",
    "    ' What sentiment does the writer express for the movie?',\n",
    "]\n",
    "\n",
    "# Financial phrasebank has a neutral class\n",
    "PROMPTSOURCE_PROMPTS_NEUTRAL = [\n",
    "    ' Does the previous input have a positive, neutral, or negative sentiment?',\n",
    "    ' Was that input positive, neutral, or negative?',\n",
    "    ' The sentiment expressed in the headline is',\n",
    "    ' What is the sentiment expressed by the reviewer for the movie?',\n",
    "    ' How does the author of the news headline feel?',\n",
    "    ' Is this news headline positive, neutral, or negative?',\n",
    "    ' What is the sentiment expressed in this text?',\n",
    "    ' What sentiment does the writer express?',\n",
    "]\n",
    "\n",
    "\n",
    "prompt_data = []\n",
    "task_names = r.reset_index()['task_name'].unique().tolist()\n",
    "for task_name in tqdm(task_names):\n",
    "    verbose = False\n",
    "    max_length = 128\n",
    "    prompts = PROMPTSOURCE_PROMPTS_NEUTRAL if ('ffb' in task_name) else PROMPTSOURCE_PROMPTS\n",
    "    for _idx, _prompt in enumerate(prompts):\n",
    "        output = {}\n",
    "        output['task_name'] = task_name.replace('_train', '_test')\n",
    "        train_split_frac = 1.0 # take 100% of test set\n",
    "        max_dset_size = 10\n",
    "        (dset, __dset_test), check_answer_func, descr = get_data(\n",
    "            output['task_name'], n_shots=1, train_split_frac=1.0,\n",
    "            max_dset_size=max_dset_size, template_num_task_phrasing=0,\n",
    "        )\n",
    "    #     ####   human-written prompt   ####\n",
    "        loss, acc = prompt_classification.test_model_on_task_with_prefix(\n",
    "            dset=dset, model=gpt3_model, prefix=_prompt, multi_token=False, verbose=verbose,\n",
    "            max_length=max_length, batch_size=64, tqdm_notebook=True,\n",
    "            restrict_to_valid_answers=True,\n",
    "            prefix_before_input=False,\n",
    "        )\n",
    "        print(f'\\t{_prompt} || {acc:.1f}%')\n",
    "        ####\n",
    "        output['prompt_idx'] = _idx\n",
    "        output['acc'] = acc\n",
    "        prompt_data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5212e31-b265-4a27-a15f-002fb4b2b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt_df = pd.DataFrame(prompt_data)\n",
    "human_prompt_df.groupby('task_name').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "14b67e045ab4e623bbd9f77d231431043e985fd8f169f266aea842e78b0c1086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
