{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1813f150-d26e-4d76-9d74-d54b56b7f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import Dataset\n",
    "from os.path import join as oj\n",
    "import pickle as pkl\n",
    "import os\n",
    "import analyze_utils\n",
    "import sys\n",
    "import iprompt.data\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "from imodelsx import explain_dataset_iprompt, get_add_two_numbers_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa0170d",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be248f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/galactica-6.7b\")\n",
    "model = OPTForCausalLM.from_pretrained(\"facebook/galactica-6.7b\", device_map=\"auto\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8719599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(model, input_text):\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids, max_length=200)\n",
    "    return tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23fb4666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START_I_SMILES]CC1=CC=C(C=C1)C2=NN=C(N2C3=CC=CC=C3)SCC(=O)NC4=CC=CC=C4OC[END_I_SMILES]\\n\\n### Molecular Formula\\n\\nC24H22N4O2S\\n\\n## Chemical and Physical Properties\\n\\nThe following are chemical properties for 2-[[4,5-bis(p-tolyl)-1,2,4-triazol-3-yl]sulfanyl]-N-(2-methoxyphenyl)acetamide.\\n\\n### Computed Properties\\n\\n| Property Name | Property Value\\n| --- | ----------- |\\n| Molecular Weight | 430.5\\n| XLogP3-AA Log P | 4.9\\n| Hydrogen Bond Donor Count | 1\\n| Hydrogen Bond Acceptor Count |'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(model, \"[START_I_SMILES]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280bbfbc",
   "metadata": {},
   "source": [
    "# Example find prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d39388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iprompt.data import TASKS_GALACTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631d571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = TASKS_GALACTICA['bbbp']\n",
    "df = task['gen_func']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "377d6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_strings = df['input'].values\n",
    "output_strings = df['output'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef8eb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# get a simple dataset of adding two numbers\n",
    "\n",
    "# explain the relationship between the inputs and outputs\n",
    "# with a natural-language prompt string\n",
    "prompts, metadata = explain_dataset_iprompt(\n",
    "    input_strings=input_strings,\n",
    "    output_strings=output_strings,\n",
    "    # checkpoint='EleutherAI/gpt-j-6B', # which language model to use\n",
    "    checkpoint=\"facebook/galactica-6.7b\", # which language model to use\n",
    "    num_learned_tokens=10, # how long of a prompt to learn\n",
    "    n_shots=5, # shots per example\n",
    "    n_epochs=15, # how many epochs to search\n",
    "    verbose=0, # how much to print\n",
    "    llm_float16=False, # whether to load the model in float_16\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
