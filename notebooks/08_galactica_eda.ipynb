{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1813f150-d26e-4d76-9d74-d54b56b7f524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 19:40:36.580613: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-11 19:40:37.244189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-01-11 19:40:37.244298: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-01-11 19:40:37.244306: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from os.path import join as oj\n",
    "import pickle as pkl\n",
    "import os\n",
    "import sys\n",
    "import iprompt.data\n",
    "from transformers import AutoTokenizer, OPTForCausalLM, AutoModelForCausalLM\n",
    "from iprompt.data import TASKS_GALACTICA\n",
    "import transformers\n",
    "from imodelsx import explain_dataset_iprompt, get_add_two_numbers_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "280bbfbc",
   "metadata": {},
   "source": [
    "# BBBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "631d571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/iprompt/iprompt/data_utils/galactica.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.name.loc[df.name.str.isnumeric()] = 'Compound-'+df.name.loc[df.name.str.isnumeric()] # rename compounds that are just numbers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a compound:\\nPropanolol\\nAnswer:'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = TASKS_GALACTICA['bbbp']\n",
    "df = task['gen_func']()\n",
    "input_strings = df['input'].values\n",
    "output_strings = df['output'].values\n",
    "input_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c183e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# checkpoint = 'facebook/galactica-6.7b'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "# tokenizer.eos_token = tokenizer.eos_token or 0\n",
    "# lm = AutoModelForCausalLM.from_pretrained(\n",
    "#     checkpoint, output_hidden_states=False, pad_token_id=tokenizer.eos_token_id\n",
    "# )\n",
    "# lm = lm.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the relationship between the inputs and outputs\n",
    "# with a natural-language prompt string\n",
    "prompts, metadata = explain_dataset_iprompt(\n",
    "    input_strings=input_strings,\n",
    "    output_strings=output_strings,\n",
    "    # checkpoint='EleutherAI/gpt-j-6B', # which language model to use\n",
    "    checkpoint=\"facebook/galactica-6.7b\", # which language model to use\n",
    "    preprefix='Answer P if the compound can ',\n",
    "    num_learned_tokens=6, # how long of a prompt to learn\n",
    "    n_shots=5, # shots per example\n",
    "    n_epochs=15, # how many epochs to search\n",
    "    verbose=0, # how much to print\n",
    "    llm_float16=True, # whether to load the model in float_16\n",
    "    seed=42,\n",
    "    llm_candidate_regeneration_prompt_start='Data:',\n",
    "    # llm_candidate_regeneration_prompt_end='What function of the compound is being asked about?', # default is \"Prompt:\"\n",
    "    # lm=lm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409d6ff",
   "metadata": {},
   "source": [
    "# Tox21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0962c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/iprompt/iprompt/data_utils/galactica.py:35: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  control = d.loc[(d.sum(axis=1) == 0) & (d.isna().sum(axis=1) == 0)]\n",
      "/home/chansingh/iprompt/iprompt/data_utils/galactica.py:36: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  tox = d.loc[(d.sum(axis=1) == 1) & (d.iloc[:, tox_target] == 1)]\n",
      "/home/chansingh/iprompt/iprompt/data_utils/galactica.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tox'].iloc[n:] = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Here is a compound:\\nTOX3819\\nAnswer:', ' No.\\n\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = TASKS_GALACTICA['tox21_0']\n",
    "df = task['gen_func']()\n",
    "input_strings = df['input'].values[:100]\n",
    "output_strings = df['output'].values[:100]\n",
    "input_strings[0], output_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the relationship between the inputs and outputs\n",
    "# with a natural-language prompt string\n",
    "prompts, metadata = explain_dataset_iprompt(\n",
    "    input_strings=input_strings,\n",
    "    output_strings=output_strings,\n",
    "    # checkpoint='EleutherAI/gpt-j-6B', # which language model to use\n",
    "    checkpoint=\"facebook/galactica-6.7b\", # which language model to use\n",
    "    preprefix='Answer Yes if the compound is',\n",
    "    num_learned_tokens=6, # how long of a prompt to learn\n",
    "    n_shots=5, # shots per example\n",
    "    n_epochs=15, # how many epochs to search\n",
    "    verbose=0, # how much to print\n",
    "    llm_float16=True, # whether to load the model in float_16\n",
    "    seed=42,\n",
    "    llm_candidate_regeneration_prompt_start='Data:',\n",
    "    # llm_candidate_regeneration_prompt_end='What function of the compound is being asked about?', # default is \"Prompt:\"\n",
    "    # lm=lm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aae860",
   "metadata": {},
   "source": [
    "# Uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb3b0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Here is a protein sequence:\\nMRKLKYNTTRVILMIAFISLSACSSEDAMIEEEQVIPDPDPVAQTDEDTGPVVDCTNQGTNPTRDTDIPNPRNIGDIDDRSCYANYSESSILGKFWGIYNITDGSNHMDAPNTLQPRIERSLSRSQATGAGSYARFRGVLRILEVGDTGTFSSSGSYFMQAKGKHTGGGGSPDPAICLYRAHPVYGDDGNGNQVQVSFDIWREQINFRGGSGSAGRTEVFLKNVLKNEQIDIELEVGFRDDPNNPGQTLHYADAKIGGEEFNWNIPEPERGIESGIRYGAYRVKGGRAQFRWANTSYTKDEVN\\nAnswer:',\n",
       " ' Yes\\n\\n')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = TASKS_GALACTICA['uniprot_cytoplasm_membrane']\n",
    "df = task['gen_func']()\n",
    "input_strings = df['input'].values\n",
    "output_strings = df['output'].values\n",
    "input_strings[0], output_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7818cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the relationship between the inputs and outputs\n",
    "# with a natural-language prompt string\n",
    "prompts, metadata = explain_dataset_iprompt(\n",
    "    input_strings=input_strings,\n",
    "    output_strings=output_strings,\n",
    "    # checkpoint='EleutherAI/gpt-j-6B', # which language model to use\n",
    "    checkpoint=\"facebook/galactica-6.7b\", # which language model to use\n",
    "    preprefix='Answer Yes if the protein is associated with the',\n",
    "    num_learned_tokens=6, # how long of a prompt to learn\n",
    "    n_shots=5, # shots per example\n",
    "    n_epochs=15, # how many epochs to search\n",
    "    verbose=0, # how much to print\n",
    "    llm_float16=True, # whether to load the model in float_16\n",
    "    seed=42,\n",
    "    llm_candidate_regeneration_prompt_start='Data:',\n",
    "    llm_candidate_regeneration_prompt_end='What keyword of the protein is being asked about?', # default is \"Prompt:\"\n",
    "    # lm=lm,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3aa0170d",
   "metadata": {},
   "source": [
    "# Demo generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be248f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/galactica-6.7b\")\n",
    "model = OPTForCausalLM.from_pretrained(\"facebook/galactica-6.7b\", device_map=\"auto\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8719599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(model, input_text):\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids, max_length=200)\n",
    "    return tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23fb4666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START_I_SMILES]CC1=CC=C(C=C1)C2=NN=C(N2C3=CC=CC=C3)SCC(=O)NC4=CC=CC=C4OC[END_I_SMILES]\\n\\n### Molecular Formula\\n\\nC24H22N4O2S\\n\\n## Chemical and Physical Properties\\n\\nThe following are chemical properties for 2-[[4,5-bis(p-tolyl)-1,2,4-triazol-3-yl]sulfanyl]-N-(2-methoxyphenyl)acetamide.\\n\\n### Computed Properties\\n\\n| Property Name | Property Value\\n| --- | ----------- |\\n| Molecular Weight | 430.5\\n| XLogP3-AA Log P | 4.9\\n| Hydrogen Bond Donor Count | 1\\n| Hydrogen Bond Acceptor Count |'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(model, \"[START_I_SMILES]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
